2018-11-21 17:12:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:12:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:12:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:12:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:12:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:12:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:12:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:12:36 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:12:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:12:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:12:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/> (referer: None)
2018-11-21 17:12:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:12:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 211,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 2687,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 12, 39, 112194),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 624963584,
 'memusage/startup': 624963584,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 12, 36, 170766)}
2018-11-21 17:12:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:13:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:13:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:13:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:13:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:13:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:13:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:13:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:13:38 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:13:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:13:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:13:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:13:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 13, 38, 26071),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 633782272,
 'memusage/startup': 633782272,
 'start_time': datetime.datetime(2018, 11, 21, 9, 13, 38, 21486)}
2018-11-21 17:13:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:13:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:13:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:13:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:13:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:13:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:13:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:13:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:13:48 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:13:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:13:49 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:13:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:13:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 13, 49, 5779),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 635301888,
 'memusage/startup': 635301888,
 'start_time': datetime.datetime(2018, 11, 21, 9, 13, 49, 1504)}
2018-11-21 17:13:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:14:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:14:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:14:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:14:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:14:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:14:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:14:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:14:01 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:14:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:14:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:14:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:14:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 14, 1, 972532),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 636936192,
 'memusage/startup': 636936192,
 'start_time': datetime.datetime(2018, 11, 21, 9, 14, 1, 968034)}
2018-11-21 17:14:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:14:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:14:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:14:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:14:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:14:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:14:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:14:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:14:13 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:14:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:14:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:14:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/> (referer: None)
2018-11-21 17:14:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:14:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 211,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 2687,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 14, 14, 794197),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 638869504,
 'memusage/startup': 638869504,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 14, 13, 726968)}
2018-11-21 17:14:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:15:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:15:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:15:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:15:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:15:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:15:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:15:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:15:00 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:15:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:15:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:15:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-21 17:15:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:15:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 15, 0, 440046),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 648003584,
 'memusage/startup': 648003584,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 15, 0, 330266)}
2018-11-21 17:15:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:15:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:15:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:15:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:15:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:15:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:15:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:15:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:15:36 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:15:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:15:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-21 17:15:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:15:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 15, 36, 265890),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 654196736,
 'memusage/startup': 654196736,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 15, 36, 152813)}
2018-11-21 17:15:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:17:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:17:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:17:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:17:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:17:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:17:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:17:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:17:03 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:17:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:17:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:17:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-21 17:17:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:17:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 17, 3, 477600),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 658034688,
 'memusage/startup': 658034688,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 17, 3, 364276)}
2018-11-21 17:17:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:17:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:17:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:17:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:17:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:17:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:17:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:17:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:17:34 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:17:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:17:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:17:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-21 17:17:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:17:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 17, 34, 961653),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 666218496,
 'memusage/startup': 666218496,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 17, 34, 830409)}
2018-11-21 17:17:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:21:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:21:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:21:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:21:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:21:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:21:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:21:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:21:15 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:21:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:21:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:21:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-21 17:21:15 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 13, in parse
    ip_list = selector.xpath('//table[@id="ip_list"]/tbody')
AttributeError: 'str' object has no attribute 'xpath'
2018-11-21 17:21:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:21:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 21, 15, 382914),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 689676288,
 'memusage/startup': 689676288,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 21, 15, 171636)}
2018-11-21 17:21:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:21:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:21:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:21:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:21:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:21:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:21:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:21:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:21:36 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:21:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:21:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-21 17:21:36 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 14, in parse
    ip_list = selector.xpath('//table[@id="ip_list"]/tbody')
AttributeError: 'str' object has no attribute 'xpath'
2018-11-21 17:21:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:21:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 21, 36, 744523),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 692207616,
 'memusage/startup': 692207616,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 21, 36, 532109)}
2018-11-21 17:21:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-21 17:22:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-21 17:22:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-21 17:22:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-21 17:22:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-21 17:22:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-21 17:22:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-21 17:22:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-21 17:22:10 [scrapy.core.engine] INFO: Spider opened
2018-11-21 17:22:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-21 17:22:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-21 17:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-21 17:22:10 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 13, in parse
    ip_list = selector.xpath('//table[@id="ip_list"]/tbody')
AttributeError: 'str' object has no attribute 'xpath'
2018-11-21 17:22:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-21 17:22:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 21, 9, 22, 10, 574876),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 694525952,
 'memusage/startup': 694525952,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 21, 9, 22, 10, 363710)}
2018-11-21 17:22:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:26:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:26:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:26:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:26:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:26:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:26:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:26:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:26:18 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:26:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:26:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:26:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:26:18 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 13, in parse
    ip_list = selector.xpath('//table[@id="ip_list"]/tbody')
AttributeError: 'str' object has no attribute 'xpath'
2018-11-22 08:26:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:26:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 26, 18, 755834),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 503083008,
 'memusage/startup': 503083008,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 26, 18, 389216)}
2018-11-22 08:26:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:28:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:28:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:28:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:28:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:28:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:28:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:28:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:28:00 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:28:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:28:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:28:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:28:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:28:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 28, 1, 68794),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 542998528,
 'memusage/startup': 542998528,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 28, 0, 943398)}
2018-11-22 08:28:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:29:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:29:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:29:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:29:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:29:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:29:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:29:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:29:24 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:29:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:29:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:29:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:29:24 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 23, in parse
    body = selector.body
AttributeError: 'str' object has no attribute 'body'
2018-11-22 08:29:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:29:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 29, 24, 692863),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 599232512,
 'memusage/startup': 599232512,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 29, 24, 467868)}
2018-11-22 08:29:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:29:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:29:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:29:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:29:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:29:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:29:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:29:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:29:51 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:29:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:29:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:29:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:29:51 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 23, in parse
    body = selector.url
AttributeError: 'str' object has no attribute 'url'
2018-11-22 08:29:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:29:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 29, 51, 732304),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 605736960,
 'memusage/startup': 605736960,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 29, 51, 505544)}
2018-11-22 08:29:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:30:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:30:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:30:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:30:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:30:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:30:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:30:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:30:01 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:30:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:30:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:30:01 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 23, in parse
    body = selector.url
AttributeError: 'str' object has no attribute 'url'
2018-11-22 08:30:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:30:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 30, 1, 748091),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 609665024,
 'memusage/startup': 609665024,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 30, 1, 518698)}
2018-11-22 08:30:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:31:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:31:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:31:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:31:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:31:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:31:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:31:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:31:09 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:31:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:31:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:31:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:31:09 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 23, in parse
    body = selector.url
AttributeError: 'str' object has no attribute 'url'
2018-11-22 08:31:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:31:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 31, 9, 993262),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 614088704,
 'memusage/startup': 614088704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 31, 9, 765853)}
2018-11-22 08:31:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:31:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:31:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:31:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:31:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:31:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:31:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:31:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:31:17 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:31:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:31:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:31:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:31:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 31, 17, 759051),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 614567936,
 'memusage/startup': 614567936,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 31, 17, 635262)}
2018-11-22 08:31:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:31:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:31:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:31:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:31:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:31:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:31:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:31:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:31:34 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:31:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:31:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:31:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:31:34 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 23, in parse
    body = selector.url
AttributeError: 'str' object has no attribute 'url'
2018-11-22 08:31:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:31:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 31, 34, 345729),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 615944192,
 'memusage/startup': 615944192,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 31, 34, 122803)}
2018-11-22 08:31:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:33:08 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:33:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:33:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:33:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:33:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:33:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:33:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:33:08 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:33:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:33:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:33:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:33:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 33, 8, 273100),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 636776448,
 'memusage/startup': 636776448,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 33, 8, 144769)}
2018-11-22 08:33:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:34:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:34:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:34:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:34:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:34:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:34:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:34:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:34:34 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:34:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:34:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:34:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:34:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:34:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 34, 35, 105460),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 643629056,
 'memusage/startup': 643629056,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 34, 34, 699345)}
2018-11-22 08:34:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:35:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:35:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:35:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:35:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:35:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:35:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:35:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:35:41 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:35:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:35:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:35:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:35:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 35, 41, 965246),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 645505024,
 'memusage/startup': 645505024,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 35, 41, 774106)}
2018-11-22 08:35:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:36:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:36:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:36:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:36:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:36:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:36:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:36:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:36:03 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:36:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:36:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:36:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:36:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 36, 4, 76256),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 646340608,
 'memusage/startup': 646340608,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 36, 3, 912703)}
2018-11-22 08:36:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:38:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:38:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:38:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:38:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:38:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:38:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:38:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:38:20 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:38:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:38:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:38:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:38:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:38:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 38, 20, 657628),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 674123776,
 'memusage/startup': 674123776,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 38, 20, 483619)}
2018-11-22 08:38:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:44:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:44:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:44:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:44:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:44:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:44:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:44:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:44:51 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:44:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:44:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:44:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:44:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:44:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 44, 51, 377801),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 684883968,
 'memusage/startup': 684883968,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 44, 51, 212169)}
2018-11-22 08:44:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:45:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:45:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:45:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:45:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:45:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:45:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:45:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:45:03 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:45:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:45:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:45:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:45:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:45:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 45, 3, 176353),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 684883968,
 'memusage/startup': 684883968,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 45, 3, 44498)}
2018-11-22 08:45:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:46:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:46:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:46:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:46:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:46:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:46:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:46:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:46:01 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:46:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:46:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:46:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:46:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:46:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 46, 1, 723570),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 701722624,
 'memusage/startup': 701722624,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 46, 1, 565750)}
2018-11-22 08:46:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:48:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:48:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:48:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:48:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:48:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:48:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:48:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:48:24 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:48:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:48:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:48:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:48:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:48:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 48, 24, 309871),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 703602688,
 'memusage/startup': 703602688,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 48, 24, 184365)}
2018-11-22 08:48:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:48:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:48:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:48:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:48:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:48:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:48:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:48:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:48:38 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:48:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:48:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:48:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:48:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:48:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 48, 38, 829648),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 703963136,
 'memusage/startup': 703963136,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 48, 38, 650930)}
2018-11-22 08:48:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:50:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:50:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:50:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:50:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:50:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:50:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:50:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:50:27 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:50:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:50:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:50:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:50:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 50, 27, 455827),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 705482752,
 'memusage/startup': 705482752,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 50, 27, 296590)}
2018-11-22 08:50:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:51:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:51:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:51:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:51:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:51:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:51:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:51:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:51:59 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:51:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:51:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:51:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:52:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:52:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 52, 0, 34112),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 706293760,
 'memusage/startup': 706293760,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 51, 59, 841080)}
2018-11-22 08:52:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 08:57:57 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 08:57:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 08:57:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 08:57:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 08:57:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 08:57:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 08:57:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 08:57:57 [scrapy.core.engine] INFO: Spider opened
2018-11-22 08:57:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 08:57:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 08:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 08:57:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 08:57:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 0, 57, 57, 412852),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 713596928,
 'memusage/startup': 713596928,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 0, 57, 57, 243359)}
2018-11-22 08:57:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:12:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:12:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:12:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:12:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:12:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:12:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:12:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:12:18 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:12:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:12:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:12:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:12:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:12:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 12, 18, 635707),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 732131328,
 'memusage/startup': 732131328,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 12, 18, 461049)}
2018-11-22 09:12:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:15:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:15:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:15:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:15:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:15:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:15:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:15:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:15:06 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:15:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:15:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:15:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:15:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:15:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 15, 6, 425008),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 732131328,
 'memusage/startup': 732131328,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 15, 6, 128722)}
2018-11-22 09:15:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:36:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:36:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:36:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:36:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:36:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:36:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:36:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:36:15 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:36:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:36:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:36:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:36:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:36:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 36, 15, 749053),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 739106816,
 'memusage/startup': 739106816,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 36, 15, 520310)}
2018-11-22 09:36:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:37:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:37:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:37:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:37:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:37:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:37:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:37:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:37:20 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:37:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:37:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:37:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:37:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:37:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 37, 21, 95688),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 740372480,
 'memusage/startup': 740372480,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 37, 20, 836762)}
2018-11-22 09:37:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:37:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:37:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:37:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:37:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:37:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:37:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:37:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:37:52 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:37:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:37:52 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:37:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:37:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:37:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 37, 53, 147107),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 740741120,
 'memusage/startup': 740741120,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 37, 52, 964183)}
2018-11-22 09:37:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:38:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:38:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:38:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:38:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:38:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:38:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:38:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:38:36 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:38:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:38:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:38:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:38:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:38:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 38, 36, 344111),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 741515264,
 'memusage/startup': 741515264,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 38, 36, 139226)}
2018-11-22 09:38:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:39:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:39:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:39:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:39:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:39:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:39:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:39:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:39:36 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:39:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:39:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:39:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:39:36 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:39:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:39:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 39, 36, 474793),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 742080512,
 'memusage/startup': 742080512,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 39, 36, 252678)}
2018-11-22 09:39:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:40:07 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:40:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:40:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:40:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:40:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:40:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:40:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:40:07 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:40:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:40:07 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:40:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:40:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:40:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 40, 7, 464397),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 742580224,
 'memusage/startup': 742580224,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 40, 7, 285125)}
2018-11-22 09:40:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:42:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:42:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:42:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:42:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:42:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:42:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:42:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:42:36 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:42:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:42:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:42:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:42:37 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:42:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 42, 37, 81861),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 747192320,
 'memusage/startup': 747192320,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 42, 36, 846829)}
2018-11-22 09:42:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:42:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:42:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:42:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:42:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:42:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:42:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:42:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 09:42:59 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:42:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:42:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:42:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:42:59 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:42:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:42:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 42, 59, 677190),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 749187072,
 'memusage/startup': 749187072,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 42, 59, 417449)}
2018-11-22 09:42:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:44:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:44:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:44:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:44:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:44:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:44:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:44:44 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:44:44 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:44:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:44:44 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:44:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:44:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:44:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:44:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 44, 44, 307169),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 756744192,
 'memusage/startup': 756744192,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 44, 44, 96891)}
2018-11-22 09:44:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:46:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:46:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:46:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:46:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:46:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:46:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:46:25 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:46:25 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:46:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:46:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:46:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 46, 25, 201656),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 46, 25, 18147)}
2018-11-22 09:46:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:46:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:46:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:46:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:46:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:46:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:46:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:46:56 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:46:56 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:46:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:46:56 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:46:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:46:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:46:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:46:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 46, 57, 115456),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 46, 56, 922126)}
2018-11-22 09:46:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:47:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:47:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:47:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:47:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:47:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:47:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:47:27 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:47:27 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:47:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:47:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:47:28 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:47:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:47:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 47, 28, 57252),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 47, 27, 857453)}
2018-11-22 09:47:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:48:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:48:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:48:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:48:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:48:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:48:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:48:00 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:48:00 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:48:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:48:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:48:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:48:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:48:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 48, 0, 877333),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 48, 0, 693494)}
2018-11-22 09:48:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:48:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:48:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:48:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:48:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:48:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:48:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:48:06 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:48:06 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:48:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:48:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:48:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:48:07 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:48:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:48:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 48, 7, 160094),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 48, 6, 977075)}
2018-11-22 09:48:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:51:12 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:51:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:51:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:51:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:51:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:51:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:51:13 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:51:13 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:51:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:51:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:51:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:51:13 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:51:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 51, 13, 289603),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 51, 13, 61623)}
2018-11-22 09:51:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:51:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:51:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:51:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:51:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:51:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:51:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:51:41 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:51:41 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:51:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:51:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:51:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:51:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 51, 41, 274068),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 51, 41, 48195)}
2018-11-22 09:51:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:52:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:52:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:52:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:52:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:52:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:52:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:52:09 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:52:09 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:52:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:52:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:52:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:52:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:52:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:52:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 52, 9, 407499),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 52, 9, 198631)}
2018-11-22 09:52:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:53:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:53:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:53:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:53:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:53:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:53:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:53:14 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:53:14 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:53:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:53:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:53:15 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:53:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 53, 15, 198691),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 53, 14, 999104)}
2018-11-22 09:53:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:53:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:53:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:53:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:53:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:53:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:53:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:53:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:53:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:53:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:53:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:53:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:53:43 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:53:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:53:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 53, 43, 709195),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 53, 43, 510644)}
2018-11-22 09:53:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:54:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:54:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:54:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:54:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:54:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:54:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:54:06 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:54:06 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:54:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:54:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:54:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:54:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:54:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:54:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 54, 6, 694194),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 54, 6, 492660)}
2018-11-22 09:54:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:55:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:55:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:55:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:55:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:55:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:55:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:55:28 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:55:28 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:55:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:55:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:55:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:55:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:55:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 55, 29, 126151),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 768745472,
 'memusage/startup': 768745472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 55, 28, 922832)}
2018-11-22 09:55:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:57:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:57:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:57:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:57:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:57:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:57:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:57:41 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:57:41 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:57:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:57:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:57:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:57:41 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:57:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:57:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 57, 41, 795867),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 57, 41, 584850)}
2018-11-22 09:57:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:58:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:58:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:58:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:58:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:58:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:58:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:58:17 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:58:17 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:58:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:58:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:58:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:58:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 58, 17, 674411),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 58, 17, 464145)}
2018-11-22 09:58:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 09:58:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 09:58:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 09:58:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 09:58:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 09:58:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 09:58:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 09:58:32 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 09:58:32 [scrapy.core.engine] INFO: Spider opened
2018-11-22 09:58:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 09:58:32 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 09:58:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 09:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 09:58:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 09:58:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 1, 58, 32, 741494),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 1, 58, 32, 552894)}
2018-11-22 09:58:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:02:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:02:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:02:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:02:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:02:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:02:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:02:00 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:02:00 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:02:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:02:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:02:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:02:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:02:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 2, 0, 712811),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 2, 0, 526902)}
2018-11-22 10:02:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:03:57 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:03:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:03:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:03:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:03:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:03:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:03:57 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:03:57 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:03:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:03:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:03:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:03:57 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:03:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:03:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 3, 57, 355086),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 3, 57, 155905)}
2018-11-22 10:03:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:04:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:04:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:04:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:04:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:04:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:04:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:04:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:04:34 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:04:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:04:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.scraper] ERROR: Error processing {'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 11, in process_item
    print(spider.tostring())
AttributeError: 'BturlSpider' object has no attribute 'tostring'
2018-11-22 10:04:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:04:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 4, 34, 737702),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 100,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 4, 34, 555393)}
2018-11-22 10:04:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:11:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:11:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:11:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:11:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:11:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:11:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:11:45 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:11:45 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:11:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:11:45 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:11:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:11:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 11, 45, 789655),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 11, 45, 585236)}
2018-11-22 10:11:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:12:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:12:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:12:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:12:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:12:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:12:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:12:32 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:12:32 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:12:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:12:32 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:12:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:12:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:12:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 12, 32, 505743),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 12, 32, 291212)}
2018-11-22 10:12:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:12:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:12:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:12:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:12:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:12:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:12:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:12:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:12:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:12:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:12:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:12:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:12:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:12:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:12:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 12, 48, 795099),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 12, 48, 594807)}
2018-11-22 10:12:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:20:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:20:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:20:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:20:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:20:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:20:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:20:56 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:20:56 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:20:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:20:56 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:20:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:20:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:20:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 20, 56, 367101),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 20, 56, 161354)}
2018-11-22 10:20:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:21:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:21:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:21:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:21:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:21:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:21:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:21:19 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:21:19 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:21:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:21:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:21:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:21:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 21, 19, 949637),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 21, 19, 749164)}
2018-11-22 10:21:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:22:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:22:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:22:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:22:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:22:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:22:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:22:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:22:51 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:22:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:22:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:22:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xicidaili.com/nn/> (failed 1 times): 503 Service Unavailable
2018-11-22 10:22:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xicidaili.com/nn/> (failed 2 times): 503 Service Unavailable
2018-11-22 10:22:51 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xicidaili.com/nn/> (failed 3 times): 503 Service Unavailable
2018-11-22 10:22:51 [scrapy.core.engine] DEBUG: Crawled (503) <GET http://www.xicidaili.com/nn/> (referer: None)
2018-11-22 10:22:51 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <503 http://www.xicidaili.com/nn/>: HTTP status code is not handled or not allowed
2018-11-22 10:22:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:22:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 657,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 999,
 'downloader/response_count': 3,
 'downloader/response_status_count/503': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 22, 51, 928748),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/503': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 8,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/503 Service Unavailable': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 2, 22, 51, 623754)}
2018-11-22 10:22:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:23:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:23:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:23:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:23:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:23:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:23:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:23:39 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:23:39 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:23:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:23:39 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xicidaili.com/nn/> (failed 1 times): 503 Service Unavailable
2018-11-22 10:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xicidaili.com/nn/> (failed 2 times): 503 Service Unavailable
2018-11-22 10:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xicidaili.com/nn/> (failed 3 times): 503 Service Unavailable
2018-11-22 10:23:39 [scrapy.core.engine] DEBUG: Crawled (503) <GET http://www.xicidaili.com/nn/> (referer: None)
2018-11-22 10:23:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <503 http://www.xicidaili.com/nn/>: HTTP status code is not handled or not allowed
2018-11-22 10:23:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:23:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 657,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 999,
 'downloader/response_count': 3,
 'downloader/response_status_count/503': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 23, 39, 728319),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/503': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 8,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/503 Service Unavailable': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 2, 23, 39, 490432)}
2018-11-22 10:23:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:25:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:25:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:25:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:25:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:25:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:25:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:25:37 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:25:37 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:25:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:25:37 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:25:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:25:37 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/xici.py", line 15, in parse
    print(response.ulr)
AttributeError: 'HtmlResponse' object has no attribute 'ulr'
2018-11-22 10:25:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:25:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 25, 37, 945015),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 792711168,
 'memusage/startup': 792711168,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 25, 37, 811163)}
2018-11-22 10:25:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:25:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:25:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:25:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:25:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:25:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:25:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:25:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:25:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:25:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:25:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:25:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:25:48 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/xici.py", line 15, in parse
    print(response.ulr)
AttributeError: 'HtmlResponse' object has no attribute 'ulr'
2018-11-22 10:25:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:25:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 25, 48, 836485),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 795557888,
 'memusage/startup': 795557888,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 25, 48, 721394)}
2018-11-22 10:25:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:25:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:25:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:25:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:25:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:25:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:25:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:25:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:25:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:25:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:25:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:25:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:25:55 [scrapy.core.scraper] ERROR: Spider error processing <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/xici.py", line 15, in parse
    print(response.ulr)
AttributeError: 'HtmlResponse' object has no attribute 'ulr'
2018-11-22 10:25:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:25:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 25, 55, 460133),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 796708864,
 'memusage/startup': 796708864,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 25, 55, 345254)}
2018-11-22 10:25:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:26:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:26:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:26:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:26:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:26:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:26:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:26:18 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:26:18 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:26:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:26:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:26:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:26:18 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:26:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:26:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 26, 18, 596860),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 797007872,
 'memusage/startup': 797007872,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 26, 18, 382768)}
2018-11-22 10:26:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:27:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:27:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:27:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:27:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:27:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:27:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:27:24 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:27:24 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:27:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:27:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:27:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:27:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:27:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:27:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 27, 24, 632426),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 797241344,
 'memusage/startup': 797241344,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 27, 24, 412452)}
2018-11-22 10:27:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:28:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:28:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:28:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:28:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:28:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:28:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:28:06 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:28:06 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:28:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:28:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:28:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:28:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 28, 6, 783822),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 798208000,
 'memusage/startup': 798208000,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 28, 6, 569601)}
2018-11-22 10:28:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:28:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:28:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:28:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:28:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:28:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:28:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:28:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:28:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:28:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:28:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:28:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:55 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:28:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:28:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 231,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 77516,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 28, 56, 88047),
 'item_scraped_count': 100,
 'log_count/DEBUG': 102,
 'log_count/INFO': 7,
 'memusage/max': 798461952,
 'memusage/startup': 798461952,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 28, 55, 864113)}
2018-11-22 10:28:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:42:23 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:42:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:42:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:42:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:42:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:42:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:42:23 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:42:23 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:42:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:42:23 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:42:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:42:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici2.html> (referer: None)
2018-11-22 10:42:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici3.html> (referer: None)
2018-11-22 10:42:23 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.16.9',
 'LAST_CHECK_TIME': '18-11-21 02:02',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.146.2.234',
 'LAST_CHECK_TIME': '18-11-21 02:01',
 'LOCATION': '',
 'PORT': '39960',
 'SPEED': '0.243',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '211.147.239.101',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '57281',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.77.156',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.227',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.86.80',
 'LAST_CHECK_TIME': '18-11-21 01:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.466',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.71.15',
 'LAST_CHECK_TIME': '18-11-21 01:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.529',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.240.224.252',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '33035',
 'SPEED': '0.186',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.169',
 'LAST_CHECK_TIME': '18-11-21 00:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.244',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.17.236.83',
 'LAST_CHECK_TIME': '18-11-21 00:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.347',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.115.49.174',
 'LAST_CHECK_TIME': '18-11-21 00:30',
 'LOCATION': '',
 'PORT': '59216',
 'SPEED': '0.146',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.69.13.242',
 'LAST_CHECK_TIME': '18-11-21 00:23',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '3.461',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.224.101.48',
 'LAST_CHECK_TIME': '18-11-20 13:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.088',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.3.170.89',
 'LAST_CHECK_TIME': '18-11-20 13:30',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.85.248',
 'LAST_CHECK_TIME': '18-11-20 13:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.992',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.72.115.59',
 'LAST_CHECK_TIME': '18-11-20 12:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.27',
 'LAST_CHECK_TIME': '18-11-20 12:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.32',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.127.93.188',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '57985',
 'SPEED': '4.426',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.253.84.183',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '30071',
 'SPEED': '4.317',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.254',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.718',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '58.62.238.150',
 'LAST_CHECK_TIME': '18-11-21 00:16',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.78.214',
 'LAST_CHECK_TIME': '18-11-21 00:05',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.895',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.86.208.98',
 'LAST_CHECK_TIME': '18-11-21 00:00',
 'LOCATION': '',
 'PORT': '41683',
 'SPEED': '1.181',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '120.10.25.4',
 'LAST_CHECK_TIME': '18-11-20 12:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.122.53',
 'LAST_CHECK_TIME': '18-11-20 12:12',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.912',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.175.218.98',
 'LAST_CHECK_TIME': '18-11-20 12:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.692',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.4.217',
 'LAST_CHECK_TIME': '18-11-20 11:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '2.468',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.27.43',
 'LAST_CHECK_TIME': '18-11-20 23:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.338',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.218.102.146',
 'LAST_CHECK_TIME': '18-11-20 23:45',
 'LOCATION': '',
 'PORT': '33323',
 'SPEED': '0.019',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.70.66',
 'LAST_CHECK_TIME': '18-11-20 23:41',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.156.237',
 'LAST_CHECK_TIME': '18-11-20 11:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.217',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '61.178.127.14',
 'LAST_CHECK_TIME': '18-11-20 11:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.165',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.185.221.142',
 'LAST_CHECK_TIME': '18-11-20 10:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.121',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.25.193',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.558',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.44',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.194',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.59.84.15',
 'LAST_CHECK_TIME': '18-11-20 10:30',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.784',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '49.82.50.36',
 'LAST_CHECK_TIME': '18-11-20 10:21',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '4.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.61.203.134',
 'LAST_CHECK_TIME': '18-11-20 10:15',
 'LOCATION': '',
 'PORT': '51987',
 'SPEED': '0.172',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.178.227.171',
 'LAST_CHECK_TIME': '18-11-20 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.006',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.20',
 'LAST_CHECK_TIME': '18-11-20 09:45',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.25',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.234.181.194',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '33695',
 'SPEED': '3.011',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.48.51.212',
 'LAST_CHECK_TIME': '18-11-20 09:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.172.191.226',
 'LAST_CHECK_TIME': '18-11-20 09:24',
 'LOCATION': '',
 'PORT': '33384',
 'SPEED': '4.076',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.72.195.140',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.612',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.20',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '5.48',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.228',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.803',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.169.199.126',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.416',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.24.170',
 'LAST_CHECK_TIME': '18-11-20 08:46',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.977',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.186.228',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.735',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.74.147',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.247',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.77.167',
 'LAST_CHECK_TIME': '18-11-20 08:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.215',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.173.72.153',
 'LAST_CHECK_TIME': '18-11-20 08:05',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.81',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.24.16.198',
 'LAST_CHECK_TIME': '18-11-20 23:31',
 'LOCATION': '',
 'PORT': '43620',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.165.131',
 'LAST_CHECK_TIME': '18-11-20 23:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.229',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.165.234',
 'LAST_CHECK_TIME': '18-11-20 23:23',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.819',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.214.180.122',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '33190',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '118.181.226.216',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '36430',
 'SPEED': '0.261',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.80',
 'LAST_CHECK_TIME': '18-11-20 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.473',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.154.99',
 'LAST_CHECK_TIME': '18-11-20 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.3',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.248',
 'LAST_CHECK_TIME': '18-11-20 23:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.597',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.187.206.207',
 'LAST_CHECK_TIME': '18-11-20 22:55',
 'LOCATION': '',
 'PORT': '46693',
 'SPEED': '4.125',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.165.130.111',
 'LAST_CHECK_TIME': '18-11-20 07:55',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.527',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.104.38',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.781',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.116',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.421',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '113.103.15.139',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.913',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.175.136.195',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '54584',
 'SPEED': '0.187',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.192.216',
 'LAST_CHECK_TIME': '18-11-20 07:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.536',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.55.21.194',
 'LAST_CHECK_TIME': '18-11-20 07:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.224',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.178.149.237',
 'LAST_CHECK_TIME': '18-11-20 22:40',
 'LOCATION': '',
 'PORT': '59042',
 'SPEED': '1.809',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '49.71.81.165',
 'LAST_CHECK_TIME': '18-11-20 22:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '4.586',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.190',
 'LAST_CHECK_TIME': '18-11-20 22:15',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.78.43.87',
 'LAST_CHECK_TIME': '18-11-20 22:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.142',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.89.33.59',
 'LAST_CHECK_TIME': '18-11-20 21:45',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.11',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.176.186',
 'LAST_CHECK_TIME': '18-11-20 21:44',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.537',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.223.115.30',
 'LAST_CHECK_TIME': '18-11-20 21:22',
 'LOCATION': '',
 'PORT': '51618',
 'SPEED': '0.073',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.210.133.98',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '32741',
 'SPEED': '0.214',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.18.115',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.176.36.251',
 'LAST_CHECK_TIME': '18-11-20 07:01',
 'LOCATION': '',
 'PORT': '37000',
 'SPEED': '0.357',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '106.14.214.94',
 'LAST_CHECK_TIME': '18-11-20 06:56',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.104',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.157.174.133',
 'LAST_CHECK_TIME': '18-11-20 06:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.39',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.17.236.52',
 'LAST_CHECK_TIME': '18-11-20 06:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.802',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '222.182.56.218',
 'LAST_CHECK_TIME': '18-11-20 03:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.113.27.170',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '47849',
 'SPEED': '0.094',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.119.65.16',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '39.76.14.191',
 'LAST_CHECK_TIME': '18-11-20 03:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.635',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.61',
 'LAST_CHECK_TIME': '18-11-20 02:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '1.189',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.184.127.79',
 'LAST_CHECK_TIME': '18-11-20 21:17',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.164.78',
 'LAST_CHECK_TIME': '18-11-20 21:16',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.348',
 'TYPE': 'HTTP'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.219.106.147',
 'LAST_CHECK_TIME': '18-11-20 21:10',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.342',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.228.49.232',
 'LAST_CHECK_TIME': '18-11-20 21:02',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.692',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '113.121.243.50',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '38118',
 'SPEED': '1.19',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.154.23',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '0.505',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.183.121.126',
 'LAST_CHECK_TIME': '18-11-20 20:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.081',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.25.163',
 'LAST_CHECK_TIME': '18-11-20 20:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.839',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.91.11',
 'LAST_CHECK_TIME': '18-11-20 20:42',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.427',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.202',
 'LAST_CHECK_TIME': '18-11-20 02:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.823',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.25.124',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.925',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.43',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.501',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '36.33.32.158',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '59019',
 'SPEED': '0.205',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.54',
 'LAST_CHECK_TIME': '18-11-20 02:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.845',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.77.72',
 'LAST_CHECK_TIME': '18-11-20 01:52',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.577',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.64.130',
 'LAST_CHECK_TIME': '18-11-20 01:46',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.816',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.132',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6675',
 'SPEED': '1.199',
 'TYPE': 'socks4/5'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.24.111',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.193',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.10',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.498',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.67.25.83',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '41681',
 'SPEED': '0.342',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.15.202.34',
 'LAST_CHECK_TIME': '18-11-20 20:21',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.104',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.236.98.78',
 'LAST_CHECK_TIME': '18-11-20 20:02',
 'LOCATION': '',
 'PORT': '43682',
 'SPEED': '0.165',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.148.79.233',
 'LAST_CHECK_TIME': '18-11-20 01:44',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.246',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '220.173.106.168',
 'LAST_CHECK_TIME': '18-11-20 01:38',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.284',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.194.141',
 'LAST_CHECK_TIME': '18-11-20 01:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.641',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.68.115',
 'LAST_CHECK_TIME': '18-11-20 19:50',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.805',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.166.159',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.28',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.156.179',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.467',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.168.136.31',
 'LAST_CHECK_TIME': '18-11-20 19:22',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.184',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.44.62',
 'LAST_CHECK_TIME': '18-11-20 19:21',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.031',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '114.99.167.121',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.599',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.162.208',
 'LAST_CHECK_TIME': '18-11-20 01:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.568',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.228.49.227',
 'LAST_CHECK_TIME': '18-11-20 01:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.85',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.107.144',
 'LAST_CHECK_TIME': '18-11-20 00:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.783',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.78.41',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.039',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.219',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.876',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.153.165',
 'LAST_CHECK_TIME': '18-11-20 00:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.234',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.79.224',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.553',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.32.37.229',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.208',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.190.95.35',
 'LAST_CHECK_TIME': '18-11-19 23:51',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.052',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.174.225.26',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '60984',
 'SPEED': '0.14',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.161.208',
 'LAST_CHECK_TIME': '18-11-20 19:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.194.214',
 'LAST_CHECK_TIME': '18-11-20 19:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.529',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.254.94.105',
 'LAST_CHECK_TIME': '18-11-20 18:55',
 'LOCATION': '',
 'PORT': '58999',
 'SPEED': '3.252',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.142.132.146',
 'LAST_CHECK_TIME': '18-11-20 18:33',
 'LOCATION': '',
 'PORT': '40655',
 'SPEED': '3.836',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.168.13.26',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '4.068',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '117.21.191.154',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.2',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.827',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '119.1.97.193',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '60916',
 'SPEED': '0.398',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.138.140',
 'LAST_CHECK_TIME': '18-11-19 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.226',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.100',
 'LAST_CHECK_TIME': '18-11-19 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.91',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.64.78',
 'LAST_CHECK_TIME': '18-11-19 23:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.026',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '101.236.54.166',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.02',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '223.203.0.14',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.025',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.99.255.28',
 'LAST_CHECK_TIME': '18-11-19 22:46',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.133',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.106.91.58',
 'LAST_CHECK_TIME': '18-11-20 18:22',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.202.216.218',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.18',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.143.180',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '7.255',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.235.135.210',
 'LAST_CHECK_TIME': '18-11-20 17:50',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '3.855',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.57.214',
 'LAST_CHECK_TIME': '18-11-20 17:45',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.24.153',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.156',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.42',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.99.133.223',
 'LAST_CHECK_TIME': '18-11-20 17:06',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.212',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.147.198',
 'LAST_CHECK_TIME': '18-11-20 17:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '1.842',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.150.45',
 'LAST_CHECK_TIME': '18-11-20 16:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.873',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.68.73',
 'LAST_CHECK_TIME': '18-11-19 22:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.584',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.213.234',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.387',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.71',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.041',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.115.181.125',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.7',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.215.149.170',
 'LAST_CHECK_TIME': '18-11-19 22:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.079',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.189',
 'LAST_CHECK_TIME': '18-11-19 22:22',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.204',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.59.193.14',
 'LAST_CHECK_TIME': '18-11-19 22:15',
 'LOCATION': '',
 'PORT': '47138',
 'SPEED': '7.113',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.36.247',
 'LAST_CHECK_TIME': '18-11-19 22:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.609',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.36',
 'LAST_CHECK_TIME': '18-11-19 22:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.768',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.193.214',
 'LAST_CHECK_TIME': '18-11-19 22:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.388',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.45.88.109',
 'LAST_CHECK_TIME': '18-11-20 16:22',
 'LOCATION': '',
 'PORT': '61710',
 'SPEED': '0.842',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.163.152.130',
 'LAST_CHECK_TIME': '18-11-20 16:15',
 'LOCATION': '',
 'PORT': '60596',
 'SPEED': '0.173',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.114',
 'LAST_CHECK_TIME': '18-11-20 16:14',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.179',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.156',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.652',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.223.85.244',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.568',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.155.164',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '3.235',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.170.179.89',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '50799',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.25.206',
 'LAST_CHECK_TIME': '18-11-20 15:55',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.433',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.110.5.254',
 'LAST_CHECK_TIME': '18-11-20 15:45',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.51',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.159.233',
 'LAST_CHECK_TIME': '18-11-20 15:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.323',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.134.204',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.477',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.41.205',
 'LAST_CHECK_TIME': '18-11-19 21:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.818',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '14.204.20.95',
 'LAST_CHECK_TIME': '18-11-19 21:40',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '2.262',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.80.249',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.322',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.249',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '61234',
 'SPEED': '2.87',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.165.77',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.302',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.157.171',
 'LAST_CHECK_TIME': '18-11-19 21:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.97.196',
 'LAST_CHECK_TIME': '18-11-19 21:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.287',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.170.140',
 'LAST_CHECK_TIME': '18-11-19 21:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.2',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.143.219',
 'LAST_CHECK_TIME': '18-11-19 21:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.223',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.230.41.119',
 'LAST_CHECK_TIME': '18-11-19 20:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.317',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.185.5.9',
 'LAST_CHECK_TIME': '18-11-20 14:52',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.118',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '36.48.132.203',
 'LAST_CHECK_TIME': '18-11-20 14:44',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.127',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.90.92',
 'LAST_CHECK_TIME': '18-11-20 14:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.405',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.26.86',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.107',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '6.593',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.138.159.221',
 'LAST_CHECK_TIME': '18-11-20 14:21',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.242',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.91',
 'LAST_CHECK_TIME': '18-11-20 14:20',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.855',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.59.11',
 'LAST_CHECK_TIME': '18-11-20 14:12',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.457',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.17.253.106',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '60004',
 'SPEED': '0.926',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.120.189',
 'LAST_CHECK_TIME': '18-11-19 20:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.676',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.22.102.107',
 'LAST_CHECK_TIME': '18-11-19 19:56',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.389',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.438',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.40.109.154',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '31610',
 'SPEED': '1.458',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.150.73.206',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.214',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.164.118',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.16',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.162.198',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.279',
 'TYPE': 'HTTP'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.75.106',
 'LAST_CHECK_TIME': '18-11-19 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.429',
 'TYPE': 'HTTPS'}
2018-11-22 10:42:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:42:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 233143,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 42, 25, 360691),
 'item_scraped_count': 300,
 'log_count/DEBUG': 304,
 'log_count/INFO': 7,
 'memusage/max': 924295168,
 'memusage/startup': 924295168,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 2, 42, 23, 269806)}
2018-11-22 10:42:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:43:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:43:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:43:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:43:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:43:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:43:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:43:50 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:43:50 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:43:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:43:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:43:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/> (referer: None)
2018-11-22 10:43:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:43:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 211,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 2688,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 43, 51, 414902),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 925523968,
 'memusage/startup': 925523968,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 43, 50, 311849)}
2018-11-22 10:43:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:45:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:45:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:45:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:45:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:45:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:45:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:45:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:45:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:45:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:45:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:45:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:45:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici2.html> (referer: None)
2018-11-22 10:45:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici3.html> (referer: None)
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.16.9',
 'LAST_CHECK_TIME': '18-11-21 02:02',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.146.2.234',
 'LAST_CHECK_TIME': '18-11-21 02:01',
 'LOCATION': '',
 'PORT': '39960',
 'SPEED': '0.243',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '211.147.239.101',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '57281',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.77.156',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.227',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.86.80',
 'LAST_CHECK_TIME': '18-11-21 01:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.466',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.71.15',
 'LAST_CHECK_TIME': '18-11-21 01:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.529',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.169',
 'LAST_CHECK_TIME': '18-11-21 00:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.244',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.17.236.83',
 'LAST_CHECK_TIME': '18-11-21 00:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.347',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.115.49.174',
 'LAST_CHECK_TIME': '18-11-21 00:30',
 'LOCATION': '',
 'PORT': '59216',
 'SPEED': '0.146',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.69.13.242',
 'LAST_CHECK_TIME': '18-11-21 00:23',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '3.461',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.127.93.188',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '57985',
 'SPEED': '4.426',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.253.84.183',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '30071',
 'SPEED': '4.317',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.254',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.718',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '58.62.238.150',
 'LAST_CHECK_TIME': '18-11-21 00:16',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.78.214',
 'LAST_CHECK_TIME': '18-11-21 00:05',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.895',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.86.208.98',
 'LAST_CHECK_TIME': '18-11-21 00:00',
 'LOCATION': '',
 'PORT': '41683',
 'SPEED': '1.181',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.27.43',
 'LAST_CHECK_TIME': '18-11-20 23:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.338',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.218.102.146',
 'LAST_CHECK_TIME': '18-11-20 23:45',
 'LOCATION': '',
 'PORT': '33323',
 'SPEED': '0.019',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.70.66',
 'LAST_CHECK_TIME': '18-11-20 23:41',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.234.181.194',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '33695',
 'SPEED': '3.011',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.81',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.24.16.198',
 'LAST_CHECK_TIME': '18-11-20 23:31',
 'LOCATION': '',
 'PORT': '43620',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.240.224.252',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '33035',
 'SPEED': '0.186',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.224.101.48',
 'LAST_CHECK_TIME': '18-11-20 13:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.088',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.3.170.89',
 'LAST_CHECK_TIME': '18-11-20 13:30',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.85.248',
 'LAST_CHECK_TIME': '18-11-20 13:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.992',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.72.115.59',
 'LAST_CHECK_TIME': '18-11-20 12:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.27',
 'LAST_CHECK_TIME': '18-11-20 12:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.32',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '120.10.25.4',
 'LAST_CHECK_TIME': '18-11-20 12:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.165.131',
 'LAST_CHECK_TIME': '18-11-20 23:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.229',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.165.234',
 'LAST_CHECK_TIME': '18-11-20 23:23',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.819',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.214.180.122',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '33190',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '118.181.226.216',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '36430',
 'SPEED': '0.261',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.80',
 'LAST_CHECK_TIME': '18-11-20 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.473',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.154.99',
 'LAST_CHECK_TIME': '18-11-20 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.3',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.248',
 'LAST_CHECK_TIME': '18-11-20 23:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.597',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.187.206.207',
 'LAST_CHECK_TIME': '18-11-20 22:55',
 'LOCATION': '',
 'PORT': '46693',
 'SPEED': '4.125',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.178.149.237',
 'LAST_CHECK_TIME': '18-11-20 22:40',
 'LOCATION': '',
 'PORT': '59042',
 'SPEED': '1.809',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '49.71.81.165',
 'LAST_CHECK_TIME': '18-11-20 22:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '4.586',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.190',
 'LAST_CHECK_TIME': '18-11-20 22:15',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.78.43.87',
 'LAST_CHECK_TIME': '18-11-20 22:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.142',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.89.33.59',
 'LAST_CHECK_TIME': '18-11-20 21:45',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.11',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.176.186',
 'LAST_CHECK_TIME': '18-11-20 21:44',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.537',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.223.115.30',
 'LAST_CHECK_TIME': '18-11-20 21:22',
 'LOCATION': '',
 'PORT': '51618',
 'SPEED': '0.073',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.122.53',
 'LAST_CHECK_TIME': '18-11-20 12:12',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.912',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.175.218.98',
 'LAST_CHECK_TIME': '18-11-20 12:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.692',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.4.217',
 'LAST_CHECK_TIME': '18-11-20 11:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '2.468',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.156.237',
 'LAST_CHECK_TIME': '18-11-20 11:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.217',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '61.178.127.14',
 'LAST_CHECK_TIME': '18-11-20 11:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.165',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.185.221.142',
 'LAST_CHECK_TIME': '18-11-20 10:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.121',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.25.193',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.558',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.44',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.194',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.59.84.15',
 'LAST_CHECK_TIME': '18-11-20 10:30',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.784',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '49.82.50.36',
 'LAST_CHECK_TIME': '18-11-20 10:21',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '4.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.61.203.134',
 'LAST_CHECK_TIME': '18-11-20 10:15',
 'LOCATION': '',
 'PORT': '51987',
 'SPEED': '0.172',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.178.227.171',
 'LAST_CHECK_TIME': '18-11-20 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.006',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.20',
 'LAST_CHECK_TIME': '18-11-20 09:45',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.25',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.48.51.212',
 'LAST_CHECK_TIME': '18-11-20 09:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.172.191.226',
 'LAST_CHECK_TIME': '18-11-20 09:24',
 'LOCATION': '',
 'PORT': '33384',
 'SPEED': '4.076',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.184.127.79',
 'LAST_CHECK_TIME': '18-11-20 21:17',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.164.78',
 'LAST_CHECK_TIME': '18-11-20 21:16',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.348',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.219.106.147',
 'LAST_CHECK_TIME': '18-11-20 21:10',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.342',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.228.49.232',
 'LAST_CHECK_TIME': '18-11-20 21:02',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.692',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '113.121.243.50',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '38118',
 'SPEED': '1.19',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.154.23',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '0.505',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.183.121.126',
 'LAST_CHECK_TIME': '18-11-20 20:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.081',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.25.163',
 'LAST_CHECK_TIME': '18-11-20 20:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.839',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.91.11',
 'LAST_CHECK_TIME': '18-11-20 20:42',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.427',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.132',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6675',
 'SPEED': '1.199',
 'TYPE': 'socks4/5'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.24.111',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.193',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.10',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.498',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.67.25.83',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '41681',
 'SPEED': '0.342',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.15.202.34',
 'LAST_CHECK_TIME': '18-11-20 20:21',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.104',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.236.98.78',
 'LAST_CHECK_TIME': '18-11-20 20:02',
 'LOCATION': '',
 'PORT': '43682',
 'SPEED': '0.165',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.72.195.140',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.612',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.20',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '5.48',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.228',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.803',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.169.199.126',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.416',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.24.170',
 'LAST_CHECK_TIME': '18-11-20 08:46',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.977',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.186.228',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.735',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.74.147',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.247',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.77.167',
 'LAST_CHECK_TIME': '18-11-20 08:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.215',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.173.72.153',
 'LAST_CHECK_TIME': '18-11-20 08:05',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.165.130.111',
 'LAST_CHECK_TIME': '18-11-20 07:55',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.527',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.104.38',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.781',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.116',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.421',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '113.103.15.139',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.913',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.175.136.195',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '54584',
 'SPEED': '0.187',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.68.115',
 'LAST_CHECK_TIME': '18-11-20 19:50',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.805',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.166.159',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.28',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.156.179',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.467',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.168.136.31',
 'LAST_CHECK_TIME': '18-11-20 19:22',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.184',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.44.62',
 'LAST_CHECK_TIME': '18-11-20 19:21',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.031',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '114.99.167.121',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.599',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.174.225.26',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '60984',
 'SPEED': '0.14',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.161.208',
 'LAST_CHECK_TIME': '18-11-20 19:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.194.214',
 'LAST_CHECK_TIME': '18-11-20 19:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.529',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.254.94.105',
 'LAST_CHECK_TIME': '18-11-20 18:55',
 'LOCATION': '',
 'PORT': '58999',
 'SPEED': '3.252',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.142.132.146',
 'LAST_CHECK_TIME': '18-11-20 18:33',
 'LOCATION': '',
 'PORT': '40655',
 'SPEED': '3.836',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.168.13.26',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '4.068',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '117.21.191.154',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.106.91.58',
 'LAST_CHECK_TIME': '18-11-20 18:22',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.202.216.218',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.18',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.192.216',
 'LAST_CHECK_TIME': '18-11-20 07:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.536',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.55.21.194',
 'LAST_CHECK_TIME': '18-11-20 07:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.224',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.210.133.98',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '32741',
 'SPEED': '0.214',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.18.115',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.176.36.251',
 'LAST_CHECK_TIME': '18-11-20 07:01',
 'LOCATION': '',
 'PORT': '37000',
 'SPEED': '0.357',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '106.14.214.94',
 'LAST_CHECK_TIME': '18-11-20 06:56',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.104',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.157.174.133',
 'LAST_CHECK_TIME': '18-11-20 06:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.39',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.17.236.52',
 'LAST_CHECK_TIME': '18-11-20 06:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.802',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '222.182.56.218',
 'LAST_CHECK_TIME': '18-11-20 03:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.113.27.170',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '47849',
 'SPEED': '0.094',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.119.65.16',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '39.76.14.191',
 'LAST_CHECK_TIME': '18-11-20 03:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.635',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.61',
 'LAST_CHECK_TIME': '18-11-20 02:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '1.189',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.202',
 'LAST_CHECK_TIME': '18-11-20 02:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.823',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.25.124',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.925',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.143.180',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '7.255',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.235.135.210',
 'LAST_CHECK_TIME': '18-11-20 17:50',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '3.855',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.57.214',
 'LAST_CHECK_TIME': '18-11-20 17:45',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.24.153',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.156',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.42',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.99.133.223',
 'LAST_CHECK_TIME': '18-11-20 17:06',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.212',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.147.198',
 'LAST_CHECK_TIME': '18-11-20 17:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '1.842',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.150.45',
 'LAST_CHECK_TIME': '18-11-20 16:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.873',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.45.88.109',
 'LAST_CHECK_TIME': '18-11-20 16:22',
 'LOCATION': '',
 'PORT': '61710',
 'SPEED': '0.842',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.163.152.130',
 'LAST_CHECK_TIME': '18-11-20 16:15',
 'LOCATION': '',
 'PORT': '60596',
 'SPEED': '0.173',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.114',
 'LAST_CHECK_TIME': '18-11-20 16:14',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.179',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.156',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.652',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.223.85.244',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.568',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.155.164',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '3.235',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.170.179.89',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '50799',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.43',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.501',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '36.33.32.158',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '59019',
 'SPEED': '0.205',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.54',
 'LAST_CHECK_TIME': '18-11-20 02:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.845',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.77.72',
 'LAST_CHECK_TIME': '18-11-20 01:52',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.577',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.64.130',
 'LAST_CHECK_TIME': '18-11-20 01:46',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.816',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.148.79.233',
 'LAST_CHECK_TIME': '18-11-20 01:44',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.246',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '220.173.106.168',
 'LAST_CHECK_TIME': '18-11-20 01:38',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.284',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.194.141',
 'LAST_CHECK_TIME': '18-11-20 01:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.641',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.162.208',
 'LAST_CHECK_TIME': '18-11-20 01:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.568',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.228.49.227',
 'LAST_CHECK_TIME': '18-11-20 01:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.85',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.107.144',
 'LAST_CHECK_TIME': '18-11-20 00:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.783',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.78.41',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.039',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.219',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.876',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.153.165',
 'LAST_CHECK_TIME': '18-11-20 00:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.234',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.25.206',
 'LAST_CHECK_TIME': '18-11-20 15:55',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.433',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.110.5.254',
 'LAST_CHECK_TIME': '18-11-20 15:45',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.51',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.159.233',
 'LAST_CHECK_TIME': '18-11-20 15:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.323',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.134.204',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.477',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.249',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '61234',
 'SPEED': '2.87',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.185.5.9',
 'LAST_CHECK_TIME': '18-11-20 14:52',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.118',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '36.48.132.203',
 'LAST_CHECK_TIME': '18-11-20 14:44',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.127',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.90.92',
 'LAST_CHECK_TIME': '18-11-20 14:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.405',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.26.86',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.107',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '6.593',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.138.159.221',
 'LAST_CHECK_TIME': '18-11-20 14:21',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.242',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.91',
 'LAST_CHECK_TIME': '18-11-20 14:20',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.855',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.59.11',
 'LAST_CHECK_TIME': '18-11-20 14:12',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.457',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.79.224',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.553',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.32.37.229',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.208',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.190.95.35',
 'LAST_CHECK_TIME': '18-11-19 23:51',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.052',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.2',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.827',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '119.1.97.193',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '60916',
 'SPEED': '0.398',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.138.140',
 'LAST_CHECK_TIME': '18-11-19 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.226',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.100',
 'LAST_CHECK_TIME': '18-11-19 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.91',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.64.78',
 'LAST_CHECK_TIME': '18-11-19 23:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.026',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '101.236.54.166',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.02',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '223.203.0.14',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.025',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.99.255.28',
 'LAST_CHECK_TIME': '18-11-19 22:46',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.133',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.68.73',
 'LAST_CHECK_TIME': '18-11-19 22:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.584',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.213.234',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.387',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.71',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.041',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.17.253.106',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '60004',
 'SPEED': '0.926',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.438',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.40.109.154',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '31610',
 'SPEED': '1.458',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.150.73.206',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.214',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.115.181.125',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.7',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.215.149.170',
 'LAST_CHECK_TIME': '18-11-19 22:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.079',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.189',
 'LAST_CHECK_TIME': '18-11-19 22:22',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.204',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.59.193.14',
 'LAST_CHECK_TIME': '18-11-19 22:15',
 'LOCATION': '',
 'PORT': '47138',
 'SPEED': '7.113',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.36.247',
 'LAST_CHECK_TIME': '18-11-19 22:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.609',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.36',
 'LAST_CHECK_TIME': '18-11-19 22:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.768',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.193.214',
 'LAST_CHECK_TIME': '18-11-19 22:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.388',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.41.205',
 'LAST_CHECK_TIME': '18-11-19 21:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.818',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '14.204.20.95',
 'LAST_CHECK_TIME': '18-11-19 21:40',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '2.262',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.80.249',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.322',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.165.77',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.302',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.157.171',
 'LAST_CHECK_TIME': '18-11-19 21:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.97.196',
 'LAST_CHECK_TIME': '18-11-19 21:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.287',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.170.140',
 'LAST_CHECK_TIME': '18-11-19 21:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.2',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.143.219',
 'LAST_CHECK_TIME': '18-11-19 21:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.223',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.230.41.119',
 'LAST_CHECK_TIME': '18-11-19 20:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.317',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.120.189',
 'LAST_CHECK_TIME': '18-11-19 20:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.676',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.22.102.107',
 'LAST_CHECK_TIME': '18-11-19 19:56',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.389',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.164.118',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.16',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.162.198',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.279',
 'TYPE': 'HTTP'}
2018-11-22 10:45:44 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.75.106',
 'LAST_CHECK_TIME': '18-11-19 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.429',
 'TYPE': 'HTTPS'}
2018-11-22 10:45:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:45:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 233143,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 45, 44, 292682),
 'item_scraped_count': 300,
 'log_count/DEBUG': 304,
 'log_count/INFO': 7,
 'memusage/max': 964014080,
 'memusage/startup': 964014080,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 2, 45, 43, 943095)}
2018-11-22 10:45:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:48:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:48:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:48:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:48:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:48:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:48:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:48:52 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:48:52 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:48:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:48:52 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:48:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-22 10:48:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici2.html> (referer: None)
2018-11-22 10:48:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici3.html> (referer: None)
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.16.9',
 'LAST_CHECK_TIME': '18-11-21 02:02',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.240.224.252',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '33035',
 'SPEED': '0.186',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.224.101.48',
 'LAST_CHECK_TIME': '18-11-20 13:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.088',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.3.170.89',
 'LAST_CHECK_TIME': '18-11-20 13:30',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.85.248',
 'LAST_CHECK_TIME': '18-11-20 13:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.992',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.72.115.59',
 'LAST_CHECK_TIME': '18-11-20 12:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.27',
 'LAST_CHECK_TIME': '18-11-20 12:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.32',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.146.2.234',
 'LAST_CHECK_TIME': '18-11-21 02:01',
 'LOCATION': '',
 'PORT': '39960',
 'SPEED': '0.243',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '211.147.239.101',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '57281',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.77.156',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.227',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.86.80',
 'LAST_CHECK_TIME': '18-11-21 01:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.466',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.71.15',
 'LAST_CHECK_TIME': '18-11-21 01:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.529',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.169',
 'LAST_CHECK_TIME': '18-11-21 00:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.244',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.17.236.83',
 'LAST_CHECK_TIME': '18-11-21 00:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.347',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.115.49.174',
 'LAST_CHECK_TIME': '18-11-21 00:30',
 'LOCATION': '',
 'PORT': '59216',
 'SPEED': '0.146',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.69.13.242',
 'LAST_CHECK_TIME': '18-11-21 00:23',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '3.461',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.127.93.188',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '57985',
 'SPEED': '4.426',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.253.84.183',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '30071',
 'SPEED': '4.317',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.254',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.718',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '58.62.238.150',
 'LAST_CHECK_TIME': '18-11-21 00:16',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.78.214',
 'LAST_CHECK_TIME': '18-11-21 00:05',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.895',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '120.10.25.4',
 'LAST_CHECK_TIME': '18-11-20 12:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.122.53',
 'LAST_CHECK_TIME': '18-11-20 12:12',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.912',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.175.218.98',
 'LAST_CHECK_TIME': '18-11-20 12:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.692',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.4.217',
 'LAST_CHECK_TIME': '18-11-20 11:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '2.468',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.156.237',
 'LAST_CHECK_TIME': '18-11-20 11:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.217',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '61.178.127.14',
 'LAST_CHECK_TIME': '18-11-20 11:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.165',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.185.221.142',
 'LAST_CHECK_TIME': '18-11-20 10:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.121',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.25.193',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.558',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.44',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.194',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.59.84.15',
 'LAST_CHECK_TIME': '18-11-20 10:30',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.784',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '49.82.50.36',
 'LAST_CHECK_TIME': '18-11-20 10:21',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '4.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.61.203.134',
 'LAST_CHECK_TIME': '18-11-20 10:15',
 'LOCATION': '',
 'PORT': '51987',
 'SPEED': '0.172',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.86.208.98',
 'LAST_CHECK_TIME': '18-11-21 00:00',
 'LOCATION': '',
 'PORT': '41683',
 'SPEED': '1.181',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.27.43',
 'LAST_CHECK_TIME': '18-11-20 23:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.338',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.218.102.146',
 'LAST_CHECK_TIME': '18-11-20 23:45',
 'LOCATION': '',
 'PORT': '33323',
 'SPEED': '0.019',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.70.66',
 'LAST_CHECK_TIME': '18-11-20 23:41',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.234.181.194',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '33695',
 'SPEED': '3.011',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.81',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.24.16.198',
 'LAST_CHECK_TIME': '18-11-20 23:31',
 'LOCATION': '',
 'PORT': '43620',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.165.131',
 'LAST_CHECK_TIME': '18-11-20 23:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.229',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.165.234',
 'LAST_CHECK_TIME': '18-11-20 23:23',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.819',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.214.180.122',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '33190',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '118.181.226.216',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '36430',
 'SPEED': '0.261',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.80',
 'LAST_CHECK_TIME': '18-11-20 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.473',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.154.99',
 'LAST_CHECK_TIME': '18-11-20 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.3',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.248',
 'LAST_CHECK_TIME': '18-11-20 23:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.597',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.178.227.171',
 'LAST_CHECK_TIME': '18-11-20 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.006',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.20',
 'LAST_CHECK_TIME': '18-11-20 09:45',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.25',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.48.51.212',
 'LAST_CHECK_TIME': '18-11-20 09:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.172.191.226',
 'LAST_CHECK_TIME': '18-11-20 09:24',
 'LOCATION': '',
 'PORT': '33384',
 'SPEED': '4.076',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.72.195.140',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.612',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.20',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '5.48',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.228',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.803',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.169.199.126',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.416',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.24.170',
 'LAST_CHECK_TIME': '18-11-20 08:46',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.977',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.186.228',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.735',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.74.147',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.247',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.77.167',
 'LAST_CHECK_TIME': '18-11-20 08:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.215',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.173.72.153',
 'LAST_CHECK_TIME': '18-11-20 08:05',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.165.130.111',
 'LAST_CHECK_TIME': '18-11-20 07:55',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.527',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.187.206.207',
 'LAST_CHECK_TIME': '18-11-20 22:55',
 'LOCATION': '',
 'PORT': '46693',
 'SPEED': '4.125',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.178.149.237',
 'LAST_CHECK_TIME': '18-11-20 22:40',
 'LOCATION': '',
 'PORT': '59042',
 'SPEED': '1.809',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '49.71.81.165',
 'LAST_CHECK_TIME': '18-11-20 22:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '4.586',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.190',
 'LAST_CHECK_TIME': '18-11-20 22:15',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.78.43.87',
 'LAST_CHECK_TIME': '18-11-20 22:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.142',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.89.33.59',
 'LAST_CHECK_TIME': '18-11-20 21:45',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.11',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.176.186',
 'LAST_CHECK_TIME': '18-11-20 21:44',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.537',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.223.115.30',
 'LAST_CHECK_TIME': '18-11-20 21:22',
 'LOCATION': '',
 'PORT': '51618',
 'SPEED': '0.073',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.184.127.79',
 'LAST_CHECK_TIME': '18-11-20 21:17',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.164.78',
 'LAST_CHECK_TIME': '18-11-20 21:16',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.348',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.219.106.147',
 'LAST_CHECK_TIME': '18-11-20 21:10',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.342',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.228.49.232',
 'LAST_CHECK_TIME': '18-11-20 21:02',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.692',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '113.121.243.50',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '38118',
 'SPEED': '1.19',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.154.23',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '0.505',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.104.38',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.781',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.116',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.421',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '113.103.15.139',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.913',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.175.136.195',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '54584',
 'SPEED': '0.187',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.192.216',
 'LAST_CHECK_TIME': '18-11-20 07:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.536',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.55.21.194',
 'LAST_CHECK_TIME': '18-11-20 07:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.224',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.210.133.98',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '32741',
 'SPEED': '0.214',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.18.115',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.176.36.251',
 'LAST_CHECK_TIME': '18-11-20 07:01',
 'LOCATION': '',
 'PORT': '37000',
 'SPEED': '0.357',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '106.14.214.94',
 'LAST_CHECK_TIME': '18-11-20 06:56',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.104',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.157.174.133',
 'LAST_CHECK_TIME': '18-11-20 06:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.39',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.17.236.52',
 'LAST_CHECK_TIME': '18-11-20 06:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.802',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '222.182.56.218',
 'LAST_CHECK_TIME': '18-11-20 03:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.113.27.170',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '47849',
 'SPEED': '0.094',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.183.121.126',
 'LAST_CHECK_TIME': '18-11-20 20:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.081',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.25.163',
 'LAST_CHECK_TIME': '18-11-20 20:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.839',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.91.11',
 'LAST_CHECK_TIME': '18-11-20 20:42',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.427',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.132',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6675',
 'SPEED': '1.199',
 'TYPE': 'socks4/5'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.24.111',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.193',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.10',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.498',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.67.25.83',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '41681',
 'SPEED': '0.342',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.15.202.34',
 'LAST_CHECK_TIME': '18-11-20 20:21',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.104',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.236.98.78',
 'LAST_CHECK_TIME': '18-11-20 20:02',
 'LOCATION': '',
 'PORT': '43682',
 'SPEED': '0.165',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.68.115',
 'LAST_CHECK_TIME': '18-11-20 19:50',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.805',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.166.159',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.28',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.156.179',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.467',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.168.136.31',
 'LAST_CHECK_TIME': '18-11-20 19:22',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.184',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.44.62',
 'LAST_CHECK_TIME': '18-11-20 19:21',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.031',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.119.65.16',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '39.76.14.191',
 'LAST_CHECK_TIME': '18-11-20 03:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.635',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.61',
 'LAST_CHECK_TIME': '18-11-20 02:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '1.189',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.202',
 'LAST_CHECK_TIME': '18-11-20 02:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.823',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.25.124',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.925',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.43',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.501',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '36.33.32.158',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '59019',
 'SPEED': '0.205',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.54',
 'LAST_CHECK_TIME': '18-11-20 02:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.845',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.77.72',
 'LAST_CHECK_TIME': '18-11-20 01:52',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.577',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.64.130',
 'LAST_CHECK_TIME': '18-11-20 01:46',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.816',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.148.79.233',
 'LAST_CHECK_TIME': '18-11-20 01:44',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.246',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '220.173.106.168',
 'LAST_CHECK_TIME': '18-11-20 01:38',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.284',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.194.141',
 'LAST_CHECK_TIME': '18-11-20 01:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.641',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '114.99.167.121',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.599',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.174.225.26',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '60984',
 'SPEED': '0.14',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.161.208',
 'LAST_CHECK_TIME': '18-11-20 19:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.194.214',
 'LAST_CHECK_TIME': '18-11-20 19:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.529',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.254.94.105',
 'LAST_CHECK_TIME': '18-11-20 18:55',
 'LOCATION': '',
 'PORT': '58999',
 'SPEED': '3.252',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.142.132.146',
 'LAST_CHECK_TIME': '18-11-20 18:33',
 'LOCATION': '',
 'PORT': '40655',
 'SPEED': '3.836',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.168.13.26',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '4.068',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '117.21.191.154',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.106.91.58',
 'LAST_CHECK_TIME': '18-11-20 18:22',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.202.216.218',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.18',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.143.180',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '7.255',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.235.135.210',
 'LAST_CHECK_TIME': '18-11-20 17:50',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '3.855',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.57.214',
 'LAST_CHECK_TIME': '18-11-20 17:45',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.24.153',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.156',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.162.208',
 'LAST_CHECK_TIME': '18-11-20 01:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.568',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.228.49.227',
 'LAST_CHECK_TIME': '18-11-20 01:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.85',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.107.144',
 'LAST_CHECK_TIME': '18-11-20 00:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.783',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.78.41',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.039',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.219',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.876',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.153.165',
 'LAST_CHECK_TIME': '18-11-20 00:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.234',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.79.224',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.553',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.32.37.229',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.208',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.190.95.35',
 'LAST_CHECK_TIME': '18-11-19 23:51',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.052',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.2',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.827',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '119.1.97.193',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '60916',
 'SPEED': '0.398',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.138.140',
 'LAST_CHECK_TIME': '18-11-19 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.226',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.100',
 'LAST_CHECK_TIME': '18-11-19 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.91',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.64.78',
 'LAST_CHECK_TIME': '18-11-19 23:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.026',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.42',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.99.133.223',
 'LAST_CHECK_TIME': '18-11-20 17:06',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.212',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.147.198',
 'LAST_CHECK_TIME': '18-11-20 17:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '1.842',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.150.45',
 'LAST_CHECK_TIME': '18-11-20 16:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.873',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.45.88.109',
 'LAST_CHECK_TIME': '18-11-20 16:22',
 'LOCATION': '',
 'PORT': '61710',
 'SPEED': '0.842',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.163.152.130',
 'LAST_CHECK_TIME': '18-11-20 16:15',
 'LOCATION': '',
 'PORT': '60596',
 'SPEED': '0.173',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.114',
 'LAST_CHECK_TIME': '18-11-20 16:14',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.179',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.156',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.652',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.223.85.244',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.568',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.155.164',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '3.235',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.170.179.89',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '50799',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.25.206',
 'LAST_CHECK_TIME': '18-11-20 15:55',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.433',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.110.5.254',
 'LAST_CHECK_TIME': '18-11-20 15:45',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.51',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.159.233',
 'LAST_CHECK_TIME': '18-11-20 15:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.323',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '101.236.54.166',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.02',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '223.203.0.14',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.025',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.99.255.28',
 'LAST_CHECK_TIME': '18-11-19 22:46',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.133',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.68.73',
 'LAST_CHECK_TIME': '18-11-19 22:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.584',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.213.234',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.387',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.71',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.041',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.115.181.125',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.7',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.215.149.170',
 'LAST_CHECK_TIME': '18-11-19 22:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.079',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.189',
 'LAST_CHECK_TIME': '18-11-19 22:22',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.204',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.59.193.14',
 'LAST_CHECK_TIME': '18-11-19 22:15',
 'LOCATION': '',
 'PORT': '47138',
 'SPEED': '7.113',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.36.247',
 'LAST_CHECK_TIME': '18-11-19 22:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.609',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.36',
 'LAST_CHECK_TIME': '18-11-19 22:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.768',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.193.214',
 'LAST_CHECK_TIME': '18-11-19 22:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.388',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.134.204',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.477',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.249',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '61234',
 'SPEED': '2.87',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.185.5.9',
 'LAST_CHECK_TIME': '18-11-20 14:52',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.118',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '36.48.132.203',
 'LAST_CHECK_TIME': '18-11-20 14:44',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.127',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.90.92',
 'LAST_CHECK_TIME': '18-11-20 14:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.405',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.26.86',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.107',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '6.593',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.138.159.221',
 'LAST_CHECK_TIME': '18-11-20 14:21',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.242',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.91',
 'LAST_CHECK_TIME': '18-11-20 14:20',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.855',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.59.11',
 'LAST_CHECK_TIME': '18-11-20 14:12',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.457',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.17.253.106',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '60004',
 'SPEED': '0.926',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.438',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.41.205',
 'LAST_CHECK_TIME': '18-11-19 21:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.818',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '14.204.20.95',
 'LAST_CHECK_TIME': '18-11-19 21:40',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '2.262',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.80.249',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.322',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.165.77',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.302',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.157.171',
 'LAST_CHECK_TIME': '18-11-19 21:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.97.196',
 'LAST_CHECK_TIME': '18-11-19 21:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.287',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.170.140',
 'LAST_CHECK_TIME': '18-11-19 21:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.2',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.143.219',
 'LAST_CHECK_TIME': '18-11-19 21:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.223',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.230.41.119',
 'LAST_CHECK_TIME': '18-11-19 20:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.317',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.120.189',
 'LAST_CHECK_TIME': '18-11-19 20:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.676',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.22.102.107',
 'LAST_CHECK_TIME': '18-11-19 19:56',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.389',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.164.118',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.16',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.40.109.154',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '31610',
 'SPEED': '1.458',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.150.73.206',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.214',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.162.198',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.279',
 'TYPE': 'HTTP'}
2018-11-22 10:48:52 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.75.106',
 'LAST_CHECK_TIME': '18-11-19 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.429',
 'TYPE': 'HTTPS'}
2018-11-22 10:48:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:48:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 233143,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 48, 52, 852291),
 'item_scraped_count': 300,
 'log_count/DEBUG': 304,
 'log_count/INFO': 7,
 'memusage/max': 974528512,
 'memusage/startup': 974528512,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 2, 48, 52, 466863)}
2018-11-22 10:48:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:49:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 10:49:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 10:49:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 10:49:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:49:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:49:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:49:09 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 10:49:09 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:49:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:49:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 10:49:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/> (referer: None)
2018-11-22 10:49:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:49:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 211,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 2688,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 49, 10, 620885),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 978169856,
 'memusage/startup': 978169856,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 2, 49, 9, 322024)}
2018-11-22 10:49:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:23:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:23:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:23:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:23:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:23:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:23:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:23:37 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:23:37 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:23:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:23:37 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:23:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:23:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 23, 37, 495008),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1002336256,
 'memusage/startup': 1002336256,
 'start_time': datetime.datetime(2018, 11, 22, 3, 23, 37, 490373)}
2018-11-22 11:23:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:24:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:24:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:24:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:24:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:24:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:24:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:24:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:24:34 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:24:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:24:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:24:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:24:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 24, 34, 283714),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1004621824,
 'memusage/startup': 1004621824,
 'start_time': datetime.datetime(2018, 11, 22, 3, 24, 34, 278479)}
2018-11-22 11:24:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:29:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:29:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:29:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:29:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:29:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:29:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:29:33 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:29:33 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:29:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:29:33 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:29:33 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f8b771bb940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:29:33 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:29:38 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f8b771bb940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:29:38 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:29:43 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f8b771bb940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:29:43 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:29:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:29:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 29, 48, 717764),
 'log_count/CRITICAL': 3,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 3,
 'log_count/INFO': 7,
 'memusage/max': 1007927296,
 'memusage/startup': 1007927296,
 'start_time': datetime.datetime(2018, 11, 22, 3, 29, 33, 712036)}
2018-11-22 11:29:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:33:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:33:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:33:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:33:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:33:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:33:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:33:05 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:33:05 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:33:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:33:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:33:05 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7fcb76c337f0>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:33:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:33:10 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7fcb76c337f0>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:33:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:33:15 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7fcb76c337f0>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:33:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:33:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:33:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 33, 20, 207184),
 'log_count/CRITICAL': 3,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 3,
 'log_count/INFO': 7,
 'memusage/max': 1011068928,
 'memusage/startup': 1011068928,
 'start_time': datetime.datetime(2018, 11, 22, 3, 33, 5, 201516)}
2018-11-22 11:33:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:33:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:33:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:33:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:33:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:33:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:33:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:33:32 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:33:32 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:33:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:33:32 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:33:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:33:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 33, 32, 810286),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1013657600,
 'memusage/startup': 1013657600,
 'start_time': datetime.datetime(2018, 11, 22, 3, 33, 32, 803833)}
2018-11-22 11:33:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:33:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:33:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:33:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:33:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:33:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:33:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:33:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:33:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:33:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:33:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:33:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:33:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 33, 55, 165199),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1014841344,
 'memusage/startup': 1014841344,
 'start_time': datetime.datetime(2018, 11, 22, 3, 33, 55, 158695)}
2018-11-22 11:33:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:34:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:34:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:34:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:34:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:34:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:34:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:34:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:34:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:34:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:34:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:34:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:34:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 34, 43, 612627),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1016000512,
 'memusage/startup': 1016000512,
 'start_time': datetime.datetime(2018, 11, 22, 3, 34, 43, 606345)}
2018-11-22 11:34:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:34:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:34:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:34:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:34:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:34:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:34:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:34:50 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:34:50 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:34:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:34:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:34:50 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f1022c78898>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:34:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:34:55 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f1022c78898>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:34:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:35:00 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f1022c78898>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:35:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:35:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:35:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 35, 5, 164210),
 'log_count/CRITICAL': 3,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 3,
 'log_count/INFO': 7,
 'memusage/max': 1016815616,
 'memusage/startup': 1016815616,
 'start_time': datetime.datetime(2018, 11, 22, 3, 34, 50, 159736)}
2018-11-22 11:35:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:35:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:35:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:35:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:35:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:35:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:35:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:35:46 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:35:46 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:35:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:35:46 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:35:46 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f90e0963898>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:35:46 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:35:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f90e0963898>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:35:51 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:35:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f90e0963898>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:35:56 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:36:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:36:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 36, 1, 483575),
 'log_count/CRITICAL': 3,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 3,
 'log_count/INFO': 7,
 'memusage/max': 1016979456,
 'memusage/startup': 1016979456,
 'start_time': datetime.datetime(2018, 11, 22, 3, 35, 46, 479422)}
2018-11-22 11:36:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:37:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:37:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:37:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:37:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:37:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:37:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:37:11 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:37:11 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:37:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:37:11 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:37:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:37:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 37, 11, 772113),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1017458688,
 'memusage/startup': 1017458688,
 'start_time': datetime.datetime(2018, 11, 22, 3, 37, 11, 767616)}
2018-11-22 11:37:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:37:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:37:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:37:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:37:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:37:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:37:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:37:19 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:37:19 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:37:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:37:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:37:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 37, 19, 56126),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1018454016,
 'memusage/startup': 1018454016,
 'start_time': datetime.datetime(2018, 11, 22, 3, 37, 19, 51600)}
2018-11-22 11:37:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:38:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:38:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:38:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:38:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:38:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:38:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:38:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:38:51 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:38:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:38:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:38:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:38:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 38, 51, 222648),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1022357504,
 'memusage/startup': 1022357504,
 'start_time': datetime.datetime(2018, 11, 22, 3, 38, 51, 218032)}
2018-11-22 11:38:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:39:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:39:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:39:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:39:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:39:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:39:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:39:03 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:39:03 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:39:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:39:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:39:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:39:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 39, 3, 53727),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1022443520,
 'memusage/startup': 1022443520,
 'start_time': datetime.datetime(2018, 11, 22, 3, 39, 3, 49251)}
2018-11-22 11:39:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:40:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:40:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:40:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:40:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:40:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:40:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:40:37 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:40:37 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:40:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:40:37 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:40:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:40:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 40, 37, 407635),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1022775296,
 'memusage/startup': 1022775296,
 'start_time': datetime.datetime(2018, 11, 22, 3, 40, 37, 392007)}
2018-11-22 11:40:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:40:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:40:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:40:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:40:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:40:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:40:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:40:47 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:40:47 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:40:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:40:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:40:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:40:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 40, 47, 147173),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1023041536,
 'memusage/startup': 1023041536,
 'start_time': datetime.datetime(2018, 11, 22, 3, 40, 47, 142418)}
2018-11-22 11:40:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:41:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:41:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:41:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:41:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:41:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:41:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:41:09 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:41:09 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:41:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:41:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:41:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:41:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 41, 9, 885978),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'memusage/max': 1023209472,
 'memusage/startup': 1023209472,
 'start_time': datetime.datetime(2018, 11, 22, 3, 41, 9, 881395)}
2018-11-22 11:41:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:41:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:41:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:41:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:41:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:41:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:41:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:41:41 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:41:41 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:41:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:41:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:41:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f4f42b51940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:41:41 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:41:46 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f4f42b51940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:41:46 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:41:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f4f42b51940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:41:51 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:41:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:41:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 41, 56, 777615),
 'log_count/CRITICAL': 3,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 3,
 'log_count/INFO': 7,
 'memusage/max': 1023496192,
 'memusage/startup': 1023496192,
 'start_time': datetime.datetime(2018, 11, 22, 3, 41, 41, 770279)}
2018-11-22 11:41:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:44:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:44:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:44:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:44:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:44:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:44:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:44:35 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:44:35 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:44:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:44:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:44:35 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f629d912940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:44:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:44:40 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f629d912940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:44:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:44:45 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method RefererMiddleware.request_scheduled of <scrapy.spidermiddlewares.referer.RefererMiddleware object at 0x7f629d912940>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/signal.py", line 30, in send_catch_log
    *arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spidermiddlewares/referer.py", line 343, in request_scheduled
    redirected_urls = request.meta.get('redirect_urls', [])
AttributeError: 'str' object has no attribute 'meta'
2018-11-22 11:44:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1267, in run
    self.mainLoop()
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 135, in _next_request
    self.crawl(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/scheduler.py", line 54, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
builtins.AttributeError: 'str' object has no attribute 'dont_filter'

2018-11-22 11:44:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:44:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 44, 50, 864898),
 'log_count/CRITICAL': 3,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 3,
 'log_count/INFO': 7,
 'memusage/max': 1025998848,
 'memusage/startup': 1025998848,
 'start_time': datetime.datetime(2018, 11, 22, 3, 44, 35, 859358)}
2018-11-22 11:44:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:46:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:46:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:46:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:46:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:46:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:46:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:46:01 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:46:01 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:46:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:46:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:46:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-22 11:46:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-22 11:46:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-22 11:46:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:46:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 702,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 10748,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 46, 3, 868041),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 1027141632,
 'memusage/startup': 1027141632,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 3, 46, 1, 737820)}
2018-11-22 11:46:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:53:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:53:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:53:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:53:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:53:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:53:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:53:24 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:53:24 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:53:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:53:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:53:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 11:53:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:53:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 53, 24, 994130),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1032110080,
 'memusage/startup': 1032110080,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 3, 53, 24, 880866)}
2018-11-22 11:53:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:53:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:53:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:53:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:53:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:53:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:53:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:53:31 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:53:31 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:53:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:53:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:53:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 11:53:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl2.html> (referer: None)
2018-11-22 11:53:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl3.html> (referer: None)
2018-11-22 11:53:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:53:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 696,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 34976,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 53, 31, 734882),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 1034268672,
 'memusage/startup': 1034268672,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 3, 53, 31, 615059)}
2018-11-22 11:53:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:53:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 11:53:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 11:53:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 11:53:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:53:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:53:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:53:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 11:53:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:53:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:53:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 11:53:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 11:53:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:53:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 53, 48, 377854),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1045585920,
 'memusage/startup': 1045585920,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 3, 53, 48, 265441)}
2018-11-22 11:53:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:29:16 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:29:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:29:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:29:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:29:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:29:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:29:16 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:29:16 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:29:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:29:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:29:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:29:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:29:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 29, 17, 108144),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1045585920,
 'memusage/startup': 1045585920,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 29, 16, 997163)}
2018-11-22 13:29:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:29:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:29:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:29:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:29:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:29:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:29:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:29:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:29:30 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:29:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:29:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:29:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:29:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:29:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 29, 31, 91154),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1046216704,
 'memusage/startup': 1046216704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 29, 30, 974449)}
2018-11-22 13:29:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:29:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:29:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:29:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:29:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:29:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:29:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:29:47 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:29:47 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:29:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:29:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:29:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:29:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:29:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 29, 47, 587441),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1046425600,
 'memusage/startup': 1046425600,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 29, 47, 472046)}
2018-11-22 13:29:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:30:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:30:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:30:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:30:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:30:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:30:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:30:50 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:30:50 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:30:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:30:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:30:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:30:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 30, 50, 552242),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1046700032,
 'memusage/startup': 1046700032,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 30, 50, 437092)}
2018-11-22 13:30:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:31:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:31:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:31:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:31:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:31:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:31:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:31:58 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:31:58 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:31:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:31:58 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:31:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:31:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 31, 58, 352187),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1047126016,
 'memusage/startup': 1047126016,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 31, 58, 236289)}
2018-11-22 13:31:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:32:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:32:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:32:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:32:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:32:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:32:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:32:10 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:32:10 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:32:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:32:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:32:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:32:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 32, 10, 432747),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1047244800,
 'memusage/startup': 1047244800,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 32, 10, 316805)}
2018-11-22 13:32:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:32:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:32:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:32:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:32:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:32:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:32:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:32:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:32:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:32:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:32:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:32:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:32:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 32, 55, 127862),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1047244800,
 'memusage/startup': 1047244800,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 32, 55, 17812)}
2018-11-22 13:32:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:33:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:33:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:33:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:33:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:33:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:33:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:33:36 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:33:36 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:33:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:33:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:33:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:33:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 33, 36, 893659),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1048248320,
 'memusage/startup': 1048248320,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 33, 36, 778852)}
2018-11-22 13:33:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:33:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:33:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:33:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:33:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:33:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:33:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:33:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:33:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:33:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:33:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:33:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:33:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 33, 48, 678168),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1048879104,
 'memusage/startup': 1048879104,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 33, 48, 564264)}
2018-11-22 13:33:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:34:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:34:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:34:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:34:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:34:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:34:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:34:02 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:34:02 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:34:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:34:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:34:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:34:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 34, 2, 269704),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1049182208,
 'memusage/startup': 1049182208,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 34, 2, 154837)}
2018-11-22 13:34:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:34:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:34:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:34:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:34:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:34:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:34:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:34:25 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:34:25 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:34:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:34:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:34:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:34:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 34, 25, 181731),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1050226688,
 'memusage/startup': 1050226688,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 34, 25, 65946)}
2018-11-22 13:34:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:35:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:35:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:35:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:35:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:35:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:35:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:35:01 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:35:01 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:35:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:35:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:35:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:35:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 35, 1, 574668),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1050394624,
 'memusage/startup': 1050394624,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 35, 1, 458962)}
2018-11-22 13:35:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:37:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:37:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:37:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:37:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:37:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:37:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:37:23 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:37:23 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:37:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:37:23 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:37:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:37:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:37:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 37, 23, 161673),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1051189248,
 'memusage/startup': 1051189248,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 37, 23, 46571)}
2018-11-22 13:37:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:37:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:37:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:37:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:37:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:37:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:37:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:37:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:37:51 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:37:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:37:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:37:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:37:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 37, 51, 910355),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1051336704,
 'memusage/startup': 1051336704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 37, 51, 795619)}
2018-11-22 13:37:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:41:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:41:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:41:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:41:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:41:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:41:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:41:10 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:41:10 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:41:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:41:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:41:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:41:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:41:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 41, 10, 927831),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1051721728,
 'memusage/startup': 1051721728,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 41, 10, 812653)}
2018-11-22 13:41:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:41:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:41:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:41:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:41:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:41:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:41:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:41:44 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:41:44 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:41:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:41:44 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:41:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:41:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 41, 44, 281810),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1051721728,
 'memusage/startup': 1051721728,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 41, 44, 166568)}
2018-11-22 13:41:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:42:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:42:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:42:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:42:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:42:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:42:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:42:22 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:42:22 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:42:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:42:22 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:42:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:42:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:42:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 42, 22, 834629),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1051766784,
 'memusage/startup': 1051766784,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 42, 22, 719822)}
2018-11-22 13:42:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:42:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:42:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:42:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:42:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:42:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:42:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:42:35 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:42:35 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:42:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:42:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:42:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:42:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl2.html> (referer: None)
2018-11-22 13:42:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl3.html> (referer: None)
2018-11-22 13:42:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:42:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 696,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 34976,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 42, 36, 5730),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 1051774976,
 'memusage/startup': 1051774976,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 5, 42, 35, 878972)}
2018-11-22 13:42:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:42:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:42:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:42:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:42:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:42:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:42:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:42:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:42:51 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:42:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:42:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:42:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:42:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl2.html> (referer: None)
2018-11-22 13:42:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl3.html> (referer: None)
2018-11-22 13:42:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:42:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 696,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 34976,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 42, 51, 254895),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 1051774976,
 'memusage/startup': 1051774976,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 5, 42, 51, 128774)}
2018-11-22 13:42:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:43:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:43:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:43:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:43:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:43:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:43:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:43:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:43:30 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:43:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:43:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:43:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:43:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11630,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 43, 30, 764184),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1052823552,
 'memusage/startup': 1052823552,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 5, 43, 30, 648750)}
2018-11-22 13:43:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:48:07 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:48:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:48:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:48:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:48:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:48:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:48:07 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:48:07 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:48:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:48:07 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:48:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:48:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: None)
2018-11-22 13:48:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:48:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 488,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14038,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 48, 9, 637676),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1053351936,
 'memusage/startup': 1053351936,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 5, 48, 7, 202026)}
2018-11-22 13:48:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 13:48:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 13:48:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 13:48:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 13:48:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 13:48:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 13:48:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 13:48:38 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 13:48:38 [scrapy.core.engine] INFO: Spider opened
2018-11-22 13:48:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 13:48:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 13:48:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 13:48:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: None)
2018-11-22 13:48:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 13:48:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 488,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14038,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 5, 48, 39, 629596),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1053532160,
 'memusage/startup': 1053532160,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 5, 48, 38, 553470)}
2018-11-22 13:48:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:00:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:00:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:00:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:00:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:00:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:00:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:00:40 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:00:40 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:00:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 14:00:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: None)
2018-11-22 14:00:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:00:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 488,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14038,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 0, 41, 168738),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1055088640,
 'memusage/startup': 1055088640,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 6, 0, 40, 125854)}
2018-11-22 14:00:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:07:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:07:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:07:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:07:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:07:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:07:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:07:56 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:07:56 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:07:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:07:56 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:07:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 14:07:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: None)
2018-11-22 14:07:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/spiders/bturl.py", line 50, in parse_detail
    title = response.xpath('//h1[@class="T1"]/text')[0].extract()
  File "/usr/local/lib/python3.6/dist-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-22 14:07:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:07:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 488,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14038,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 7, 59, 963666),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 1055780864,
 'memusage/startup': 1055780864,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 7, 56, 946494)}
2018-11-22 14:07:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:09:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:09:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:09:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:09:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:09:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:09:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:09:25 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:09:25 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:09:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:09:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 14:09:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: None)
2018-11-22 14:09:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:09:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 488,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14038,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 9, 31, 361641),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1056583680,
 'memusage/startup': 1056583680,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 6, 9, 25, 810762)}
2018-11-22 14:09:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:09:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:09:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:09:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:09:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:09:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:09:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:09:49 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:09:49 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:09:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:09:49 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:09:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturl1.html> (referer: None)
2018-11-22 14:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: None)
2018-11-22 14:09:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:09:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 488,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14038,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 9, 51, 746334),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1056583680,
 'memusage/startup': 1056583680,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 6, 9, 49, 147247)}
2018-11-22 14:09:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:14:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:14:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:14:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:14:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:14:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:14:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:14:47 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:14:47 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:14:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:14:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:14:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:14:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:14:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 14, 47, 132629),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1057218560,
 'memusage/startup': 1057218560,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 14, 47, 21051)}
2018-11-22 14:14:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:15:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:15:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:15:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:15:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:15:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:15:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:15:10 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:15:10 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:15:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:15:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:15:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:15:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:15:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 15, 10, 665530),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1057218560,
 'memusage/startup': 1057218560,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 15, 10, 554949)}
2018-11-22 14:15:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:16:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:16:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:16:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:16:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:16:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:16:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:16:14 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:16:14 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:16:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:16:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:16:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:16:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:16:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 16, 14, 357050),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1057243136,
 'memusage/startup': 1057243136,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 16, 14, 246319)}
2018-11-22 14:16:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:16:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:16:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:16:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:16:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:16:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:16:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:16:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:16:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:16:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:16:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:16:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:16:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:16:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 16, 55, 444481),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1057783808,
 'memusage/startup': 1057783808,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 16, 55, 334027)}
2018-11-22 14:16:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:19:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:19:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:19:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:19:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:19:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:19:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:19:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:19:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:19:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:19:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:19:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:19:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:19:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 19, 43, 903145),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1058091008,
 'memusage/startup': 1058091008,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 19, 43, 792134)}
2018-11-22 14:19:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:19:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:19:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:19:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:19:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:19:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:19:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:19:54 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:19:54 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:19:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:19:54 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:19:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:19:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:19:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 19, 54, 961252),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1058091008,
 'memusage/startup': 1058091008,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 19, 54, 846470)}
2018-11-22 14:19:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:20:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:20:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:20:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:20:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:20:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:20:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:20:02 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:20:02 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:20:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:20:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:20:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:20:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:20:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 20, 2, 320129),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1058308096,
 'memusage/startup': 1058308096,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 20, 2, 209913)}
2018-11-22 14:20:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:20:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:20:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:20:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:20:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:20:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:20:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:20:31 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:20:31 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:20:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:20:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:20:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:20:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:20:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 20, 31, 658561),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1058308096,
 'memusage/startup': 1058308096,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 20, 31, 544445)}
2018-11-22 14:20:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:21:21 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:21:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:21:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:21:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:21:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:21:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:21:21 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:21:21 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:21:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:21:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:21:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:21:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:21:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 21, 21, 757421),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1091272704,
 'memusage/startup': 1091272704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 21, 21, 642116)}
2018-11-22 14:21:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:23:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:23:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:23:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:23:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:23:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:23:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:23:39 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:23:39 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:23:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:23:39 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:23:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:23:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 23, 39, 644341),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1091272704,
 'memusage/startup': 1091272704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 23, 39, 533255)}
2018-11-22 14:23:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:23:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:23:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:23:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:23:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:23:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:23:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:23:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:23:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:23:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:23:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:23:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:23:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 23, 55, 731090),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1091272704,
 'memusage/startup': 1091272704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 23, 55, 620184)}
2018-11-22 14:23:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:24:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:24:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:24:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:24:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:24:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:24:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:24:28 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:24:28 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:24:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:24:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:24:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:24:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:24:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 24, 28, 392153),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1091272704,
 'memusage/startup': 1091272704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 24, 28, 281017)}
2018-11-22 14:24:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:24:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:24:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:24:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:24:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:24:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:24:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:24:58 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:24:58 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:24:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:24:58 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:24:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:24:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:24:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 24, 58, 552887),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1091272704,
 'memusage/startup': 1091272704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 24, 58, 437925)}
2018-11-22 14:24:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:25:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:25:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:25:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:25:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:25:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:25:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:25:28 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:25:28 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:25:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:25:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:25:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:25:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:25:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 25, 29, 60335),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1091272704,
 'memusage/startup': 1091272704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 25, 28, 949491)}
2018-11-22 14:25:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:25:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:25:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:25:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:25:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:25:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:25:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:25:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:25:51 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:25:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:25:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:25:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:25:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:25:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 25, 52, 84221),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1093210112,
 'memusage/startup': 1093210112,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 25, 51, 969856)}
2018-11-22 14:25:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:37:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:37:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:37:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:37:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:37:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:37:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:37:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:37:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:37:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:37:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:37:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/bturltext.html>
{'click': '1',
 'ctime': '2018-11-20',
 'filename': 'I.Simpson.29x06.Marge.Sindaca.iTALiAN.AC3.Dvb.x264.720p.by.Alex69Picci.mkv',
 'length': '400.4 MB',
 'link': 'magnet:?xt=urn:btih:CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3'}
2018-11-22 14:37:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:37:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 37, 48, 398215),
 'item_scraped_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1095761920,
 'memusage/startup': 1095761920,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 37, 48, 272312)}
2018-11-22 14:37:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:53:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 14:53:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 14:53:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 14:53:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:53:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:53:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:53:53 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 14:53:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:53:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:53:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 14:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 14:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/bturltext.html>
{'click': '1',
 'ctime': '2018-11-20',
 'filename': 'I.Simpson.29x06.Marge.Sindaca.iTALiAN.AC3.Dvb.x264.720p.by.Alex69Picci.mkv',
 'length': '400.4 MB',
 'link': 'magnet:?xt=urn:btih:CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3'}
2018-11-22 14:53:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:53:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 53, 53, 766238),
 'item_scraped_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1096499200,
 'memusage/startup': 1096499200,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 6, 53, 53, 654615)}
2018-11-22 14:53:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:12:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 15:12:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 15:12:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 15:12:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:12:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:12:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:12:58 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 15:12:58 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:12:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:12:58 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 15:12:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 15:12:58 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/bturltext.html>
{'click': '1',
 'ctime': '2018-11-20',
 'filename': 'I.Simpson.29x06.Marge.Sindaca.iTALiAN.AC3.Dvb.x264.720p.by.Alex69Picci.mkv',
 'length': '400.4 MB',
 'link': 'magnet:?xt=urn:btih:CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3'}
2018-11-22 15:12:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:12:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 12, 58, 337806),
 'item_scraped_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1099157504,
 'memusage/startup': 1099157504,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 7, 12, 58, 221346)}
2018-11-22 15:12:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:14:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 15:14:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 15:14:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 15:14:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:14:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:14:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:14:27 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 15:14:27 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:14:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:14:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 15:14:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 15:14:27 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/bturltext.html>
{'click': '1',
 'ctime': '2018-11-20',
 'filename': 'I.Simpson.29x06.Marge.Sindaca.iTALiAN.AC3.Dvb.x264.720p.by.Alex69Picci.mkv',
 'length': '400.4 MB',
 'link': 'magnet:?xt=urn:btih:CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3'}
2018-11-22 15:14:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:14:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 14, 27, 269356),
 'item_scraped_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1101152256,
 'memusage/startup': 1101152256,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 7, 14, 27, 157501)}
2018-11-22 15:14:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:17:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 15:17:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 15:17:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 15:17:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:17:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:17:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:17:53 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 15:17:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:17:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:17:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 15:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-22 15:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-22 15:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-22 15:17:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:17:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 702,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 10733,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 17, 57, 669579),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 1116622848,
 'memusage/startup': 1116622848,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 7, 17, 53, 230863)}
2018-11-22 15:17:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:20:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 15:20:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 15:20:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 15:20:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:20:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:20:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:20:59 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 15:20:59 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:20:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:20:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 15:21:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-22 15:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-22 15:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-22 15:21:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:21:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 702,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 10740,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 21, 1, 735278),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 1117216768,
 'memusage/startup': 1117216768,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 7, 20, 59, 458287)}
2018-11-22 15:21:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:23:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 15:23:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 15:23:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 15:23:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:23:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:23:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:23:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 15:23:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:23:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:23:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 15:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-22 15:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-22 15:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-22 15:23:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:23:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 702,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 10735,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 23, 57, 373286),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 1117573120,
 'memusage/startup': 1117573120,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 22, 7, 23, 55, 23801)}
2018-11-22 15:23:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:25:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 15:25:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 15:25:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 15:25:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:25:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:25:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:25:54 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 15:25:54 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:25:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:25:54 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 15:25:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-22 15:25:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/18B16FF9D69599A8C933D62C2A500CFAE8F250F8.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:25:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/18B16FF9D69599A8C933D62C2A500CFAE8F250F8.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'Pocket Monsters Sun & Moon - 064 (TVh 1280x720 x264 AAC).mkv',
 'length': '304.1 MB',
 'link': 'magnet:?xt=urn:btih:18B16FF9D69599A8C933D62C2A500CFAE8F250F8'}
2018-11-22 15:25:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-22 15:25:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:25:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html>
{'click': '1',
 'ctime': '2018-11-20',
 'filename': 'I.Simpson.29x06.Marge.Sindaca.iTALiAN.AC3.Dvb.x264.720p.by.Alex69Picci.mkv',
 'length': '400.4 MB',
 'link': 'magnet:?xt=urn:btih:CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3'}
2018-11-22 15:26:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-22 15:26:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A883F987CFEABDABE1550D05BEC20D9279DFD73D.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:26:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/A883F987CFEABDABE1550D05BEC20D9279DFD73D.html>
{'click': '9',
 'ctime': '2018-11-21',
 'filename': 'NCIS.New.Orleans.S05E08.720p.HDTV.x264-300MB.mkv',
 'length': '292.0 MB',
 'link': 'magnet:?xt=urn:btih:A883F987CFEABDABE1550D05BEC20D9279DFD73D'}
2018-11-22 15:26:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:26:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1821,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 17457,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 26, 6, 772000),
 'item_scraped_count': 3,
 'log_count/DEBUG': 10,
 'log_count/INFO': 7,
 'memusage/max': 1119281152,
 'memusage/startup': 1119281152,
 'request_depth_max': 1,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2018, 11, 22, 7, 25, 54, 11219)}
2018-11-22 15:26:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:28:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 15:28:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 15:28:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 15:28:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:28:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:28:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:28:42 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 15:28:42 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:28:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:28:42 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 15:28:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-22 15:28:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5D75FEBE6DCE228613A17F1C6AB095C62E5F4F1B.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/FF42EE1953317CB1995A91CDB0D6209388706AB9.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/5D75FEBE6DCE228613A17F1C6AB095C62E5F4F1B.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'Fifa Football Awards 2018 - 2018 09 24 - 720p - English.mkv',
 'length': '1.2 GB',
 'link': 'magnet:?xt=urn:btih:5D75FEBE6DCE228613A17F1C6AB095C62E5F4F1B'}
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D01EB7D087B3CC41C87A58373A2BF9E9E369DA12.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/FF42EE1953317CB1995A91CDB0D6209388706AB9.html>
{'click': '2',
 'ctime': '2018-11-21',
 'filename': 'Texas.Flip.N.Move.S10E10.Shotgun.Shanty.vs.Garden.Digs.720p.WEB.x264-KOMPOST[eztv].mkv',
 'length': '913.9 MB',
 'link': 'magnet:?xt=urn:btih:FF42EE1953317CB1995A91CDB0D6209388706AB9'}
2018-11-22 15:28:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/D01EB7D087B3CC41C87A58373A2BF9E9E369DA12.html>
{'click': '3',
 'ctime': '2018-11-21',
 'filename': 'Shark.Il.Primo.Squalo.2018.1080p.BRRip.x264.AC3.ITA.Cris600.mkv',
 'length': '2.3 GB',
 'link': 'magnet:?xt=urn:btih:D01EB7D087B3CC41C87A58373A2BF9E9E369DA12'}
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/E0004DE0871836E945EFE35E612315FBFEB0494F.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/E0004DE0871836E945EFE35E612315FBFEB0494F.html>
{'click': '20',
 'ctime': '2018-11-21',
 'filename': 'Mom.S06E08.720p.WEB.x264-300MB.mkv',
 'length': '156.8 MB',
 'link': 'magnet:?xt=urn:btih:E0004DE0871836E945EFE35E612315FBFEB0494F'}
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D0F06A7DCBCF6554C677B2318B6CDCEC5F325DC0.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1F3BC5A1B7E39F418DF76E026654776ADEBBC740.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/D0F06A7DCBCF6554C677B2318B6CDCEC5F325DC0.html>
{'click': '12',
 'ctime': '2018-11-21',
 'filename': 'teen.mom.s07e26.720p.web.x264-tbs[eztv].mkv',
 'length': '769.8 MB',
 'link': 'magnet:?xt=urn:btih:D0F06A7DCBCF6554C677B2318B6CDCEC5F325DC0'}
2018-11-22 15:28:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/1F3BC5A1B7E39F418DF76E026654776ADEBBC740.html>
{'click': '4',
 'ctime': '2018-11-21',
 'filename': 'The.Simpsons.s30e07.720p.WEB.x264-300MB.mkv',
 'length': '159.6 MB',
 'link': 'magnet:?xt=urn:btih:1F3BC5A1B7E39F418DF76E026654776ADEBBC740'}
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/93285D29876D8467D8F5C83D5CFB8A93BC43B1CF.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/60F43A6CA287C703D9AEA4A1A8D46F702D4D7923.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3B9D410B9183DBEE3EF1276D4CA3D72C7BBA42F9.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/93285D29876D8467D8F5C83D5CFB8A93BC43B1CF.html>
{'click': '8',
 'ctime': '2018-11-21',
 'filename': 'the.jim.jefferies.show.s02e30.720p.web.x264-tbs[eztv].mkv',
 'length': '378.7 MB',
 'link': 'magnet:?xt=urn:btih:93285D29876D8467D8F5C83D5CFB8A93BC43B1CF'}
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/60F43A6CA287C703D9AEA4A1A8D46F702D4D7923.html>
{'click': '12',
 'ctime': '2018-11-21',
 'filename': 'The.Conners.S01E04.1080p.rus.HDREZKA.AG.mkv',
 'length': '1.1 GB',
 'link': 'magnet:?xt=urn:btih:60F43A6CA287C703D9AEA4A1A8D46F702D4D7923'}
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A1FF3BB3B95753733E5DCD695D10ECBC31D51493.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/3B9D410B9183DBEE3EF1276D4CA3D72C7BBA42F9.html>
{'click': '6',
 'ctime': '2018-11-21',
 'filename': 'Chak De! India 2007 BDRip 1080p x264 2Rus.mkv',
 'length': '16.7 GB',
 'link': 'magnet:?xt=urn:btih:3B9D410B9183DBEE3EF1276D4CA3D72C7BBA42F9'}
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A2D115EDA92F8A5F9519E04ACB9509BE8BD4E360.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/A1FF3BB3B95753733E5DCD695D10ECBC31D51493.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'Power.Office.Girls.S04E01.WEB.x264-WaLMaRT[eztv].mkv',
 'length': '722.5 MB',
 'link': 'magnet:?xt=urn:btih:A1FF3BB3B95753733E5DCD695D10ECBC31D51493'}
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/BED8C953F9A2035D65AA85428A1BA046438132B7.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/A2D115EDA92F8A5F9519E04ACB9509BE8BD4E360.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'True.Blood.S04E01.720p.HDTV.X264-DIMENSION.mkv',
 'length': '2.0 GB',
 'link': 'magnet:?xt=urn:btih:A2D115EDA92F8A5F9519E04ACB9509BE8BD4E360'}
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/BED8C953F9A2035D65AA85428A1BA046438132B7.html>
{'click': '10',
 'ctime': '2018-11-21',
 'filename': 'Shuudengo, Capsule Hotel de, Joushi ni Binetsu Tsutawaru Yoru. - '
             '07 (1280x720 Hi10P AAC).mkv',
 'length': '57.8 MB',
 'link': 'magnet:?xt=urn:btih:BED8C953F9A2035D65AA85428A1BA046438132B7'}
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3D6287CE73FCD64E28A0268F1499C678E4E6FB25.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/18B16FF9D69599A8C933D62C2A500CFAE8F250F8.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1860597E9BD7D9B27CC3281FB4984D77D8516FE3.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3B2037C2DA2D00B0DA4EA228FABAE2423A251EE9.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/3D6287CE73FCD64E28A0268F1499C678E4E6FB25.html>
{'click': '7',
 'ctime': '2018-11-21',
 'filename': 'Dogman.2O18.P.BDRip.72Op_KOSHARA.mkv',
 'length': '5.2 GB',
 'link': 'magnet:?xt=urn:btih:3D6287CE73FCD64E28A0268F1499C678E4E6FB25'}
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/18B16FF9D69599A8C933D62C2A500CFAE8F250F8.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'Pocket Monsters Sun & Moon - 064 (TVh 1280x720 x264 AAC).mkv',
 'length': '304.1 MB',
 'link': 'magnet:?xt=urn:btih:18B16FF9D69599A8C933D62C2A500CFAE8F250F8'}
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/1860597E9BD7D9B27CC3281FB4984D77D8516FE3.html>
{'click': '27',
 'ctime': '2018-11-21',
 'filename': 'Idiocracy (2006) WEBRip 1080p H.265 [UKR_ENG].mkv',
 'length': '3.4 GB',
 'link': 'magnet:?xt=urn:btih:1860597E9BD7D9B27CC3281FB4984D77D8516FE3'}
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/3B2037C2DA2D00B0DA4EA228FABAE2423A251EE9.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'New.Amsterdam.2018.S01E08.720p.HDTV.2CH.x265.HEVC-PSA.mkv',
 'length': '192.4 MB',
 'link': 'magnet:?xt=urn:btih:3B2037C2DA2D00B0DA4EA228FABAE2423A251EE9'}
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/DB8A7362A92E5F26FDE3BE25CE3260DD6F8519E2.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1E914CAB20B93CEFC2C1FD62D0C32038E146052B.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/63D3F07351494E4015CFE306B349FA307DA448EA.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/896CE4650190F653639B8236F35438C807D34476.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/DB8A7362A92E5F26FDE3BE25CE3260DD6F8519E2.html>
{'click': '4',
 'ctime': '2018-11-21',
 'filename': 'The.Little.Stranger.2018.720p.WEBRip.HiWayGrope.mkv',
 'length': '2.5 GB',
 'link': 'magnet:?xt=urn:btih:DB8A7362A92E5F26FDE3BE25CE3260DD6F8519E2'}
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/1E914CAB20B93CEFC2C1FD62D0C32038E146052B.html>
{'click': '2',
 'ctime': '2018-11-21',
 'filename': 'The.Flash.2014.S05E06.720p.HDTV.x265-MiNX[eztv].mkv',
 'length': '200.9 MB',
 'link': 'magnet:?xt=urn:btih:1E914CAB20B93CEFC2C1FD62D0C32038E146052B'}
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/FFAB35F7416C445A20BAE9E30CDFD15EFBF14BF1.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/035E050E16B5786982FB83948A98043E14F6D509.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/63D3F07351494E4015CFE306B349FA307DA448EA.html>
{'click': '2',
 'ctime': '2018-11-21',
 'filename': 'The.Vanilla.Ice.Project.S08E06.Working.Out.the.Foyer.720p.WEB.x264-KOMPOST[eztv].mkv',
 'length': '458.5 MB',
 'link': 'magnet:?xt=urn:btih:63D3F07351494E4015CFE306B349FA307DA448EA'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/896CE4650190F653639B8236F35438C807D34476.html>
{'click': '2',
 'ctime': '2018-11-20',
 'filename': '[Golumpa] Zombie Land Saga - 04 [FuniDub 720p x264 AAC] '
             '[A91B5256].mkv',
 'length': '402.0 MB',
 'link': 'magnet:?xt=urn:btih:896CE4650190F653639B8236F35438C807D34476'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/FFAB35F7416C445A20BAE9E30CDFD15EFBF14BF1.html>
{'click': '3',
 'ctime': '2018-11-20',
 'filename': 'Bir Zamanlar Cukurova 10.BLM (15.11.2018) 720p WEB-DL '
             'x264-TURG.mkv',
 'length': '1.4 GB',
 'link': 'magnet:?xt=urn:btih:FFAB35F7416C445A20BAE9E30CDFD15EFBF14BF1'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/035E050E16B5786982FB83948A98043E14F6D509.html>
{'click': '6',
 'ctime': '2018-11-20',
 'filename': 'Z.Nation.S05E07.Docs.Stoned.History.720p.AMZN.WEB-DL.DDP5.1.H.264-KiNGS[eztv].mkv',
 'length': '1.4 GB',
 'link': 'magnet:?xt=urn:btih:035E050E16B5786982FB83948A98043E14F6D509'}
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6E62713640EA32A5AB9AD213903D09ADFC1DC903.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/64B80BDE32683202F534E189EBB519446277C0CB.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D9996A10BEA2ACD1AFBA2211872746D8D45B761F.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/EB2BEEA2CCCBCA9D4E18E22B3E9D461EB91254D5.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/845C904ED3AC1AB1E8DB91BC2607BB380164D794.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/6E62713640EA32A5AB9AD213903D09ADFC1DC903.html>
{'click': '1',
 'ctime': '2018-11-20',
 'filename': 'the.bold.and.the.beautiful.s32e22.web.x264-w4f[eztv].mkv',
 'length': '114.7 MB',
 'link': 'magnet:?xt=urn:btih:6E62713640EA32A5AB9AD213903D09ADFC1DC903'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/64B80BDE32683202F534E189EBB519446277C0CB.html>
{'click': '54',
 'ctime': '2018-11-20',
 'filename': '[Erai-raws] Black Clover (TV) - 59 [720p][Multiple Subtitle].mkv',
 'length': '521.0 MB',
 'link': 'magnet:?xt=urn:btih:64B80BDE32683202F534E189EBB519446277C0CB'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/D9996A10BEA2ACD1AFBA2211872746D8D45B761F.html>
{'click': '13',
 'ctime': '2018-11-20',
 'filename': 'The.Last.Kingdom.S03E02.720p.WEB.x264-CRiMSON[eztv].mkv',
 'length': '948.6 MB',
 'link': 'magnet:?xt=urn:btih:D9996A10BEA2ACD1AFBA2211872746D8D45B761F'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/EB2BEEA2CCCBCA9D4E18E22B3E9D461EB91254D5.html>
{'click': '18',
 'ctime': '2018-11-20',
 'filename': 'The.Last.Kingdom.S03E04.720p.10bit.WEBRip.2CH.x265.HEVC-PSA.mkv',
 'length': '257.9 MB',
 'link': 'magnet:?xt=urn:btih:EB2BEEA2CCCBCA9D4E18E22B3E9D461EB91254D5'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/845C904ED3AC1AB1E8DB91BC2607BB380164D794.html>
{'click': '3',
 'ctime': '2018-11-20',
 'filename': 'Kagemusha.1980.BDRip.AVC.UKR.mkv',
 'length': '2.3 GB',
 'link': 'magnet:?xt=urn:btih:845C904ED3AC1AB1E8DB91BC2607BB380164D794'}
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1D37899B2922E72CC8B08E58E1E66A713E98F039.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/1D37899B2922E72CC8B08E58E1E66A713E98F039.html>
{'click': '5',
 'ctime': '2018-11-20',
 'filename': 'Busy.Tonight.2018.11.19.Ike.Barinholtz.480p.x264-mSD[eztv].mkv',
 'length': '125.6 MB',
 'link': 'magnet:?xt=urn:btih:1D37899B2922E72CC8B08E58E1E66A713E98F039'}
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/477FDA391958C24DE21F5C6A5E8DEEA5610B0987.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/477FDA391958C24DE21F5C6A5E8DEEA5610B0987.html>
{'click': '3',
 'ctime': '2018-11-20',
 'filename': 'Fighting.Season.s01e02.720p.HDTV.x264-300MB.mkv',
 'length': '370.0 MB',
 'link': 'magnet:?xt=urn:btih:477FDA391958C24DE21F5C6A5E8DEEA5610B0987'}
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3.html>
{'click': '1',
 'ctime': '2018-11-20',
 'filename': 'I.Simpson.29x06.Marge.Sindaca.iTALiAN.AC3.Dvb.x264.720p.by.Alex69Picci.mkv',
 'length': '400.4 MB',
 'link': 'magnet:?xt=urn:btih:CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3'}
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/50CF80A496B66A688A951DA55FA3D56A440920D8.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/018F775F863C0581274F96827709C5D3E54FEDA1.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/50CF80A496B66A688A951DA55FA3D56A440920D8.html>
{'click': '3',
 'ctime': '2018-11-21',
 'filename': 'Good.Eats-Reloaded.S01E04.The.Dough.Also.Rises-Reloaded.720p.WEB.x264-KOMPOST[eztv].mkv',
 'length': '458.0 MB',
 'link': 'magnet:?xt=urn:btih:50CF80A496B66A688A951DA55FA3D56A440920D8'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/852BBE5EC4A6E89A22A46830A5EA28AA22F42EE1.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/8A8C534FB7195020AF946CA89422DC069E08E424.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/018F775F863C0581274F96827709C5D3E54FEDA1.html>
{'click': '30',
 'ctime': '2018-11-20',
 'filename': 'Mickey.Mouse.Clubhouse.S03E04.720p.WEB.x264-CRiMSON[eztv].mkv',
 'length': '328.2 MB',
 'link': 'magnet:?xt=urn:btih:018F775F863C0581274F96827709C5D3E54FEDA1'}
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/852BBE5EC4A6E89A22A46830A5EA28AA22F42EE1.html>
{'click': '4',
 'ctime': '2018-11-21',
 'filename': '[HorribleSubs] Conception - 07 [480p].mkv',
 'length': '135.6 MB',
 'link': 'magnet:?xt=urn:btih:852BBE5EC4A6E89A22A46830A5EA28AA22F42EE1'}
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/8A8C534FB7195020AF946CA89422DC069E08E424.html>
{'click': '2',
 'ctime': '2018-11-20',
 'filename': '[PuyaSubs!] Jingai-san no yome - 08 [1080p][9C3317DC].mkv',
 'length': '117.4 MB',
 'link': 'magnet:?xt=urn:btih:8A8C534FB7195020AF946CA89422DC069E08E424'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D6B04B662664BEB176D8FFA7A6D7D2F794452512.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D8C544B4F13C25B8DCCA1F20E8C17A9525429B4D.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1900D64A5EE99F870E927FC9320F40E262C8B861.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/D6B04B662664BEB176D8FFA7A6D7D2F794452512.html>
{'click': '3',
 'ctime': '2018-11-21',
 'filename': 'Tomorrow.Tonight.S01E03.720p.HDTV.x264-CCT[eztv].mkv',
 'length': '934.3 MB',
 'link': 'magnet:?xt=urn:btih:D6B04B662664BEB176D8FFA7A6D7D2F794452512'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/405630072E75773DF14CCE8B694ACF226A7CB40F.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D8E9F7CFEC6125D6B497D7D92DD841329A169696.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/D8C544B4F13C25B8DCCA1F20E8C17A9525429B4D.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'Children Of Bodom - Live @ Hellfest (2018).mkv',
 'length': '2.2 GB',
 'link': 'magnet:?xt=urn:btih:D8C544B4F13C25B8DCCA1F20E8C17A9525429B4D'}
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/405630072E75773DF14CCE8B694ACF226A7CB40F.html>
{'click': '16',
 'ctime': '2018-11-20',
 'filename': 'Inuyashiki.2018.mkv',
 'length': '2.8 GB',
 'link': 'magnet:?xt=urn:btih:405630072E75773DF14CCE8B694ACF226A7CB40F'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A883F987CFEABDABE1550D05BEC20D9279DFD73D.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/D8E9F7CFEC6125D6B497D7D92DD841329A169696.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'Sorry.For.Your.Loss.S01E09.1080p.rus.HDREZKA.AG.mkv',
 'length': '867.4 MB',
 'link': 'magnet:?xt=urn:btih:D8E9F7CFEC6125D6B497D7D92DD841329A169696'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/B68516ABE056F873168F80B4F6BEDA3C9AB4CCA6.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/A883F987CFEABDABE1550D05BEC20D9279DFD73D.html>
{'click': '9',
 'ctime': '2018-11-21',
 'filename': 'NCIS.New.Orleans.S05E08.720p.HDTV.x264-300MB.mkv',
 'length': '292.0 MB',
 'link': 'magnet:?xt=urn:btih:A883F987CFEABDABE1550D05BEC20D9279DFD73D'}
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/B68516ABE056F873168F80B4F6BEDA3C9AB4CCA6.html>
{'click': '2',
 'ctime': '2018-11-20',
 'filename': 'Mr.D.S08E01.720p.WEBRip.x264-TBS[eztv].mkv',
 'length': '467.5 MB',
 'link': 'magnet:?xt=urn:btih:B68516ABE056F873168F80B4F6BEDA3C9AB4CCA6'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/F6CF1C9E0A612B99DFDB578F1FC8A41A91084078.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/357F95393076F7362A4A0902D07307431D9795B4.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/F6CF1C9E0A612B99DFDB578F1FC8A41A91084078.html>
{'click': '18',
 'ctime': '2018-11-21',
 'filename': 'ice.cold.killers.s03e06.720p.hdtv.x264-w4f[eztv].mkv',
 'length': '923.8 MB',
 'link': 'magnet:?xt=urn:btih:F6CF1C9E0A612B99DFDB578F1FC8A41A91084078'}
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/357F95393076F7362A4A0902D07307431D9795B4.html>
{'click': '3',
 'ctime': '2018-11-21',
 'filename': 'The.Predator.2018.1080p.5.1.rus.HDREZKA.AG.mkv',
 'length': '3.5 GB',
 'link': 'magnet:?xt=urn:btih:357F95393076F7362A4A0902D07307431D9795B4'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2DD7FB7FC81BC01D1732A0F2E6E33A74E5424A77.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/2DD7FB7FC81BC01D1732A0F2E6E33A74E5424A77.html>
{'click': '1',
 'ctime': '2018-11-21',
 'filename': 'UEL 2018 - Qualifying - Maribor vs Rangers - 2018 08 17 - 720p - '
             'English.mkv',
 'length': '2.0 GB',
 'link': 'magnet:?xt=urn:btih:2DD7FB7FC81BC01D1732A0F2E6E33A74E5424A77'}
2018-11-22 15:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/E242FC2BB964C641BB0A468D1DDE6929E2D338F3.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-22 15:28:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.cc/E242FC2BB964C641BB0A468D1DDE6929E2D338F3.html>
{'click': '2',
 'ctime': '2018-11-21',
 'filename': '.Killer.Toon.2013.Bluray.1080p.HEVC.10bit-GHFLY.mkv',
 'length': '2.8 GB',
 'link': 'magnet:?xt=urn:btih:E242FC2BB964C641BB0A468D1DDE6929E2D338F3'}
2018-11-22 15:28:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:28:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17487,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 110909,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 28, 47, 939175),
 'item_scraped_count': 44,
 'log_count/DEBUG': 93,
 'log_count/INFO': 7,
 'memusage/max': 1120006144,
 'memusage/startup': 1120006144,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 22, 7, 28, 42, 242155)}
2018-11-22 15:28:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 16:49:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 16:49:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 16:49:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 16:49:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 16:49:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 16:49:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 16:49:50 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 16:49:50 [scrapy.core.engine] INFO: Spider opened
2018-11-22 16:49:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 16:49:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 16:49:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 16:49:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 16:49:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 8, 49, 50, 225266),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 8, 49, 50, 114149)}
2018-11-22 16:49:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 16:52:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 16:52:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 16:52:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 16:52:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 16:52:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 16:52:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 16:52:36 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 16:52:36 [scrapy.core.engine] INFO: Spider opened
2018-11-22 16:52:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 16:52:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 16:52:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 16:52:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 16:52:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 8, 52, 36, 508806),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 8, 52, 36, 393400)}
2018-11-22 16:52:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 16:56:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 16:56:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 16:56:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 16:56:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 16:56:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 16:56:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 16:56:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 16:56:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 16:56:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 16:56:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 16:56:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 16:56:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 16:56:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 8, 56, 48, 971772),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 8, 56, 48, 856341)}
2018-11-22 16:56:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 16:57:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 16:57:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 16:57:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 16:57:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 16:57:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 16:57:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 16:57:53 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 16:57:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 16:57:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 16:57:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 16:57:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 16:57:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 16:57:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 8, 57, 53, 678475),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 8, 57, 53, 563157)}
2018-11-22 16:57:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 16:58:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 16:58:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 16:58:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 16:58:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 16:58:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 16:58:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 16:58:04 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 16:58:04 [scrapy.core.engine] INFO: Spider opened
2018-11-22 16:58:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 16:58:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 16:58:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 16:58:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 16:58:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 8, 58, 4, 871859),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 8, 58, 4, 756992)}
2018-11-22 16:58:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 16:59:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 16:59:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 16:59:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 16:59:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 16:59:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 16:59:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 16:59:11 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 16:59:11 [scrapy.core.engine] INFO: Spider opened
2018-11-22 16:59:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 16:59:11 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 16:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 16:59:11 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 16:59:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 16:59:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 8, 59, 11, 561291),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 8, 59, 11, 445230)}
2018-11-22 16:59:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 16:59:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 16:59:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 16:59:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 16:59:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 16:59:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 16:59:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 16:59:25 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 16:59:25 [scrapy.core.engine] INFO: Spider opened
2018-11-22 16:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 16:59:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 16:59:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 16:59:25 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 16:59:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 16:59:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 8, 59, 25, 821663),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 8, 59, 25, 710959)}
2018-11-22 16:59:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:01:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:01:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:01:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:01:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:01:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:01:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:01:09 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:01:09 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:01:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:01:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:01:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:01:09 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 17:01:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:01:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 1, 9, 719704),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 9, 1, 9, 603605)}
2018-11-22 17:01:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:01:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:01:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:01:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:01:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:01:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:01:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:01:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:01:30 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:01:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:01:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:01:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:01:30 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 17:01:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:01:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 1, 30, 673534),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 9, 1, 30, 557316)}
2018-11-22 17:01:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:03:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:03:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:03:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:03:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:03:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:03:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:03:02 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:03:02 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:03:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:03:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:03:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:03:02 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 17:03:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:03:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 3, 2, 864233),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 9, 3, 2, 748264)}
2018-11-22 17:03:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:05:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:05:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:05:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:05:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:05:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:05:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:05:09 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:05:09 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:05:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:05:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:05:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:05:09 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 17:05:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:05:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 5, 9, 815778),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 9, 5, 9, 699544)}
2018-11-22 17:05:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:06:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:06:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:06:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:06:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:06:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:06:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:06:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:06:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:06:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:06:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:06:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:06:48 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 17:06:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:06:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 6, 48, 960248),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 9, 6, 48, 844797)}
2018-11-22 17:06:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:07:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:07:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:07:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:07:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:07:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:07:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:07:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:07:34 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:07:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:07:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:07:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:07:34 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 17:07:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:07:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 7, 34, 167030),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 9, 7, 34, 52179)}
2018-11-22 17:07:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:08:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:08:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:08:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:08:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:08:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:08:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:08:03 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:08:03 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:08:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:08:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:08:03 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'fanyi.baidu.com': <GET https://fanyi.baidu.com/#en/zh/i%20simpson>
2018-11-22 17:08:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:08:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4665,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 8, 3, 711134),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 22, 9, 8, 3, 595389)}
2018-11-22 17:08:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:08:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:08:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:08:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:08:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:08:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:08:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:08:28 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:08:28 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:08:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:08:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:08:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:08:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:08:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:08:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47485,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 8, 30, 85128),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 8, 28, 987956)}
2018-11-22 17:08:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:09:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:09:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:09:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:09:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:09:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:09:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:09:26 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:09:26 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:09:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:09:26 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:09:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:09:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47485,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 9, 27, 118435),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 9, 26, 106010)}
2018-11-22 17:09:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:10:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:10:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:10:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:10:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:10:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:10:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:10:05 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:10:05 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:10:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:10:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:10:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:10:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:10:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:10:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47481,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 10, 6, 171710),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 10, 5, 66667)}
2018-11-22 17:10:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:10:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:10:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:10:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:10:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:10:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:10:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:10:36 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:10:36 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:10:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:10:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:10:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:10:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:10:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:10:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47479,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 10, 37, 383862),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 10, 36, 340877)}
2018-11-22 17:10:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:10:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:10:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:10:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:10:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:10:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:10:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:10:50 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:10:50 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:10:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:10:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:10:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:10:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:10:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:10:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47483,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 10, 52, 47727),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 10, 50, 826206)}
2018-11-22 17:10:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:11:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:11:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:11:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:11:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:11:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:11:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:11:28 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:11:28 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:11:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:11:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:11:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:11:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:11:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47482,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 11, 29, 927717),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 11, 28, 926005)}
2018-11-22 17:11:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:11:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:11:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:11:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:11:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:11:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:11:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:11:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:11:48 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:11:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:11:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:11:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:11:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:11:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:11:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47483,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 11, 49, 358296),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 11, 48, 180579)}
2018-11-22 17:11:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:11:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:11:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:11:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:11:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:11:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:11:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:11:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:11:55 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:11:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:11:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:11:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fanyi.baidu.com/#en/zh/i%20simpson> (referer: None)
2018-11-22 17:11:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:11:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 449,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 47481,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 11, 56, 509956),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 11, 55, 777334)}
2018-11-22 17:11:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:24:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:24:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:24:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:24:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:24:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:24:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:24:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:24:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:24:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:24:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:24:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:24:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-22 17:24:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:24:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 24, 43, 300472),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 24, 43, 15264)}
2018-11-22 17:24:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 17:27:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-22 17:27:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-22 17:27:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-22 17:27:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 17:27:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 17:27:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 17:27:53 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-22 17:27:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 17:27:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 17:27:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-22 17:27:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-22 17:27:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-22 17:27:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 17:27:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 9, 27, 53, 990945),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 1131753472,
 'memusage/startup': 1131753472,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 22, 9, 27, 53, 705104)}
2018-11-22 17:27:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:30:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:30:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:30:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:30:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:30:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:30:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:30:02 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:30:02 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:30:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:30:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:30:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:30:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:30:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:30:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 30, 3, 120552),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 550039552,
 'memusage/startup': 550039552,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 30, 2, 625687)}
2018-11-23 11:30:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:30:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:30:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:30:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:30:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:30:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:30:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:30:56 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:30:56 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:30:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:30:56 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:30:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:30:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:30:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:30:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 30, 57, 90078),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 604868608,
 'memusage/startup': 604868608,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 30, 56, 813190)}
2018-11-23 11:30:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:32:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:32:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:32:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:32:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:32:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:32:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:32:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:32:30 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:32:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:32:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:32:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:32:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 32, 31, 202184),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 616370176,
 'memusage/startup': 616370176,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 32, 30, 924790)}
2018-11-23 11:32:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:33:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:33:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:33:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:33:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:33:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:33:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:33:15 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:33:15 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:33:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:33:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:33:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:33:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:33:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 33, 16, 395736),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 626647040,
 'memusage/startup': 626647040,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 33, 15, 344380)}
2018-11-23 11:33:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:33:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:33:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:33:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:33:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:33:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:33:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:33:47 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:33:47 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:33:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:33:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:33:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:33:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 33, 47, 433157),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 641396736,
 'memusage/startup': 641396736,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 33, 47, 153288)}
2018-11-23 11:33:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:35:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:35:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:35:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:35:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:35:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:35:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:35:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:35:48 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:35:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:35:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:35:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:35:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 35, 48, 881264),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 674578432,
 'memusage/startup': 674578432,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 35, 48, 603891)}
2018-11-23 11:35:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:36:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:36:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:36:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:36:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:36:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:36:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:36:14 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:36:14 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:36:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:36:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:36:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:36:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 36, 15, 137580),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 676872192,
 'memusage/startup': 676872192,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 36, 14, 848298)}
2018-11-23 11:36:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:36:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:36:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:36:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:36:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:36:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:36:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:36:27 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:36:27 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:36:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:36:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:36:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:36:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:36:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 36, 28, 133133),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 679489536,
 'memusage/startup': 679489536,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 36, 27, 844664)}
2018-11-23 11:36:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:42:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:42:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:42:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:42:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:42:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:42:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:42:19 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:42:19 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:42:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:42:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:42:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/bturltext.html> (referer: None)
2018-11-23 11:42:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20> (referer: None)
2018-11-23 11:42:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=i%20simpson%20>
{'click': '1',
 'ctime': '2018-11-20',
 'fanyi': '',
 'filename': 'I.Simpson.29x06.Marge.Sindaca.iTALiAN.AC3.Dvb.x264.720p.by.Alex69Picci.mkv',
 'length': '400.4 MB',
 'link': 'magnet:?xt=urn:btih:CFBD561A52C181C781F4FA95ADBE8C3CBB3921C3'}
2018-11-23 11:42:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:42:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 543,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5165,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 42, 19, 722544),
 'item_scraped_count': 1,
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'memusage/max': 717811712,
 'memusage/startup': 717811712,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 11, 23, 3, 42, 19, 440753)}
2018-11-23 11:42:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:44:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:44:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:44:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:44:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:44:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:44:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:44:58 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:44:58 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:44:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:44:58 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:44:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-23 11:44:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-23 11:44:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-23 11:44:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/54F97B55775B396D850ED829EA8640430BAD5665.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:44:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A81F1A707EA1E8519403923FEBED36EC9778750B.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1107208049DB5084F24B5FEFF616C9F264D4E673.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mastershef%20> (referer: None)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpuyasubs%21%5D%20seishun%20buta%20yarou%20wa%20bunny%20girl%20senpai%20no%20yume%20wo%20minai%20-%20> (referer: None)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4BE0629DFA8F7FE78718171F027AB1405DA93163.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mastershef%20>
{'click': '11',
 'ctime': '2018-11-21',
 'fanyi': 'mastershef',
 'filename': 'MasterShef 8 (25 vypusk)(2018).WEB-DL(720p)_by_UCHETer.mkv',
 'length': '3.2 GB',
 'link': 'magnet:?xt=urn:btih:54F97B55775B396D850ED829EA8640430BAD5665'}
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2DCBBF12575A632E5AE47215ADE95CE1377254A7.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpuyasubs%21%5D%20seishun%20buta%20yarou%20wa%20bunny%20girl%20senpai%20no%20yume%20wo%20minai%20-%20>
{'click': '4',
 'ctime': '2018-11-21',
 'fanyi': '[puyasubs !]seishunyarou senpaiyumeminai',
 'filename': '[PuyaSubs!] Seishun Buta Yarou wa Bunny Girl Senpai no Yume wo '
             'Minai - 08 [1080p][5DD38C95].mkv',
 'length': '708.5 MB',
 'link': 'magnet:?xt=urn:btih:1107208049DB5084F24B5FEFF616C9F264D4E673'}
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2FA2063A7F26A57D8ADB8C84A464237CEE9E8152.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D908C30E7DDFC0D7B54B76D0FF70375CEF2DE73D.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20last%20kingdom%20s> (referer: None)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/419EFD64026747C2209D1CA5C322E4310A88A343.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=gun%20city%20> (referer: None)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/59A2420490C6EDF333719C328459852F1E667CB9.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20last%20kingdom%20s>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Last.Kingdom.S03E04.WEB.x264-CRiMSON[eztv].mkv',
 'length': '551.7 MB',
 'link': 'magnet:?xt=urn:btih:4BE0629DFA8F7FE78718171F027AB1405DA93163'}
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/C15197E2137CAE0B30BD3DA900FFBC6E71129B37.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20princess%20switch%20> (referer: None)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=gun%20city%20>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Gun.City.2018.French.2O18.P.WEB-DL.72Op.mkv',
 'length': '4.7 GB',
 'link': 'magnet:?xt=urn:btih:2DCBBF12575A632E5AE47215ADE95CE1377254A7'}
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6278851006185D518C4D694D53CD03C0643E9A14.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=seal%20team%20s> (referer: None)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dc%27s%20legends%20of%20tomorrow%20s> (referer: None)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20princess%20switch%20>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The Princess Switch 2018 WEB-DL 1080p.mkv',
 'length': '3.9 GB',
 'link': 'magnet:?xt=urn:btih:2FA2063A7F26A57D8ADB8C84A464237CEE9E8152'}
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1E914CAB20B93CEFC2C1FD62D0C32038E146052B.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20walking%20dead%20> (referer: None)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=seal%20team%20s>
{'click': '21',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Seal.Team.s02e07.WEBDL.1080p.NewStudio.TV.mkv',
 'length': '1.8 GB',
 'link': 'magnet:?xt=urn:btih:D908C30E7DDFC0D7B54B76D0FF70375CEF2DE73D'}
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dc%27s%20legends%20of%20tomorrow%20s>
{'click': '6',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': "DC's.Legends.of.Tomorrow.S04E05.Tagumo.Attacks.1080p.WEBRip.6CH.x265.HEVC-PSA.mkv",
 'length': '597.6 MB',
 'link': 'magnet:?xt=urn:btih:419EFD64026747C2209D1CA5C322E4310A88A343'}
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ufak%20tefek%20cinayetler%20> (referer: None)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20walking%20dead%20>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Walking.Dead.9x07.Stradivari.ITA.DLMux.x264-UBi.mkv',
 'length': '366.6 MB',
 'link': 'magnet:?xt=urn:btih:C15197E2137CAE0B30BD3DA900FFBC6E71129B37'}
2018-11-23 11:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20flash%20> (referer: None)
2018-11-23 11:45:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ufak%20tefek%20cinayetler%20>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'ufak tefek cinayetler',
 'filename': 'Ufak Tefek Cinayetler 40. Blm (06.11.2018) HD 1080P WEBRP AAC '
             'H264-LSRG.mkv',
 'length': '2.7 GB',
 'link': 'magnet:?xt=urn:btih:6278851006185D518C4D694D53CD03C0643E9A14'}
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20flash%20>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Flash.2014.S05E06.720p.HDTV.x265-MiNX[eztv].mkv',
 'length': '200.9 MB',
 'link': 'magnet:?xt=urn:btih:1E914CAB20B93CEFC2C1FD62D0C32038E146052B'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4D7C8EDC614FF822DF4ACE3F58A3B293D92331F9.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/71A72031F0BD308C955BE04C9F0CB4F2E02BC282.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3D6287CE73FCD64E28A0268F1499C678E4E6FB25.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1860597E9BD7D9B27CC3281FB4984D77D8516FE3.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tejasvini%20%28aramm%29%20%28> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/63D3F07351494E4015CFE306B349FA307DA448EA.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tejasvini%20%28aramm%29%20%28>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '(aramm)(tejasvini',
 'filename': 'Tejasvini (Aramm) (2018) 720p Hindi HDRip x264 AAC by '
             'Full4movies.mkv',
 'length': '855.1 MB',
 'link': 'magnet:?xt=urn:btih:4D7C8EDC614FF822DF4ACE3F58A3B293D92331F9'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5B%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82www%20dy> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=idiocracy%20%28> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/50CF80A496B66A688A951DA55FA3D56A440920D8.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/852BBE5EC4A6E89A22A46830A5EA28AA22F42EE1.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dogman%20> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5B%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82www%20dy>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'WWW dy [movie heaven',
 'filename': '[www.dy2018.com]BD.mkv',
 'length': '1.1 GB',
 'link': 'magnet:?xt=urn:btih:71A72031F0BD308C955BE04C9F0CB4F2E02BC282'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/77EA23BC690197222EECF0680B66137475A4C73E.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/DB8A7362A92E5F26FDE3BE25CE3260DD6F8519E2.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20vanilla%20ice%20project%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=idiocracy%20%28>
{'click': '27',
 'ctime': '2018-11-21',
 'fanyi': '(',
 'filename': 'Idiocracy (2006) WEBRip 1080p H.265 [UKR_ENG].mkv',
 'length': '3.4 GB',
 'link': 'magnet:?xt=urn:btih:1860597E9BD7D9B27CC3281FB4984D77D8516FE3'}
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dogman%20>
{'click': '7',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Dogman.2O18.P.BDRip.72Op_KOSHARA.mkv',
 'length': '5.2 GB',
 'link': 'magnet:?xt=urn:btih:3D6287CE73FCD64E28A0268F1499C678E4E6FB25'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1900D64A5EE99F870E927FC9320F40E262C8B861.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/E242FC2BB964C641BB0A468D1DDE6929E2D338F3.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20vanilla%20ice%20project%20s>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Vanilla.Ice.Project.S08E06.Working.Out.the.Foyer.720p.WEB.x264-KOMPOST[eztv].mkv',
 'length': '458.5 MB',
 'link': 'magnet:?xt=urn:btih:63D3F07351494E4015CFE306B349FA307DA448EA'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D8E9F7CFEC6125D6B497D7D92DD841329A169696.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D6B04B662664BEB176D8FFA7A6D7D2F794452512.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20conception%20-%20> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=good%20eats-reloaded%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20little%20stranger%20> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20is%20us%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2DD7FB7FC81BC01D1732A0F2E6E33A74E5424A77.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E6%9D%80%E4%BA%BA%E6%BC%AB%E7%94%BB%20killer%20toon%20> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20conception%20-%20>
{'click': '4',
 'ctime': '2018-11-21',
 'fanyi': 'horriblesubs][-',
 'filename': '[HorribleSubs] Conception - 07 [480p].mkv',
 'length': '135.6 MB',
 'link': 'magnet:?xt=urn:btih:852BBE5EC4A6E89A22A46830A5EA28AA22F42EE1'}
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=good%20eats-reloaded%20s>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'eats-reloaded',
 'filename': 'Good.Eats-Reloaded.S01E04.The.Dough.Also.Rises-Reloaded.720p.WEB.x264-KOMPOST[eztv].mkv',
 'length': '458.0 MB',
 'link': 'magnet:?xt=urn:btih:50CF80A496B66A688A951DA55FA3D56A440920D8'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/FBED025850FB03CDAB6BD19CDA0B523F58269A0C.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A883F987CFEABDABE1550D05BEC20D9279DFD73D.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/FF42EE1953317CB1995A91CDB0D6209388706AB9.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D01EB7D087B3CC41C87A58373A2BF9E9E369DA12.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sorry%20for%20your%20loss%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20little%20stranger%20>
{'click': '4',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Little.Stranger.2018.720p.WEBRip.HiWayGrope.mkv',
 'length': '2.5 GB',
 'link': 'magnet:?xt=urn:btih:DB8A7362A92E5F26FDE3BE25CE3260DD6F8519E2'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tomorrow%20tonight%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20is%20us%20s>
{'click': '16',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'This.Is.Us.S03E08.HDTV.x264-SVA[eztv].mkv',
 'length': '271.1 MB',
 'link': 'magnet:?xt=urn:btih:77EA23BC690197222EECF0680B66137475A4C73E'}
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E6%9D%80%E4%BA%BA%E6%BC%AB%E7%94%BB%20killer%20toon%20>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': 'Killer comic killer toon',
 'filename': '.Killer.Toon.2013.Bluray.1080p.HEVC.10bit-GHFLY.mkv',
 'length': '2.8 GB',
 'link': 'magnet:?xt=urn:btih:E242FC2BB964C641BB0A468D1DDE6929E2D338F3'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/93285D29876D8467D8F5C83D5CFB8A93BC43B1CF.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=uel%20> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sorry%20for%20your%20loss%20s>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Sorry.For.Your.Loss.S01E09.1080p.rus.HDREZKA.AG.mkv',
 'length': '867.4 MB',
 'link': 'magnet:?xt=urn:btih:D8E9F7CFEC6125D6B497D7D92DD841329A169696'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/F6CF1C9E0A612B99DFDB578F1FC8A41A91084078.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5D75FEBE6DCE228613A17F1C6AB095C62E5F4F1B.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ncis%20new%20orleans%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tomorrow%20tonight%20s>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Tomorrow.Tonight.S01E03.720p.HDTV.x264-CCT[eztv].mkv',
 'length': '934.3 MB',
 'link': 'magnet:?xt=urn:btih:D6B04B662664BEB176D8FFA7A6D7D2F794452512'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1F3BC5A1B7E39F418DF76E026654776ADEBBC740.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20week%20tonight%20with%20john%20oliver%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=shark%20il%20primo%20squalo%20> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=texas%20flip%20n%20move%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=uel%20>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'UEL 2018 - Qualifying - Maribor vs Rangers - 2018 08 17 - 720p - '
             'English.mkv',
 'length': '2.0 GB',
 'link': 'magnet:?xt=urn:btih:2DD7FB7FC81BC01D1732A0F2E6E33A74E5424A77'}
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ncis%20new%20orleans%20s>
{'click': '9',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'NCIS.New.Orleans.S05E08.720p.HDTV.x264-300MB.mkv',
 'length': '292.0 MB',
 'link': 'magnet:?xt=urn:btih:A883F987CFEABDABE1550D05BEC20D9279DFD73D'}
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20week%20tonight%20with%20john%20oliver%20s>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Last.Week.Tonight.With.John.Oliver.S05E30.720p.HDTV.X264-UAV[eztv].mkv',
 'length': '854.7 MB',
 'link': 'magnet:?xt=urn:btih:FBED025850FB03CDAB6BD19CDA0B523F58269A0C'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D0F06A7DCBCF6554C677B2318B6CDCEC5F325DC0.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=shark%20il%20primo%20squalo%20>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'ilsqualo',
 'filename': 'Shark.Il.Primo.Squalo.2018.1080p.BRRip.x264.AC3.ITA.Cris600.mkv',
 'length': '2.3 GB',
 'link': 'magnet:?xt=urn:btih:D01EB7D087B3CC41C87A58373A2BF9E9E369DA12'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20jim%20jefferies%20show%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fifa%20football%20awards%20> (referer: None)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3B9D410B9183DBEE3EF1276D4CA3D72C7BBA42F9.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ice%20cold%20killers%20s> (referer: None)
2018-11-23 11:45:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=texas%20flip%20n%20move%20s>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': 'n s',
 'filename': 'Texas.Flip.N.Move.S10E10.Shotgun.Shanty.vs.Garden.Digs.720p.WEB.x264-KOMPOST[eztv].mkv',
 'length': '913.9 MB',
 'link': 'magnet:?xt=urn:btih:FF42EE1953317CB1995A91CDB0D6209388706AB9'}
2018-11-23 11:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20simpsons%20s> (referer: None)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3B2037C2DA2D00B0DA4EA228FABAE2423A251EE9.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20jim%20jefferies%20show%20s>
{'click': '8',
 'ctime': '2018-11-21',
 'fanyi': 'jefferies',
 'filename': 'the.jim.jefferies.show.s02e30.720p.web.x264-tbs[eztv].mkv',
 'length': '378.7 MB',
 'link': 'magnet:?xt=urn:btih:93285D29876D8467D8F5C83D5CFB8A93BC43B1CF'}
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fifa%20football%20awards%20>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '3002166',
 'filename': 'Fifa Football Awards 2018 - 2018 09 24 - 720p - English.mkv',
 'length': '1.2 GB',
 'link': 'magnet:?xt=urn:btih:5D75FEBE6DCE228613A17F1C6AB095C62E5F4F1B'}
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ice%20cold%20killers%20s>
{'click': '18',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'ice.cold.killers.s03e06.720p.hdtv.x264-w4f[eztv].mkv',
 'length': '923.8 MB',
 'link': 'magnet:?xt=urn:btih:F6CF1C9E0A612B99DFDB578F1FC8A41A91084078'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=teen%20mom%20s> (referer: None)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20simpsons%20s>
{'click': '4',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Simpsons.s30e07.720p.WEB.x264-300MB.mkv',
 'length': '159.6 MB',
 'link': 'magnet:?xt=urn:btih:1F3BC5A1B7E39F418DF76E026654776ADEBBC740'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A2D115EDA92F8A5F9519E04ACB9509BE8BD4E360.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=chak%20de%21%20india%20> (referer: None)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/357F95393076F7362A4A0902D07307431D9795B4.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/18B16FF9D69599A8C933D62C2A500CFAE8F250F8.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=new%20amsterdam%20> (referer: None)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=teen%20mom%20s>
{'click': '12',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'teen.mom.s07e26.720p.web.x264-tbs[eztv].mkv',
 'length': '769.8 MB',
 'link': 'magnet:?xt=urn:btih:D0F06A7DCBCF6554C677B2318B6CDCEC5F325DC0'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=true%20blood%20s> (referer: None)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=chak%20de%21%20india%20>
{'click': '6',
 'ctime': '2018-11-21',
 'fanyi': '!',
 'filename': 'Chak De! India 2007 BDRip 1080p x264 2Rus.mkv',
 'length': '16.7 GB',
 'link': 'magnet:?xt=urn:btih:3B9D410B9183DBEE3EF1276D4CA3D72C7BBA42F9'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D8C544B4F13C25B8DCCA1F20E8C17A9525429B4D.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20predator%20> (referer: None)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=new%20amsterdam%20>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'New.Amsterdam.2018.S01E08.720p.HDTV.2CH.x265.HEVC-PSA.mkv',
 'length': '192.4 MB',
 'link': 'magnet:?xt=urn:btih:3B2037C2DA2D00B0DA4EA228FABAE2423A251EE9'}
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=true%20blood%20s>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'True.Blood.S04E01.720p.HDTV.X264-DIMENSION.mkv',
 'length': '2.0 GB',
 'link': 'magnet:?xt=urn:btih:A2D115EDA92F8A5F9519E04ACB9509BE8BD4E360'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=pocket%20monsters%20sun%20%26%20moon%20-%20> (referer: None)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20predator%20>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Predator.2018.1080p.5.1.rus.HDREZKA.AG.mkv',
 'length': '3.5 GB',
 'link': 'magnet:?xt=urn:btih:357F95393076F7362A4A0902D07307431D9795B4'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=children%20of%20bodom%20-%20live%20%40%20hellfest%20%28> (referer: None)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/60F43A6CA287C703D9AEA4A1A8D46F702D4D7923.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=pocket%20monsters%20sun%20%26%20moon%20-%20>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Pocket Monsters Sun & Moon - 064 (TVh 1280x720 x264 AAC).mkv',
 'length': '304.1 MB',
 'link': 'magnet:?xt=urn:btih:18B16FF9D69599A8C933D62C2A500CFAE8F250F8'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/E0004DE0871836E945EFE35E612315FBFEB0494F.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=children%20of%20bodom%20-%20live%20%40%20hellfest%20%28>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '@ hellfest(',
 'filename': 'Children Of Bodom - Live @ Hellfest (2018).mkv',
 'length': '2.2 GB',
 'link': 'magnet:?xt=urn:btih:D8C544B4F13C25B8DCCA1F20E8C17A9525429B4D'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/BED8C953F9A2035D65AA85428A1BA046438132B7.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mom%20s> (referer: None)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20conners%20s> (referer: None)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A1FF3BB3B95753733E5DCD695D10ECBC31D51493.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=shuudengo%2C%20capsule%20hotel%20de%2C%20joushi%20ni%20binetsu%20tsutawaru%20yoru%20%20-%20> (referer: None)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mom%20s>
{'click': '20',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Mom.S06E08.720p.WEB.x264-300MB.mkv',
 'length': '156.8 MB',
 'link': 'magnet:?xt=urn:btih:E0004DE0871836E945EFE35E612315FBFEB0494F'}
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20conners%20s>
{'click': '12',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Conners.S01E04.1080p.rus.HDREZKA.AG.mkv',
 'length': '1.1 GB',
 'link': 'magnet:?xt=urn:btih:60F43A6CA287C703D9AEA4A1A8D46F702D4D7923'}
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=shuudengo%2C%20capsule%20hotel%20de%2C%20joushi%20ni%20binetsu%20tsutawaru%20yoru%20%20-%20>
{'click': '10',
 'ctime': '2018-11-21',
 'fanyi': 'de,shuudengo joushibinetsu tsutawaru-',
 'filename': 'Shuudengo, Capsule Hotel de, Joushi ni Binetsu Tsutawaru Yoru. - '
             '07 (1280x720 Hi10P AAC).mkv',
 'length': '57.8 MB',
 'link': 'magnet:?xt=urn:btih:BED8C953F9A2035D65AA85428A1BA046438132B7'}
2018-11-23 11:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=power%20office%20girls%20s> (referer: None)
2018-11-23 11:45:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=power%20office%20girls%20s>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Power.Office.Girls.S04E01.WEB.x264-WaLMaRT[eztv].mkv',
 'length': '722.5 MB',
 'link': 'magnet:?xt=urn:btih:A1FF3BB3B95753733E5DCD695D10ECBC31D51493'}
2018-11-23 11:45:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:45:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 32596,
 'downloader/request_count': 90,
 'downloader/request_method_count/GET': 90,
 'downloader/response_bytes': 123778,
 'downloader/response_count': 90,
 'downloader/response_status_count/200': 90,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 45, 2, 911271),
 'item_scraped_count': 42,
 'log_count/DEBUG': 133,
 'log_count/INFO': 7,
 'memusage/max': 724967424,
 'memusage/startup': 724967424,
 'request_depth_max': 2,
 'response_received_count': 90,
 'scheduler/dequeued': 90,
 'scheduler/dequeued/memory': 90,
 'scheduler/enqueued': 90,
 'scheduler/enqueued/memory': 90,
 'start_time': datetime.datetime(2018, 11, 23, 3, 44, 58, 354556)}
2018-11-23 11:45:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 11:57:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 11:57:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 11:57:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 11:57:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 11:57:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 11:57:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 11:57:55 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 11:57:55 [scrapy.core.engine] INFO: Spider opened
2018-11-23 11:57:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 11:57:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 11:57:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/54F97B55775B396D850ED829EA8640430BAD5665.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A81F1A707EA1E8519403923FEBED36EC9778750B.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mastershef%20> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1107208049DB5084F24B5FEFF616C9F264D4E673.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mastershef%20>
{'click': '11',
 'ctime': '2018-11-21',
 'fanyi': 'mastershef',
 'filename': 'MasterShef 8 (25 vypusk)(2018).WEB-DL(720p)_by_UCHETer.mkv',
 'length': '3.2 GB',
 'link': 'magnet:?xt=urn:btih:54F97B55775B396D850ED829EA8640430BAD5665'}
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/71A72031F0BD308C955BE04C9F0CB4F2E02BC282.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4BE0629DFA8F7FE78718171F027AB1405DA93163.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2FA2063A7F26A57D8ADB8C84A464237CEE9E8152.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/C15197E2137CAE0B30BD3DA900FFBC6E71129B37.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpuyasubs%21%5D%20seishun%20buta%20yarou%20wa%20bunny%20girl%20senpai%20no%20yume%20wo%20minai%20-%20> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/77EA23BC690197222EECF0680B66137475A4C73E.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20last%20kingdom%20s> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6278851006185D518C4D694D53CD03C0643E9A14.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5B%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82www%20dy> (referer: None)
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpuyasubs%21%5D%20seishun%20buta%20yarou%20wa%20bunny%20girl%20senpai%20no%20yume%20wo%20minai%20-%20>
{'click': '4',
 'ctime': '2018-11-21',
 'fanyi': '[puyasubs !]seishun',
 'filename': '[PuyaSubs!] Seishun Buta Yarou wa Bunny Girl Senpai no Yume wo '
             'Minai - 08 [1080p][5DD38C95].mkv',
 'length': '708.5 MB',
 'link': 'magnet:?xt=urn:btih:1107208049DB5084F24B5FEFF616C9F264D4E673'}
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/59A2420490C6EDF333719C328459852F1E667CB9.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4D7C8EDC614FF822DF4ACE3F58A3B293D92331F9.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20last%20kingdom%20s>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Last.Kingdom.S03E04.WEB.x264-CRiMSON[eztv].mkv',
 'length': '551.7 MB',
 'link': 'magnet:?xt=urn:btih:4BE0629DFA8F7FE78718171F027AB1405DA93163'}
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20walking%20dead%20> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20princess%20switch%20> (referer: None)
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5B%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82www%20dy>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'WWW dy [movie heaven',
 'filename': '[www.dy2018.com]BD.mkv',
 'length': '1.1 GB',
 'link': 'magnet:?xt=urn:btih:71A72031F0BD308C955BE04C9F0CB4F2E02BC282'}
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20is%20us%20s> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ufak%20tefek%20cinayetler%20> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/FBED025850FB03CDAB6BD19CDA0B523F58269A0C.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20walking%20dead%20>
{'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Walking.Dead.9x07.Stradivari.ITA.DLMux.x264-UBi.mkv',
 'length': '366.6 MB',
 'link': 'magnet:?xt=urn:btih:C15197E2137CAE0B30BD3DA900FFBC6E71129B37'}
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20princess%20switch%20>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The Princess Switch 2018 WEB-DL 1080p.mkv',
 'length': '3.9 GB',
 'link': 'magnet:?xt=urn:btih:2FA2063A7F26A57D8ADB8C84A464237CEE9E8152'}
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20is%20us%20s>
{'click': '16',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'This.Is.Us.S03E08.HDTV.x264-SVA[eztv].mkv',
 'length': '271.1 MB',
 'link': 'magnet:?xt=urn:btih:77EA23BC690197222EECF0680B66137475A4C73E'}
2018-11-23 11:57:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ufak%20tefek%20cinayetler%20>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'ufak tefek cinayetle',
 'filename': 'Ufak Tefek Cinayetler 40. Blm (06.11.2018) HD 1080P WEBRP AAC '
             'H264-LSRG.mkv',
 'length': '2.7 GB',
 'link': 'magnet:?xt=urn:btih:6278851006185D518C4D694D53CD03C0643E9A14'}
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/419EFD64026747C2209D1CA5C322E4310A88A343.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/C07DE0019A14F7FDBFDE49126414564186777E07.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A2A08CA54635C68B9854562B76EC1049C4B55954.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tejasvini%20%28aramm%29%20%28> (referer: None)
2018-11-23 11:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20week%20tonight%20with%20john%20oliver%20s> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4B92EC104DE108554FB598CC399C3475D270152A.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D908C30E7DDFC0D7B54B76D0FF70375CEF2DE73D.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dc%27s%20legends%20of%20tomorrow%20s> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tejasvini%20%28aramm%29%20%28>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '(aramm)(tejasvini',
 'filename': 'Tejasvini (Aramm) (2018) 720p Hindi HDRip x264 AAC by '
             'Full4movies.mkv',
 'length': '855.1 MB',
 'link': 'magnet:?xt=urn:btih:4D7C8EDC614FF822DF4ACE3F58A3B293D92331F9'}
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20week%20tonight%20with%20john%20oliver%20s>
{'click': '3',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Last.Week.Tonight.With.John.Oliver.S05E30.720p.HDTV.X264-UAV[eztv].mkv',
 'length': '854.7 MB',
 'link': 'magnet:?xt=urn:btih:FBED025850FB03CDAB6BD19CDA0B523F58269A0C'}
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=impossible%20s> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3FB6A05AA967919E1F4FB55CC955E4D7DCFC7B83.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dc%27s%20legends%20of%20tomorrow%20s>
{'click': '6',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': "DC's.Legends.of.Tomorrow.S04E05.Tagumo.Attacks.1080p.WEBRip.6CH.x265.HEVC-PSA.mkv",
 'length': '597.6 MB',
 'link': 'magnet:?xt=urn:btih:419EFD64026747C2209D1CA5C322E4310A88A343'}
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2DCBBF12575A632E5AE47215ADE95CE1377254A7.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=impossible%20s>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Impossible.S05E16.720p.WEB.h264-WEBTUBE[eztv].mkv',
 'length': '1.6 GB',
 'link': 'magnet:?xt=urn:btih:A2A08CA54635C68B9854562B76EC1049C4B55954'}
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=seal%20team%20s> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/0C15202B36017A82B66E7FA5EFEFC52A602FEFB3.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20> (referer: None)
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=seal%20team%20s>
{'click': '21',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Seal.Team.s02e07.WEBDL.1080p.NewStudio.TV.mkv',
 'length': '1.8 GB',
 'link': 'magnet:?xt=urn:btih:D908C30E7DDFC0D7B54B76D0FF70375CEF2DE73D'}
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'The Equalizer 2014 m1080p DUAL BluRay x264 - HdT.mkv',
 'length': '2.7 GB',
 'link': 'magnet:?xt=urn:btih:4B92EC104DE108554FB598CC399C3475D270152A'}
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6BE186BF2DF4577096477CFE5738195FF5CA45FC.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20jingai-san%20no%20yome%20-%20> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6E7019AC97C23BB99FDCBF558A9BAC8708840094.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/E7AD7D28BC9ACDE5882FA731F741FE85DBC1F793.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%B1%D0%BE%D0%B1%D1%80%D0%BE%D0%B2%D1%8B%20%28> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A56D39962F3304D80C79D6AD99EF681B723806F3.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20jingai-san%20no%20yome%20-%20>
{'click': '13',
 'ctime': '2018-11-22',
 'fanyi': '[yome - horriblesub',
 'filename': '[HorribleSubs] Jingai-san no Yome - 08 [720p].mkv',
 'length': '55.0 MB',
 'link': 'magnet:?xt=urn:btih:0C15202B36017A82B66E7FA5EFEFC52A602FEFB3'}
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3E915B6AE2DEA156C6A1D4BDA315BF40BA7F2783.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vingadores%20guerra%20infinita%20> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=gun%20city%20> (referer: None)
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%B1%D0%BE%D0%B1%D1%80%D0%BE%D0%B2%D1%8B%20%28>
{'click': '4',
 'ctime': '2018-11-22',
 'fanyi': '(',
 'filename': ' (2016).mkv',
 'length': '836.2 MB',
 'link': 'magnet:?xt=urn:btih:3FB6A05AA967919E1F4FB55CC955E4D7DCFC7B83'}
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=normandie%20nue%20> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ncis%20new%20orleans%20s> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1C4E16CC9DEEBE261F81D3B76DA654DADAF5715D.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vingadores%20guerra%20infinita%20>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': 'vingadores',
 'filename': 'Vingadores.Guerra.Infinita.2018.720p.BluRay.x264.DUAL.WWW.COMANDOTORRENTS.COM.mkv',
 'length': '2.2 GB',
 'link': 'magnet:?xt=urn:btih:6BE186BF2DF4577096477CFE5738195FF5CA45FC'}
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=gun%20city%20>
{'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Gun.City.2018.French.2O18.P.WEB-DL.72Op.mkv',
 'length': '4.7 GB',
 'link': 'magnet:?xt=urn:btih:2DCBBF12575A632E5AE47215ADE95CE1377254A7'}
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=normandie%20nue%20>
{'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Normandie.Nue.2018.FRENCH.720p.BluRay.x264-UTT.mkv',
 'length': '4.4 GB',
 'link': 'magnet:?xt=urn:btih:6E7019AC97C23BB99FDCBF558A9BAC8708840094'}
2018-11-23 11:57:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ncis%20new%20orleans%20s>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'NCIS.New.Orleans.S05E08.Close.to.Home.720p.WEBRip.2CH.x265.HEVC-PSA.mkv',
 'length': '224.0 MB',
 'link': 'magnet:?xt=urn:btih:E7AD7D28BC9ACDE5882FA731F741FE85DBC1F793'}
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/F678902CA972659E570703D2D72A94B9318A5093.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/EBDCBE7DE4885A1A6A4C326BA14F93A58DBD224F.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/369550E71E1D638D2E6EEAFDC3A2D4DFD892FE43.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=take%20me%20out%20s> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Busp%20raws%5D%20pingu%20in%20the%20city%20-%20> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4CC479896C6C2FA09976546E34E9F3D2C0DDB7F0.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=manifest%20s> (referer: None)
2018-11-23 11:57:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=kasyno%20-%20casino%20%28> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5828922A6912C42A85E2BF169E523D24B81F7192.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=homicide%20hunter%20s> (referer: None)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=take%20me%20out%20s>
{'click': '5',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Take.Me.Out.S10E01.WEB.x264-KOMPOST[eztv].mkv',
 'length': '535.6 MB',
 'link': 'magnet:?xt=urn:btih:1C4E16CC9DEEBE261F81D3B76DA654DADAF5715D'}
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Busp%20raws%5D%20pingu%20in%20the%20city%20-%20>
{'click': '15',
 'ctime': '2018-11-22',
 'fanyi': '(usp)',
 'filename': '[USP RAWS] Pingu in the City - 33 [30AEC174].mkv',
 'length': '61.6 MB',
 'link': 'magnet:?xt=urn:btih:3E915B6AE2DEA156C6A1D4BDA315BF40BA7F2783'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20nadigaiyar%20thilagam%20%28> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/AEEF45FD3D490613412A6083B0AA403071B9FD58.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=manifest%20s>
{'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Manifest.S01E08.HDTV.x264-KILLERS[eztv].mkv',
 'length': '235.9 MB',
 'link': 'magnet:?xt=urn:btih:A56D39962F3304D80C79D6AD99EF681B723806F3'}
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=kasyno%20-%20casino%20%28>
{'click': '5',
 'ctime': '2018-11-22',
 'fanyi': 'kasyno(',
 'filename': 'Kasyno - Casino (1995) [1080P] [BLURAY] [H264] [AC3-E1973] '
             '[LEKTOR PL].mkv',
 'length': '13.2 GB',
 'link': 'magnet:?xt=urn:btih:F678902CA972659E570703D2D72A94B9318A5093'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6893FAA2BA9D0C4DAA8A6ADBD2C6D15FE9D8D139.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/171047A56E2F126D28ACE1C0725DAF9890A6033E.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=homicide%20hunter%20s>
{'click': '2',
 'ctime': '2018-11-22',
 'fanyi': 'hunter s',
 'filename': 'homicide.hunter.s05e10.720p.hdtv.x264-w4f[eztv].mkv',
 'length': '689.1 MB',
 'link': 'magnet:?xt=urn:btih:EBDCBE7DE4885A1A6A4C326BA14F93A58DBD224F'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=uefa%20nation%20league%20-%20norway%20vs%20slovenia%20-%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20nadigaiyar%20thilagam%20%28>
{'click': '5',
 'ctime': '2018-11-22',
 'fanyi': 'nadigaiyar - tamilro',
 'filename': 'www.TamilRockers.by - Nadigaiyar Thilagam (2018) [1080p Proper '
             '(Final) HQ TRUE HD - AVC - Untouched - x264 - DD 5.1 (640Kbps) - '
             '8.3GB - ESubs - Tamil].mkv',
 'length': '8.3 GB',
 'link': 'magnet:?xt=urn:btih:369550E71E1D638D2E6EEAFDC3A2D4DFD892FE43'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6B5AE87AAEFE21F9CD6B47FAA20460CF57A6DE93.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=los%20increi%CC%81bles%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20golden%20kamuy%20-%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5CF33E8EF322DD84CE92BA2FF414470CB5101E4E.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=uefa%20nation%20league%20-%20norway%20vs%20slovenia%20-%20>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '-',
 'filename': 'UEFA Nation League - Norway vs Slovenia - 2018 10 13 - 1080p - '
             'English.mkv',
 'length': '4.3 GB',
 'link': 'magnet:?xt=urn:btih:4CC479896C6C2FA09976546E34E9F3D2C0DDB7F0'}
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=los%20increi%CC%81bles%20>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': 'increibles',
 'filename': 'Los Increibles 2 (2018)[BR m1080p x264 AC3(ES-EN) '
             'Subs(ES-EN-FORZ)].mkv',
 'length': '5.0 GB',
 'link': 'magnet:?xt=urn:btih:5828922A6912C42A85E2BF169E523D24B81F7192'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D0863C32082F8C3B203881E6E5A262B3E6FFAF4D.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=air%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20jim%20jefferies%20show%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20golden%20kamuy%20-%20>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': 'horriblesubs][kamu',
 'filename': '[HorribleSubs] Golden Kamuy - 19 [1080p].mkv',
 'length': '908.2 MB',
 'link': 'magnet:?xt=urn:btih:AEEF45FD3D490613412A6083B0AA403071B9FD58'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=full%20frontal%20with%20samantha%20bee%20s> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20clinton%20affair%20s> (referer: None)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=air%20>
{'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'AIR 03.mkv',
 'length': '1.1 GB',
 'link': 'magnet:?xt=urn:btih:6B5AE87AAEFE21F9CD6B47FAA20460CF57A6DE93'}
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20jim%20jefferies%20show%20>
{'click': '5',
 'ctime': '2018-11-22',
 'fanyi': 'jefferies',
 'filename': 'the.jim.jefferies.show.0230.720p-yestv[eztv].mkv',
 'length': '689.0 MB',
 'link': 'magnet:?xt=urn:btih:6893FAA2BA9D0C4DAA8A6ADBD2C6D15FE9D8D139'}
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=full%20frontal%20with%20samantha%20bee%20s>
{'click': '7',
 'ctime': '2018-11-22',
 'fanyi': 'samantha bee',
 'filename': 'full.frontal.with.samantha.bee.s03e28.720p.hdtv.x264-w4f[eztv].mkv',
 'length': '583.9 MB',
 'link': 'magnet:?xt=urn:btih:171047A56E2F126D28ACE1C0725DAF9890A6033E'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5D5EA2FADFBAEBA73AA659B36FA261794AF65697.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/7888B815176F8C6DB5F268221A2C469CCE3373DD.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20clinton%20affair%20s>
{'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'The.Clinton.Affair.S01E04.720p.HDTV.x264-LucidTV[eztv].mkv',
 'length': '736.8 MB',
 'link': 'magnet:?xt=urn:btih:5CF33E8EF322DD84CE92BA2FF414470CB5101E4E'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=double%20decker%21%20doug%20and%20kirill%20-%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/35027851459A7D79AA9D0E765FA896E786FDABDC.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5891639C324E754F5B4BA1470F57184DD3D7BD47.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=emo%20the%20musical%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=splitting%20up%20together%20s> (referer: None)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=double%20decker%21%20doug%20and%20kirill%20-%20>
{'click': '7',
 'ctime': '2018-11-22',
 'fanyi': '!kirill -',
 'filename': 'Double Decker! Doug and Kirill - 06 -vostfr - webrip.mkv',
 'length': '883.2 MB',
 'link': 'magnet:?xt=urn:btih:D0863C32082F8C3B203881E6E5A262B3E6FFAF4D'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6237585D3AA0BC213928C7E57C104C1317DC90AD.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bargain%20hunt%20s> (referer: None)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=emo%20the%20musical%20>
{'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Emo the Musical 2016 1080p NF WEB-DL H264 Eng Ac3 Sub Ita Eng '
             'Spa Fre Ger By Pulce0000 - T7ST.mkv',
 'length': '2.6 GB',
 'link': 'magnet:?xt=urn:btih:5D5EA2FADFBAEBA73AA659B36FA261794AF65697'}
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=splitting%20up%20together%20s>
{'click': '2',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Splitting.Up.Together.s02e04.WEBDL.1080p.NewStudio.TV.mkv',
 'length': '2.3 GB',
 'link': 'magnet:?xt=urn:btih:7888B815176F8C6DB5F268221A2C469CCE3373DD'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20tokyo%20ghoul%20re%20-%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20anima%20yell%21%20-%20> (referer: None)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bargain%20hunt%20s>
{'click': '5',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'bargain.hunt.s51e15.720p.hdtv-docere[eztv].mkv',
 'length': '860.6 MB',
 'link': 'magnet:?xt=urn:btih:35027851459A7D79AA9D0E765FA896E786FDABDC'}
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20tokyo%20ghoul%20re%20-%20>
{'click': '8',
 'ctime': '2018-11-22',
 'fanyi': '[horriblesubs]ghou',
 'filename': '[HorribleSubs] Tokyo Ghoul re - 19 [720p].mkv',
 'length': '309.3 MB',
 'link': 'magnet:?xt=urn:btih:5891639C324E754F5B4BA1470F57184DD3D7BD47'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/8BEFF336BE13DB55D5FAC4D192FCBB63876489E7.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20anima%20yell%21%20-%20>
{'click': '4',
 'ctime': '2018-11-22',
 'fanyi': '[horriblesubs]-',
 'filename': '[HorribleSubs] Anima Yell! - 07 [480p].mkv',
 'length': '158.7 MB',
 'link': 'magnet:?xt=urn:btih:6237585D3AA0BC213928C7E57C104C1317DC90AD'}
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20week%20at%20the%20comedy%20cellar%20s> (referer: None)
2018-11-23 11:57:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2DFFBE3ECB79A6A6AC866A7112C98E1BF2BFDFE6.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20week%20at%20the%20comedy%20cellar%20s>
{'click': '5',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'this.week.at.the.comedy.cellar.s01e04.web.x264-tbs[eztv].mkv',
 'length': '307.5 MB',
 'link': 'magnet:?xt=urn:btih:8BEFF336BE13DB55D5FAC4D192FCBB63876489E7'}
2018-11-23 11:58:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20taxiwala%20%28> (referer: None)
2018-11-23 11:58:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/0AE2BB6FBBEC63049A1A2CD4D4E929C0D2C97BAB.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 11:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20taxiwala%20%28>
{'click': '14',
 'ctime': '2018-11-22',
 'fanyi': 'www tamilrockersta',
 'filename': 'www.TamilRockers.by - Taxiwala (2018)[Telugu - 1080p - LEAKED - '
             'HDRip - 5.1 AC3 - x264 - 3GB].mkv',
 'length': '3.1 GB',
 'link': 'magnet:?xt=urn:btih:2DFFBE3ECB79A6A6AC866A7112C98E1BF2BFDFE6'}
2018-11-23 11:58:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=martyrs%20%28> (referer: None)
2018-11-23 11:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=martyrs%20%28>
{'click': '7',
 'ctime': '2018-11-22',
 'fanyi': '(',
 'filename': 'Martyrs (2008 ITA-FRE) [720p] [P92]_1.mkv',
 'length': '2.1 GB',
 'link': 'magnet:?xt=urn:btih:0AE2BB6FBBEC63049A1A2CD4D4E929C0D2C97BAB'}
2018-11-23 11:58:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 11:58:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34621,
 'downloader/request_count': 91,
 'downloader/request_method_count/GET': 91,
 'downloader/response_bytes': 123223,
 'downloader/response_count': 91,
 'downloader/response_status_count/200': 91,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 3, 58, 0, 402593),
 'item_scraped_count': 42,
 'log_count/DEBUG': 134,
 'log_count/INFO': 7,
 'memusage/max': 742158336,
 'memusage/startup': 742158336,
 'request_depth_max': 2,
 'response_received_count': 91,
 'scheduler/dequeued': 91,
 'scheduler/dequeued/memory': 91,
 'scheduler/enqueued': 91,
 'scheduler/enqueued/memory': 91,
 'start_time': datetime.datetime(2018, 11, 23, 3, 57, 55, 390560)}
2018-11-23 11:58:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 13:45:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-23 13:45:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-23 13:45:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-23 13:45:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 13:45:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 13:45:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 13:45:14 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-23 13:45:14 [scrapy.core.engine] INFO: Spider opened
2018-11-23 13:45:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 13:45:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-23 13:45:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_3.html> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_1.html> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/7888B815176F8C6DB5F268221A2C469CCE3373DD.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D0863C32082F8C3B203881E6E5A262B3E6FFAF4D.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/171047A56E2F126D28ACE1C0725DAF9890A6033E.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A2A08CA54635C68B9854562B76EC1049C4B55954.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=splitting%20up%20together%20s> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/35027851459A7D79AA9D0E765FA896E786FDABDC.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5D5EA2FADFBAEBA73AA659B36FA261794AF65697.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2DFFBE3ECB79A6A6AC866A7112C98E1BF2BFDFE6.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=splitting%20up%20together%20s>
{'baidu': 'splitting up together s',
 'click': '2',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Splitting.Up.Together.s02e04.WEBDL.1080p.NewStudio.TV.mkv',
 'length': '2.3 GB',
 'link': 'magnet:?xt=urn:btih:7888B815176F8C6DB5F268221A2C469CCE3373DD'}
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=impossible%20s> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=full%20frontal%20with%20samantha%20bee%20s> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=double%20decker%21%20doug%20and%20kirill%20-%20> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5891639C324E754F5B4BA1470F57184DD3D7BD47.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=impossible%20s>
{'baidu': 'impossible s',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Impossible.S05E16.720p.WEB.h264-WEBTUBE[eztv].mkv',
 'length': '1.6 GB',
 'link': 'magnet:?xt=urn:btih:A2A08CA54635C68B9854562B76EC1049C4B55954'}
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/AEEF45FD3D490613412A6083B0AA403071B9FD58.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=full%20frontal%20with%20samantha%20bee%20s>
{'baidu': 'full frontal with samantha bee s',
 'click': '7',
 'ctime': '2018-11-22',
 'fanyi': 'samantha bee',
 'filename': 'full.frontal.with.samantha.bee.s03e28.720p.hdtv.x264-w4f[eztv].mkv',
 'length': '583.9 MB',
 'link': 'magnet:?xt=urn:btih:171047A56E2F126D28ACE1C0725DAF9890A6033E'}
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20taxiwala%20%28> (referer: None)
2018-11-23 13:45:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=double%20decker%21%20doug%20and%20kirill%20-%20>
{'baidu': 'double decker! doug and kirill - ',
 'click': '7',
 'ctime': '2018-11-22',
 'fanyi': '!kirill -',
 'filename': 'Double Decker! Doug and Kirill - 06 -vostfr - webrip.mkv',
 'length': '883.2 MB',
 'link': 'magnet:?xt=urn:btih:D0863C32082F8C3B203881E6E5A262B3E6FFAF4D'}
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=emo%20the%20musical%20> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/C07DE0019A14F7FDBFDE49126414564186777E07.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bargain%20hunt%20s> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6E7019AC97C23BB99FDCBF558A9BAC8708840094.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/0AE2BB6FBBEC63049A1A2CD4D4E929C0D2C97BAB.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20taxiwala%20%28>
{'baidu': 'www tamilrockers by - taxiwala (',
 'click': '14',
 'ctime': '2018-11-22',
 'fanyi': 'www tamilrockersta',
 'filename': 'www.TamilRockers.by - Taxiwala (2018)[Telugu - 1080p - LEAKED - '
             'HDRip - 5.1 AC3 - x264 - 3GB].mkv',
 'length': '3.1 GB',
 'link': 'magnet:?xt=urn:btih:2DFFBE3ECB79A6A6AC866A7112C98E1BF2BFDFE6'}
2018-11-23 13:45:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=emo%20the%20musical%20>
{'baidu': 'emo the musical ',
 'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Emo the Musical 2016 1080p NF WEB-DL H264 Eng Ac3 Sub Ita Eng '
             'Spa Fre Ger By Pulce0000 - T7ST.mkv',
 'length': '2.6 GB',
 'link': 'magnet:?xt=urn:btih:5D5EA2FADFBAEBA73AA659B36FA261794AF65697'}
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4D7C8EDC614FF822DF4ACE3F58A3B293D92331F9.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20golden%20kamuy%20-%20> (referer: None)
2018-11-23 13:45:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bargain%20hunt%20s>
{'baidu': 'bargain hunt s',
 'click': '5',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'bargain.hunt.s51e15.720p.hdtv-docere[eztv].mkv',
 'length': '860.6 MB',
 'link': 'magnet:?xt=urn:btih:35027851459A7D79AA9D0E765FA896E786FDABDC'}
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6237585D3AA0BC213928C7E57C104C1317DC90AD.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20tokyo%20ghoul%20re%20-%20> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6278851006185D518C4D694D53CD03C0643E9A14.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5CF33E8EF322DD84CE92BA2FF414470CB5101E4E.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=normandie%20nue%20> (referer: None)
2018-11-23 13:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/FBED025850FB03CDAB6BD19CDA0B523F58269A0C.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=martyrs%20%28> (referer: None)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20golden%20kamuy%20-%20>
{'baidu': '[horriblesubs] golden kamuy - ',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': 'horriblesubs][kamu',
 'filename': '[HorribleSubs] Golden Kamuy - 19 [1080p].mkv',
 'length': '908.2 MB',
 'link': 'magnet:?xt=urn:btih:AEEF45FD3D490613412A6083B0AA403071B9FD58'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20tokyo%20ghoul%20re%20-%20>
{'baidu': '[horriblesubs] tokyo ghoul re - ',
 'click': '8',
 'ctime': '2018-11-22',
 'fanyi': '[horriblesubs]ghou',
 'filename': '[HorribleSubs] Tokyo Ghoul re - 19 [720p].mkv',
 'length': '309.3 MB',
 'link': 'magnet:?xt=urn:btih:5891639C324E754F5B4BA1470F57184DD3D7BD47'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/77EA23BC690197222EECF0680B66137475A4C73E.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tejasvini%20%28aramm%29%20%28> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20anima%20yell%21%20-%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=normandie%20nue%20>
{'baidu': 'normandie nue ',
 'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Normandie.Nue.2018.FRENCH.720p.BluRay.x264-UTT.mkv',
 'length': '4.4 GB',
 'link': 'magnet:?xt=urn:btih:6E7019AC97C23BB99FDCBF558A9BAC8708840094'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/71A72031F0BD308C955BE04C9F0CB4F2E02BC282.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ufak%20tefek%20cinayetler%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A81F1A707EA1E8519403923FEBED36EC9778750B.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20clinton%20affair%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=martyrs%20%28>
{'baidu': 'martyrs (',
 'click': '7',
 'ctime': '2018-11-22',
 'fanyi': '(',
 'filename': 'Martyrs (2008 ITA-FRE) [720p] [P92]_1.mkv',
 'length': '2.1 GB',
 'link': 'magnet:?xt=urn:btih:0AE2BB6FBBEC63049A1A2CD4D4E929C0D2C97BAB'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20week%20tonight%20with%20john%20oliver%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4BE0629DFA8F7FE78718171F027AB1405DA93163.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tejasvini%20%28aramm%29%20%28>
{'baidu': 'tejasvini (aramm) (',
 'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '(aramm)(tejasvini',
 'filename': 'Tejasvini (Aramm) (2018) 720p Hindi HDRip x264 AAC by '
             'Full4movies.mkv',
 'length': '855.1 MB',
 'link': 'magnet:?xt=urn:btih:4D7C8EDC614FF822DF4ACE3F58A3B293D92331F9'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20anima%20yell%21%20-%20>
{'baidu': '[horriblesubs] anima yell! - ',
 'click': '4',
 'ctime': '2018-11-22',
 'fanyi': '[horriblesubs]-',
 'filename': '[HorribleSubs] Anima Yell! - 07 [480p].mkv',
 'length': '158.7 MB',
 'link': 'magnet:?xt=urn:btih:6237585D3AA0BC213928C7E57C104C1317DC90AD'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ufak%20tefek%20cinayetler%20>
{'baidu': 'ufak tefek cinayetler ',
 'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'ufak tefek cinayetle',
 'filename': 'Ufak Tefek Cinayetler 40. Blm (06.11.2018) HD 1080P WEBRP AAC '
             'H264-LSRG.mkv',
 'length': '2.7 GB',
 'link': 'magnet:?xt=urn:btih:6278851006185D518C4D694D53CD03C0643E9A14'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2DCBBF12575A632E5AE47215ADE95CE1377254A7.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/2FA2063A7F26A57D8ADB8C84A464237CEE9E8152.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20clinton%20affair%20s>
{'baidu': 'the clinton affair s',
 'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'The.Clinton.Affair.S01E04.720p.HDTV.x264-LucidTV[eztv].mkv',
 'length': '736.8 MB',
 'link': 'magnet:?xt=urn:btih:5CF33E8EF322DD84CE92BA2FF414470CB5101E4E'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/419EFD64026747C2209D1CA5C322E4310A88A343.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20week%20tonight%20with%20john%20oliver%20s>
{'baidu': 'last week tonight with john oliver s',
 'click': '3',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Last.Week.Tonight.With.John.Oliver.S05E30.720p.HDTV.X264-UAV[eztv].mkv',
 'length': '854.7 MB',
 'link': 'magnet:?xt=urn:btih:FBED025850FB03CDAB6BD19CDA0B523F58269A0C'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20last%20kingdom%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/search/mkv_ctime_2.html> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20is%20us%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/D908C30E7DDFC0D7B54B76D0FF70375CEF2DE73D.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=gun%20city%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1107208049DB5084F24B5FEFF616C9F264D4E673.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dc%27s%20legends%20of%20tomorrow%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20princess%20switch%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/54F97B55775B396D850ED829EA8640430BAD5665.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20last%20kingdom%20s>
{'baidu': 'the last kingdom s',
 'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Last.Kingdom.S03E04.WEB.x264-CRiMSON[eztv].mkv',
 'length': '551.7 MB',
 'link': 'magnet:?xt=urn:btih:4BE0629DFA8F7FE78718171F027AB1405DA93163'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/C15197E2137CAE0B30BD3DA900FFBC6E71129B37.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20is%20us%20s>
{'baidu': 'this is us s',
 'click': '16',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'This.Is.Us.S03E08.HDTV.x264-SVA[eztv].mkv',
 'length': '271.1 MB',
 'link': 'magnet:?xt=urn:btih:77EA23BC690197222EECF0680B66137475A4C73E'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=gun%20city%20>
{'baidu': 'gun city ',
 'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Gun.City.2018.French.2O18.P.WEB-DL.72Op.mkv',
 'length': '4.7 GB',
 'link': 'magnet:?xt=urn:btih:2DCBBF12575A632E5AE47215ADE95CE1377254A7'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dc%27s%20legends%20of%20tomorrow%20s>
{'baidu': "dc's legends of tomorrow s",
 'click': '6',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': "DC's.Legends.of.Tomorrow.S04E05.Tagumo.Attacks.1080p.WEBRip.6CH.x265.HEVC-PSA.mkv",
 'length': '597.6 MB',
 'link': 'magnet:?xt=urn:btih:419EFD64026747C2209D1CA5C322E4310A88A343'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20princess%20switch%20>
{'baidu': 'the princess switch ',
 'click': '2',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The Princess Switch 2018 WEB-DL 1080p.mkv',
 'length': '3.9 GB',
 'link': 'magnet:?xt=urn:btih:2FA2063A7F26A57D8ADB8C84A464237CEE9E8152'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/59A2420490C6EDF333719C328459852F1E667CB9.html> (referer: https://www.bturl.cc/search/mkv_ctime_1.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20walking%20dead%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mastershef%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6BE186BF2DF4577096477CFE5738195FF5CA45FC.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpuyasubs%21%5D%20seishun%20buta%20yarou%20wa%20bunny%20girl%20senpai%20no%20yume%20wo%20minai%20-%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5B%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82www%20dy> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=seal%20team%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/8BEFF336BE13DB55D5FAC4D192FCBB63876489E7.html> (referer: https://www.bturl.cc/search/mkv_ctime_3.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20walking%20dead%20>
{'baidu': 'the walking dead ',
 'click': '1',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'The.Walking.Dead.9x07.Stradivari.ITA.DLMux.x264-UBi.mkv',
 'length': '366.6 MB',
 'link': 'magnet:?xt=urn:btih:C15197E2137CAE0B30BD3DA900FFBC6E71129B37'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mastershef%20>
{'baidu': 'mastershef ',
 'click': '11',
 'ctime': '2018-11-21',
 'fanyi': 'mastershef',
 'filename': 'MasterShef 8 (25 vypusk)(2018).WEB-DL(720p)_by_UCHETer.mkv',
 'length': '3.2 GB',
 'link': 'magnet:?xt=urn:btih:54F97B55775B396D850ED829EA8640430BAD5665'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpuyasubs%21%5D%20seishun%20buta%20yarou%20wa%20bunny%20girl%20senpai%20no%20yume%20wo%20minai%20-%20>
{'baidu': '[puyasubs!] seishun buta yarou wa bunny girl senpai no yume wo '
          'minai - ',
 'click': '4',
 'ctime': '2018-11-21',
 'fanyi': '[puyasubs !]seishun',
 'filename': '[PuyaSubs!] Seishun Buta Yarou wa Bunny Girl Senpai no Yume wo '
             'Minai - 08 [1080p][5DD38C95].mkv',
 'length': '708.5 MB',
 'link': 'magnet:?xt=urn:btih:1107208049DB5084F24B5FEFF616C9F264D4E673'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5B%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82www%20dy>
{'baidu': '[www dy',
 'click': '3',
 'ctime': '2018-11-21',
 'fanyi': 'WWW dy [movie heaven',
 'filename': '[www.dy2018.com]BD.mkv',
 'length': '1.1 GB',
 'link': 'magnet:?xt=urn:btih:71A72031F0BD308C955BE04C9F0CB4F2E02BC282'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vingadores%20guerra%20infinita%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6893FAA2BA9D0C4DAA8A6ADBD2C6D15FE9D8D139.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/0C15202B36017A82B66E7FA5EFEFC52A602FEFB3.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=seal%20team%20s>
{'baidu': 'seal team s',
 'click': '21',
 'ctime': '2018-11-21',
 'fanyi': '',
 'filename': 'Seal.Team.s02e07.WEBDL.1080p.NewStudio.TV.mkv',
 'length': '1.8 GB',
 'link': 'magnet:?xt=urn:btih:D908C30E7DDFC0D7B54B76D0FF70375CEF2DE73D'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20week%20at%20the%20comedy%20cellar%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/E7AD7D28BC9ACDE5882FA731F741FE85DBC1F793.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vingadores%20guerra%20infinita%20>
{'baidu': 'vingadores guerra infinita ',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': 'vingadores',
 'filename': 'Vingadores.Guerra.Infinita.2018.720p.BluRay.x264.DUAL.WWW.COMANDOTORRENTS.COM.mkv',
 'length': '2.2 GB',
 'link': 'magnet:?xt=urn:btih:6BE186BF2DF4577096477CFE5738195FF5CA45FC'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20jim%20jefferies%20show%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/A56D39962F3304D80C79D6AD99EF681B723806F3.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/EBDCBE7DE4885A1A6A4C326BA14F93A58DBD224F.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20jingai-san%20no%20yome%20-%20> (referer: None)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=this%20week%20at%20the%20comedy%20cellar%20s>
{'baidu': 'this week at the comedy cellar s',
 'click': '5',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'this.week.at.the.comedy.cellar.s01e04.web.x264-tbs[eztv].mkv',
 'length': '307.5 MB',
 'link': 'magnet:?xt=urn:btih:8BEFF336BE13DB55D5FAC4D192FCBB63876489E7'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3E915B6AE2DEA156C6A1D4BDA315BF40BA7F2783.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ncis%20new%20orleans%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20jim%20jefferies%20show%20>
{'baidu': 'the jim jefferies show ',
 'click': '5',
 'ctime': '2018-11-22',
 'fanyi': 'jefferies',
 'filename': 'the.jim.jefferies.show.0230.720p-yestv[eztv].mkv',
 'length': '689.0 MB',
 'link': 'magnet:?xt=urn:btih:6893FAA2BA9D0C4DAA8A6ADBD2C6D15FE9D8D139'}
2018-11-23 13:45:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bhorriblesubs%5D%20jingai-san%20no%20yome%20-%20>
{'baidu': '[horriblesubs] jingai-san no yome - ',
 'click': '13',
 'ctime': '2018-11-22',
 'fanyi': '[yome - horriblesub',
 'filename': '[HorribleSubs] Jingai-san no Yome - 08 [720p].mkv',
 'length': '55.0 MB',
 'link': 'magnet:?xt=urn:btih:0C15202B36017A82B66E7FA5EFEFC52A602FEFB3'}
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4CC479896C6C2FA09976546E34E9F3D2C0DDB7F0.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=manifest%20s> (referer: None)
2018-11-23 13:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=homicide%20hunter%20s> (referer: None)
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ncis%20new%20orleans%20s>
{'baidu': 'ncis new orleans s',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'NCIS.New.Orleans.S05E08.Close.to.Home.720p.WEBRip.2CH.x265.HEVC-PSA.mkv',
 'length': '224.0 MB',
 'link': 'magnet:?xt=urn:btih:E7AD7D28BC9ACDE5882FA731F741FE85DBC1F793'}
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/5828922A6912C42A85E2BF169E523D24B81F7192.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Busp%20raws%5D%20pingu%20in%20the%20city%20-%20> (referer: None)
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/6B5AE87AAEFE21F9CD6B47FAA20460CF57A6DE93.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=manifest%20s>
{'baidu': 'manifest s',
 'click': '3',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Manifest.S01E08.HDTV.x264-KILLERS[eztv].mkv',
 'length': '235.9 MB',
 'link': 'magnet:?xt=urn:btih:A56D39962F3304D80C79D6AD99EF681B723806F3'}
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=homicide%20hunter%20s>
{'baidu': 'homicide hunter s',
 'click': '2',
 'ctime': '2018-11-22',
 'fanyi': 'hunter s',
 'filename': 'homicide.hunter.s05e10.720p.hdtv.x264-w4f[eztv].mkv',
 'length': '689.1 MB',
 'link': 'magnet:?xt=urn:btih:EBDCBE7DE4885A1A6A4C326BA14F93A58DBD224F'}
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=uefa%20nation%20league%20-%20norway%20vs%20slovenia%20-%20> (referer: None)
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/1C4E16CC9DEEBE261F81D3B76DA654DADAF5715D.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Busp%20raws%5D%20pingu%20in%20the%20city%20-%20>
{'baidu': '[usp raws] pingu in the city - ',
 'click': '15',
 'ctime': '2018-11-22',
 'fanyi': '(usp)',
 'filename': '[USP RAWS] Pingu in the City - 33 [30AEC174].mkv',
 'length': '61.6 MB',
 'link': 'magnet:?xt=urn:btih:3E915B6AE2DEA156C6A1D4BDA315BF40BA7F2783'}
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=los%20increi%CC%81bles%20> (referer: None)
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=air%20> (referer: None)
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=uefa%20nation%20league%20-%20norway%20vs%20slovenia%20-%20>
{'baidu': 'uefa nation league - norway vs slovenia - ',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '-',
 'filename': 'UEFA Nation League - Norway vs Slovenia - 2018 10 13 - 1080p - '
             'English.mkv',
 'length': '4.3 GB',
 'link': 'magnet:?xt=urn:btih:4CC479896C6C2FA09976546E34E9F3D2C0DDB7F0'}
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=take%20me%20out%20s> (referer: None)
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=los%20increi%CC%81bles%20>
{'baidu': 'los increibles ',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': 'increibles',
 'filename': 'Los Increibles 2 (2018)[BR m1080p x264 AC3(ES-EN) '
             'Subs(ES-EN-FORZ)].mkv',
 'length': '5.0 GB',
 'link': 'magnet:?xt=urn:btih:5828922A6912C42A85E2BF169E523D24B81F7192'}
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=air%20>
{'baidu': 'air ',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'AIR 03.mkv',
 'length': '1.1 GB',
 'link': 'magnet:?xt=urn:btih:6B5AE87AAEFE21F9CD6B47FAA20460CF57A6DE93'}
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=take%20me%20out%20s>
{'baidu': 'take me out s',
 'click': '5',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'Take.Me.Out.S10E01.WEB.x264-KOMPOST[eztv].mkv',
 'length': '535.6 MB',
 'link': 'magnet:?xt=urn:btih:1C4E16CC9DEEBE261F81D3B76DA654DADAF5715D'}
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/4B92EC104DE108554FB598CC399C3475D270152A.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20> (referer: None)
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/F678902CA972659E570703D2D72A94B9318A5093.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20>
{'baidu': 'the equalizer ',
 'click': '1',
 'ctime': '2018-11-22',
 'fanyi': '',
 'filename': 'The Equalizer 2014 m1080p DUAL BluRay x264 - HdT.mkv',
 'length': '2.7 GB',
 'link': 'magnet:?xt=urn:btih:4B92EC104DE108554FB598CC399C3475D270152A'}
2018-11-23 13:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=kasyno%20-%20casino%20%28> (referer: None)
2018-11-23 13:45:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=kasyno%20-%20casino%20%28>
{'baidu': 'kasyno - casino (',
 'click': '5',
 'ctime': '2018-11-22',
 'fanyi': 'kasyno(',
 'filename': 'Kasyno - Casino (1995) [1080P] [BLURAY] [H264] [AC3-E1973] '
             '[LEKTOR PL].mkv',
 'length': '13.2 GB',
 'link': 'magnet:?xt=urn:btih:F678902CA972659E570703D2D72A94B9318A5093'}
2018-11-23 13:45:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/369550E71E1D638D2E6EEAFDC3A2D4DFD892FE43.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20nadigaiyar%20thilagam%20%28> (referer: None)
2018-11-23 13:45:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=www%20tamilrockers%20by%20-%20nadigaiyar%20thilagam%20%28>
{'baidu': 'www tamilrockers by - nadigaiyar thilagam (',
 'click': '5',
 'ctime': '2018-11-22',
 'fanyi': 'nadigaiyar - tamilro',
 'filename': 'www.TamilRockers.by - Nadigaiyar Thilagam (2018) [1080p Proper '
             '(Final) HQ TRUE HD - AVC - Untouched - x264 - DD 5.1 (640Kbps) - '
             '8.3GB - ESubs - Tamil].mkv',
 'length': '8.3 GB',
 'link': 'magnet:?xt=urn:btih:369550E71E1D638D2E6EEAFDC3A2D4DFD892FE43'}
2018-11-23 13:45:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.cc/3FB6A05AA967919E1F4FB55CC955E4D7DCFC7B83.html> (referer: https://www.bturl.cc/search/mkv_ctime_2.html)
2018-11-23 13:45:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%B1%D0%BE%D0%B1%D1%80%D0%BE%D0%B2%D1%8B%20%28> (referer: None)
2018-11-23 13:45:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%B1%D0%BE%D0%B1%D1%80%D0%BE%D0%B2%D1%8B%20%28>
{'baidu': ' (',
 'click': '4',
 'ctime': '2018-11-22',
 'fanyi': '(',
 'filename': ' (2016).mkv',
 'length': '836.2 MB',
 'link': 'magnet:?xt=urn:btih:3FB6A05AA967919E1F4FB55CC955E4D7DCFC7B83'}
2018-11-23 13:45:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 13:45:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34686,
 'downloader/request_count': 91,
 'downloader/request_method_count/GET': 91,
 'downloader/response_bytes': 123184,
 'downloader/response_count': 91,
 'downloader/response_status_count/200': 91,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 5, 45, 19, 775537),
 'item_scraped_count': 42,
 'log_count/DEBUG': 134,
 'log_count/INFO': 7,
 'memusage/max': 760246272,
 'memusage/startup': 760246272,
 'request_depth_max': 2,
 'response_received_count': 91,
 'scheduler/dequeued': 91,
 'scheduler/dequeued/memory': 91,
 'scheduler/enqueued': 91,
 'scheduler/enqueued/memory': 91,
 'start_time': datetime.datetime(2018, 11, 23, 5, 45, 14, 163879)}
2018-11-23 13:45:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 10:13:08 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 10:13:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 10:13:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 10:13:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 10:13:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 10:13:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 10:13:08 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 10:13:08 [scrapy.core.engine] INFO: Spider opened
2018-11-26 10:13:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:13:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 10:13:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-26 10:13:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici2.html> (referer: None)
2018-11-26 10:13:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici3.html> (referer: None)
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.16.9',
 'LAST_CHECK_TIME': '18-11-21 02:02',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.240.224.252',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '33035',
 'SPEED': '0.186',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.146.2.234',
 'LAST_CHECK_TIME': '18-11-21 02:01',
 'LOCATION': '',
 'PORT': '39960',
 'SPEED': '0.243',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '211.147.239.101',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '57281',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.77.156',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.227',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.86.80',
 'LAST_CHECK_TIME': '18-11-21 01:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.466',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.71.15',
 'LAST_CHECK_TIME': '18-11-21 01:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.529',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.169',
 'LAST_CHECK_TIME': '18-11-21 00:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.244',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.224.101.48',
 'LAST_CHECK_TIME': '18-11-20 13:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.088',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.3.170.89',
 'LAST_CHECK_TIME': '18-11-20 13:30',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.85.248',
 'LAST_CHECK_TIME': '18-11-20 13:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.992',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.72.115.59',
 'LAST_CHECK_TIME': '18-11-20 12:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.27',
 'LAST_CHECK_TIME': '18-11-20 12:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.32',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '120.10.25.4',
 'LAST_CHECK_TIME': '18-11-20 12:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.17.236.83',
 'LAST_CHECK_TIME': '18-11-21 00:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.347',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.115.49.174',
 'LAST_CHECK_TIME': '18-11-21 00:30',
 'LOCATION': '',
 'PORT': '59216',
 'SPEED': '0.146',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.69.13.242',
 'LAST_CHECK_TIME': '18-11-21 00:23',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '3.461',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.127.93.188',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '57985',
 'SPEED': '4.426',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.253.84.183',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '30071',
 'SPEED': '4.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.254',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.718',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '58.62.238.150',
 'LAST_CHECK_TIME': '18-11-21 00:16',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.78.214',
 'LAST_CHECK_TIME': '18-11-21 00:05',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.895',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.86.208.98',
 'LAST_CHECK_TIME': '18-11-21 00:00',
 'LOCATION': '',
 'PORT': '41683',
 'SPEED': '1.181',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.27.43',
 'LAST_CHECK_TIME': '18-11-20 23:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.338',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.218.102.146',
 'LAST_CHECK_TIME': '18-11-20 23:45',
 'LOCATION': '',
 'PORT': '33323',
 'SPEED': '0.019',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.70.66',
 'LAST_CHECK_TIME': '18-11-20 23:41',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.234.181.194',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '33695',
 'SPEED': '3.011',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.81',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.122.53',
 'LAST_CHECK_TIME': '18-11-20 12:12',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.912',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.175.218.98',
 'LAST_CHECK_TIME': '18-11-20 12:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.692',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.4.217',
 'LAST_CHECK_TIME': '18-11-20 11:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '2.468',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.156.237',
 'LAST_CHECK_TIME': '18-11-20 11:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.217',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '61.178.127.14',
 'LAST_CHECK_TIME': '18-11-20 11:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.165',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.185.221.142',
 'LAST_CHECK_TIME': '18-11-20 10:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.121',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.25.193',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.558',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.44',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.194',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.59.84.15',
 'LAST_CHECK_TIME': '18-11-20 10:30',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.784',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '49.82.50.36',
 'LAST_CHECK_TIME': '18-11-20 10:21',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '4.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.61.203.134',
 'LAST_CHECK_TIME': '18-11-20 10:15',
 'LOCATION': '',
 'PORT': '51987',
 'SPEED': '0.172',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.178.227.171',
 'LAST_CHECK_TIME': '18-11-20 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.006',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.20',
 'LAST_CHECK_TIME': '18-11-20 09:45',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.25',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.48.51.212',
 'LAST_CHECK_TIME': '18-11-20 09:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.24.16.198',
 'LAST_CHECK_TIME': '18-11-20 23:31',
 'LOCATION': '',
 'PORT': '43620',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.165.131',
 'LAST_CHECK_TIME': '18-11-20 23:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.229',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.165.234',
 'LAST_CHECK_TIME': '18-11-20 23:23',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.819',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.214.180.122',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '33190',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '118.181.226.216',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '36430',
 'SPEED': '0.261',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.80',
 'LAST_CHECK_TIME': '18-11-20 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.473',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.154.99',
 'LAST_CHECK_TIME': '18-11-20 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.3',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.248',
 'LAST_CHECK_TIME': '18-11-20 23:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.597',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.187.206.207',
 'LAST_CHECK_TIME': '18-11-20 22:55',
 'LOCATION': '',
 'PORT': '46693',
 'SPEED': '4.125',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.178.149.237',
 'LAST_CHECK_TIME': '18-11-20 22:40',
 'LOCATION': '',
 'PORT': '59042',
 'SPEED': '1.809',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '49.71.81.165',
 'LAST_CHECK_TIME': '18-11-20 22:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '4.586',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.172.191.226',
 'LAST_CHECK_TIME': '18-11-20 09:24',
 'LOCATION': '',
 'PORT': '33384',
 'SPEED': '4.076',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.72.195.140',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.612',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.20',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '5.48',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.228',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.803',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.169.199.126',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.416',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.24.170',
 'LAST_CHECK_TIME': '18-11-20 08:46',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.977',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.186.228',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.735',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.74.147',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.247',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.77.167',
 'LAST_CHECK_TIME': '18-11-20 08:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.215',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.173.72.153',
 'LAST_CHECK_TIME': '18-11-20 08:05',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.165.130.111',
 'LAST_CHECK_TIME': '18-11-20 07:55',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.527',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.104.38',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.781',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.116',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.421',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.190',
 'LAST_CHECK_TIME': '18-11-20 22:15',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.78.43.87',
 'LAST_CHECK_TIME': '18-11-20 22:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.142',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.89.33.59',
 'LAST_CHECK_TIME': '18-11-20 21:45',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.11',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.176.186',
 'LAST_CHECK_TIME': '18-11-20 21:44',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.537',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.223.115.30',
 'LAST_CHECK_TIME': '18-11-20 21:22',
 'LOCATION': '',
 'PORT': '51618',
 'SPEED': '0.073',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.184.127.79',
 'LAST_CHECK_TIME': '18-11-20 21:17',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.164.78',
 'LAST_CHECK_TIME': '18-11-20 21:16',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.348',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.219.106.147',
 'LAST_CHECK_TIME': '18-11-20 21:10',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.228.49.232',
 'LAST_CHECK_TIME': '18-11-20 21:02',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.692',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '113.121.243.50',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '38118',
 'SPEED': '1.19',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.154.23',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '0.505',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.183.121.126',
 'LAST_CHECK_TIME': '18-11-20 20:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.081',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.25.163',
 'LAST_CHECK_TIME': '18-11-20 20:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.839',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '113.103.15.139',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.913',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.175.136.195',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '54584',
 'SPEED': '0.187',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.192.216',
 'LAST_CHECK_TIME': '18-11-20 07:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.536',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.55.21.194',
 'LAST_CHECK_TIME': '18-11-20 07:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.224',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.210.133.98',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '32741',
 'SPEED': '0.214',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.18.115',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.176.36.251',
 'LAST_CHECK_TIME': '18-11-20 07:01',
 'LOCATION': '',
 'PORT': '37000',
 'SPEED': '0.357',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '106.14.214.94',
 'LAST_CHECK_TIME': '18-11-20 06:56',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.104',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.157.174.133',
 'LAST_CHECK_TIME': '18-11-20 06:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.39',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.17.236.52',
 'LAST_CHECK_TIME': '18-11-20 06:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.802',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '222.182.56.218',
 'LAST_CHECK_TIME': '18-11-20 03:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.113.27.170',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '47849',
 'SPEED': '0.094',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.119.65.16',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.91.11',
 'LAST_CHECK_TIME': '18-11-20 20:42',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.427',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.132',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6675',
 'SPEED': '1.199',
 'TYPE': 'socks4/5'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.24.111',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.193',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.10',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.498',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.67.25.83',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '41681',
 'SPEED': '0.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.15.202.34',
 'LAST_CHECK_TIME': '18-11-20 20:21',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.104',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.236.98.78',
 'LAST_CHECK_TIME': '18-11-20 20:02',
 'LOCATION': '',
 'PORT': '43682',
 'SPEED': '0.165',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.68.115',
 'LAST_CHECK_TIME': '18-11-20 19:50',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.805',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.166.159',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.28',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.156.179',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.467',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.168.136.31',
 'LAST_CHECK_TIME': '18-11-20 19:22',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.184',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '39.76.14.191',
 'LAST_CHECK_TIME': '18-11-20 03:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.635',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.61',
 'LAST_CHECK_TIME': '18-11-20 02:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '1.189',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.202',
 'LAST_CHECK_TIME': '18-11-20 02:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.823',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.25.124',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.925',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.43',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.501',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '36.33.32.158',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '59019',
 'SPEED': '0.205',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.54',
 'LAST_CHECK_TIME': '18-11-20 02:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.845',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.77.72',
 'LAST_CHECK_TIME': '18-11-20 01:52',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.577',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.64.130',
 'LAST_CHECK_TIME': '18-11-20 01:46',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.816',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.148.79.233',
 'LAST_CHECK_TIME': '18-11-20 01:44',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.246',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '220.173.106.168',
 'LAST_CHECK_TIME': '18-11-20 01:38',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.284',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.44.62',
 'LAST_CHECK_TIME': '18-11-20 19:21',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.031',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '114.99.167.121',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.599',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.174.225.26',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '60984',
 'SPEED': '0.14',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.161.208',
 'LAST_CHECK_TIME': '18-11-20 19:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.194.214',
 'LAST_CHECK_TIME': '18-11-20 19:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.529',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.254.94.105',
 'LAST_CHECK_TIME': '18-11-20 18:55',
 'LOCATION': '',
 'PORT': '58999',
 'SPEED': '3.252',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.142.132.146',
 'LAST_CHECK_TIME': '18-11-20 18:33',
 'LOCATION': '',
 'PORT': '40655',
 'SPEED': '3.836',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.168.13.26',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '4.068',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '117.21.191.154',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.106.91.58',
 'LAST_CHECK_TIME': '18-11-20 18:22',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.202.216.218',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.18',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.194.141',
 'LAST_CHECK_TIME': '18-11-20 01:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.641',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.162.208',
 'LAST_CHECK_TIME': '18-11-20 01:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.568',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.228.49.227',
 'LAST_CHECK_TIME': '18-11-20 01:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.85',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.107.144',
 'LAST_CHECK_TIME': '18-11-20 00:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.783',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.78.41',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.039',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.219',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.876',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.153.165',
 'LAST_CHECK_TIME': '18-11-20 00:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.234',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.79.224',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.553',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.32.37.229',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.208',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.190.95.35',
 'LAST_CHECK_TIME': '18-11-19 23:51',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.052',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.2',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.827',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.143.180',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '7.255',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.235.135.210',
 'LAST_CHECK_TIME': '18-11-20 17:50',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '3.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.57.214',
 'LAST_CHECK_TIME': '18-11-20 17:45',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.24.153',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.156',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.42',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.99.133.223',
 'LAST_CHECK_TIME': '18-11-20 17:06',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.212',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.147.198',
 'LAST_CHECK_TIME': '18-11-20 17:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '1.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.150.45',
 'LAST_CHECK_TIME': '18-11-20 16:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.873',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.45.88.109',
 'LAST_CHECK_TIME': '18-11-20 16:22',
 'LOCATION': '',
 'PORT': '61710',
 'SPEED': '0.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.163.152.130',
 'LAST_CHECK_TIME': '18-11-20 16:15',
 'LOCATION': '',
 'PORT': '60596',
 'SPEED': '0.173',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.114',
 'LAST_CHECK_TIME': '18-11-20 16:14',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.179',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '119.1.97.193',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '60916',
 'SPEED': '0.398',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.138.140',
 'LAST_CHECK_TIME': '18-11-19 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.226',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.100',
 'LAST_CHECK_TIME': '18-11-19 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.91',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.64.78',
 'LAST_CHECK_TIME': '18-11-19 23:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.026',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '101.236.54.166',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.02',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '223.203.0.14',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.025',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.99.255.28',
 'LAST_CHECK_TIME': '18-11-19 22:46',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.133',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.68.73',
 'LAST_CHECK_TIME': '18-11-19 22:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.584',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.213.234',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.387',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.71',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.041',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.156',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.652',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.223.85.244',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.568',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.155.164',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '3.235',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.170.179.89',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '50799',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.25.206',
 'LAST_CHECK_TIME': '18-11-20 15:55',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.433',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.110.5.254',
 'LAST_CHECK_TIME': '18-11-20 15:45',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.51',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.159.233',
 'LAST_CHECK_TIME': '18-11-20 15:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.323',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.134.204',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.477',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.249',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '61234',
 'SPEED': '2.87',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.185.5.9',
 'LAST_CHECK_TIME': '18-11-20 14:52',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.118',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '36.48.132.203',
 'LAST_CHECK_TIME': '18-11-20 14:44',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.127',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.115.181.125',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.7',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.215.149.170',
 'LAST_CHECK_TIME': '18-11-19 22:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.079',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.189',
 'LAST_CHECK_TIME': '18-11-19 22:22',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.204',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.59.193.14',
 'LAST_CHECK_TIME': '18-11-19 22:15',
 'LOCATION': '',
 'PORT': '47138',
 'SPEED': '7.113',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.36.247',
 'LAST_CHECK_TIME': '18-11-19 22:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.609',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.36',
 'LAST_CHECK_TIME': '18-11-19 22:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.768',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.193.214',
 'LAST_CHECK_TIME': '18-11-19 22:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.388',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.41.205',
 'LAST_CHECK_TIME': '18-11-19 21:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.818',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '14.204.20.95',
 'LAST_CHECK_TIME': '18-11-19 21:40',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '2.262',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.80.249',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.322',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.165.77',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.302',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.157.171',
 'LAST_CHECK_TIME': '18-11-19 21:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.97.196',
 'LAST_CHECK_TIME': '18-11-19 21:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.287',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.170.140',
 'LAST_CHECK_TIME': '18-11-19 21:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.2',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.90.92',
 'LAST_CHECK_TIME': '18-11-20 14:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.405',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.26.86',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.107',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '6.593',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.138.159.221',
 'LAST_CHECK_TIME': '18-11-20 14:21',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.242',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.91',
 'LAST_CHECK_TIME': '18-11-20 14:20',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.59.11',
 'LAST_CHECK_TIME': '18-11-20 14:12',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.457',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.17.253.106',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '60004',
 'SPEED': '0.926',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.438',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.40.109.154',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '31610',
 'SPEED': '1.458',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.150.73.206',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.214',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.143.219',
 'LAST_CHECK_TIME': '18-11-19 21:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.223',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.230.41.119',
 'LAST_CHECK_TIME': '18-11-19 20:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.120.189',
 'LAST_CHECK_TIME': '18-11-19 20:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.676',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.22.102.107',
 'LAST_CHECK_TIME': '18-11-19 19:56',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.389',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.164.118',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.16',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.162.198',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.279',
 'TYPE': 'HTTP'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.75.106',
 'LAST_CHECK_TIME': '18-11-19 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.429',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-26 10:13:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 10:13:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 233143,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 2, 13, 9, 394878),
 'item_scraped_count': 300,
 'log_count/DEBUG': 304,
 'log_count/INFO': 7,
 'memusage/max': 743211008,
 'memusage/startup': 743211008,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 26, 2, 13, 8, 753215)}
2018-11-26 10:13:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 10:14:21 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 10:14:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 10:14:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 10:14:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 10:14:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 10:14:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 10:14:21 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 10:14:21 [scrapy.core.engine] INFO: Spider opened
2018-11-26 10:14:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:14:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 10:14:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-26 10:14:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici2.html> (referer: None)
2018-11-26 10:14:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici3.html> (referer: None)
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.16.9',
 'LAST_CHECK_TIME': '18-11-21 02:02',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.146.2.234',
 'LAST_CHECK_TIME': '18-11-21 02:01',
 'LOCATION': '',
 'PORT': '39960',
 'SPEED': '0.243',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '211.147.239.101',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '57281',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.77.156',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.227',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.86.80',
 'LAST_CHECK_TIME': '18-11-21 01:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.466',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.240.224.252',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '33035',
 'SPEED': '0.186',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.224.101.48',
 'LAST_CHECK_TIME': '18-11-20 13:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.088',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.3.170.89',
 'LAST_CHECK_TIME': '18-11-20 13:30',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.85.248',
 'LAST_CHECK_TIME': '18-11-20 13:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.992',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.72.115.59',
 'LAST_CHECK_TIME': '18-11-20 12:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.27',
 'LAST_CHECK_TIME': '18-11-20 12:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.32',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.71.15',
 'LAST_CHECK_TIME': '18-11-21 01:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.529',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.169',
 'LAST_CHECK_TIME': '18-11-21 00:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.244',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.17.236.83',
 'LAST_CHECK_TIME': '18-11-21 00:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.347',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.115.49.174',
 'LAST_CHECK_TIME': '18-11-21 00:30',
 'LOCATION': '',
 'PORT': '59216',
 'SPEED': '0.146',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.69.13.242',
 'LAST_CHECK_TIME': '18-11-21 00:23',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '3.461',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.127.93.188',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '57985',
 'SPEED': '4.426',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.253.84.183',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '30071',
 'SPEED': '4.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.254',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.718',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '58.62.238.150',
 'LAST_CHECK_TIME': '18-11-21 00:16',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.78.214',
 'LAST_CHECK_TIME': '18-11-21 00:05',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.895',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.86.208.98',
 'LAST_CHECK_TIME': '18-11-21 00:00',
 'LOCATION': '',
 'PORT': '41683',
 'SPEED': '1.181',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '120.10.25.4',
 'LAST_CHECK_TIME': '18-11-20 12:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.122.53',
 'LAST_CHECK_TIME': '18-11-20 12:12',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.912',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.175.218.98',
 'LAST_CHECK_TIME': '18-11-20 12:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.692',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.4.217',
 'LAST_CHECK_TIME': '18-11-20 11:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '2.468',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.156.237',
 'LAST_CHECK_TIME': '18-11-20 11:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.217',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '61.178.127.14',
 'LAST_CHECK_TIME': '18-11-20 11:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.165',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.185.221.142',
 'LAST_CHECK_TIME': '18-11-20 10:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.121',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.25.193',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.558',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.44',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.194',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.59.84.15',
 'LAST_CHECK_TIME': '18-11-20 10:30',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.784',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '49.82.50.36',
 'LAST_CHECK_TIME': '18-11-20 10:21',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '4.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.61.203.134',
 'LAST_CHECK_TIME': '18-11-20 10:15',
 'LOCATION': '',
 'PORT': '51987',
 'SPEED': '0.172',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.178.227.171',
 'LAST_CHECK_TIME': '18-11-20 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.006',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.20',
 'LAST_CHECK_TIME': '18-11-20 09:45',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.25',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.27.43',
 'LAST_CHECK_TIME': '18-11-20 23:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.338',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.218.102.146',
 'LAST_CHECK_TIME': '18-11-20 23:45',
 'LOCATION': '',
 'PORT': '33323',
 'SPEED': '0.019',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.70.66',
 'LAST_CHECK_TIME': '18-11-20 23:41',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.234.181.194',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '33695',
 'SPEED': '3.011',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.81',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.24.16.198',
 'LAST_CHECK_TIME': '18-11-20 23:31',
 'LOCATION': '',
 'PORT': '43620',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.165.131',
 'LAST_CHECK_TIME': '18-11-20 23:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.229',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.165.234',
 'LAST_CHECK_TIME': '18-11-20 23:23',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.819',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.214.180.122',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '33190',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '118.181.226.216',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '36430',
 'SPEED': '0.261',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.80',
 'LAST_CHECK_TIME': '18-11-20 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.473',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.154.99',
 'LAST_CHECK_TIME': '18-11-20 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.3',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.248',
 'LAST_CHECK_TIME': '18-11-20 23:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.597',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.187.206.207',
 'LAST_CHECK_TIME': '18-11-20 22:55',
 'LOCATION': '',
 'PORT': '46693',
 'SPEED': '4.125',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.48.51.212',
 'LAST_CHECK_TIME': '18-11-20 09:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.172.191.226',
 'LAST_CHECK_TIME': '18-11-20 09:24',
 'LOCATION': '',
 'PORT': '33384',
 'SPEED': '4.076',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.72.195.140',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.612',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.20',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '5.48',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.228',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.803',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.169.199.126',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.416',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.24.170',
 'LAST_CHECK_TIME': '18-11-20 08:46',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.977',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.186.228',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.735',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.74.147',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.247',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.77.167',
 'LAST_CHECK_TIME': '18-11-20 08:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.215',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.173.72.153',
 'LAST_CHECK_TIME': '18-11-20 08:05',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.165.130.111',
 'LAST_CHECK_TIME': '18-11-20 07:55',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.527',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.104.38',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.781',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.116',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.421',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.178.149.237',
 'LAST_CHECK_TIME': '18-11-20 22:40',
 'LOCATION': '',
 'PORT': '59042',
 'SPEED': '1.809',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '49.71.81.165',
 'LAST_CHECK_TIME': '18-11-20 22:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '4.586',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.190',
 'LAST_CHECK_TIME': '18-11-20 22:15',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.78.43.87',
 'LAST_CHECK_TIME': '18-11-20 22:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.142',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.89.33.59',
 'LAST_CHECK_TIME': '18-11-20 21:45',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.11',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.176.186',
 'LAST_CHECK_TIME': '18-11-20 21:44',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.537',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.223.115.30',
 'LAST_CHECK_TIME': '18-11-20 21:22',
 'LOCATION': '',
 'PORT': '51618',
 'SPEED': '0.073',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.184.127.79',
 'LAST_CHECK_TIME': '18-11-20 21:17',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.164.78',
 'LAST_CHECK_TIME': '18-11-20 21:16',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.348',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.219.106.147',
 'LAST_CHECK_TIME': '18-11-20 21:10',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.228.49.232',
 'LAST_CHECK_TIME': '18-11-20 21:02',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.692',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '113.121.243.50',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '38118',
 'SPEED': '1.19',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.154.23',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '0.505',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.183.121.126',
 'LAST_CHECK_TIME': '18-11-20 20:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.081',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '113.103.15.139',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.913',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.175.136.195',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '54584',
 'SPEED': '0.187',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.192.216',
 'LAST_CHECK_TIME': '18-11-20 07:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.536',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.55.21.194',
 'LAST_CHECK_TIME': '18-11-20 07:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.224',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.210.133.98',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '32741',
 'SPEED': '0.214',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.18.115',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.176.36.251',
 'LAST_CHECK_TIME': '18-11-20 07:01',
 'LOCATION': '',
 'PORT': '37000',
 'SPEED': '0.357',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '106.14.214.94',
 'LAST_CHECK_TIME': '18-11-20 06:56',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.104',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.157.174.133',
 'LAST_CHECK_TIME': '18-11-20 06:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.39',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.17.236.52',
 'LAST_CHECK_TIME': '18-11-20 06:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.802',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '222.182.56.218',
 'LAST_CHECK_TIME': '18-11-20 03:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.113.27.170',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '47849',
 'SPEED': '0.094',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.119.65.16',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '39.76.14.191',
 'LAST_CHECK_TIME': '18-11-20 03:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.635',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.25.163',
 'LAST_CHECK_TIME': '18-11-20 20:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.839',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.91.11',
 'LAST_CHECK_TIME': '18-11-20 20:42',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.427',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.132',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6675',
 'SPEED': '1.199',
 'TYPE': 'socks4/5'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.24.111',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.193',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.10',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.498',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.67.25.83',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '41681',
 'SPEED': '0.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.15.202.34',
 'LAST_CHECK_TIME': '18-11-20 20:21',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.104',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.236.98.78',
 'LAST_CHECK_TIME': '18-11-20 20:02',
 'LOCATION': '',
 'PORT': '43682',
 'SPEED': '0.165',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.68.115',
 'LAST_CHECK_TIME': '18-11-20 19:50',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.805',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.166.159',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.28',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.156.179',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.467',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.168.136.31',
 'LAST_CHECK_TIME': '18-11-20 19:22',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.184',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.44.62',
 'LAST_CHECK_TIME': '18-11-20 19:21',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.031',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '114.99.167.121',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.599',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.61',
 'LAST_CHECK_TIME': '18-11-20 02:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '1.189',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.202',
 'LAST_CHECK_TIME': '18-11-20 02:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.823',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.25.124',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.925',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.43',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.501',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '36.33.32.158',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '59019',
 'SPEED': '0.205',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.54',
 'LAST_CHECK_TIME': '18-11-20 02:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.845',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.77.72',
 'LAST_CHECK_TIME': '18-11-20 01:52',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.577',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.64.130',
 'LAST_CHECK_TIME': '18-11-20 01:46',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.816',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.148.79.233',
 'LAST_CHECK_TIME': '18-11-20 01:44',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.246',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '220.173.106.168',
 'LAST_CHECK_TIME': '18-11-20 01:38',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.284',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.194.141',
 'LAST_CHECK_TIME': '18-11-20 01:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.641',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.162.208',
 'LAST_CHECK_TIME': '18-11-20 01:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.568',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.228.49.227',
 'LAST_CHECK_TIME': '18-11-20 01:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.85',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.107.144',
 'LAST_CHECK_TIME': '18-11-20 00:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.783',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.174.225.26',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '60984',
 'SPEED': '0.14',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.161.208',
 'LAST_CHECK_TIME': '18-11-20 19:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.194.214',
 'LAST_CHECK_TIME': '18-11-20 19:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.529',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.254.94.105',
 'LAST_CHECK_TIME': '18-11-20 18:55',
 'LOCATION': '',
 'PORT': '58999',
 'SPEED': '3.252',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.142.132.146',
 'LAST_CHECK_TIME': '18-11-20 18:33',
 'LOCATION': '',
 'PORT': '40655',
 'SPEED': '3.836',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.168.13.26',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '4.068',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '117.21.191.154',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.106.91.58',
 'LAST_CHECK_TIME': '18-11-20 18:22',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.202.216.218',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.18',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.143.180',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '7.255',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.235.135.210',
 'LAST_CHECK_TIME': '18-11-20 17:50',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '3.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.57.214',
 'LAST_CHECK_TIME': '18-11-20 17:45',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.24.153',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.156',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.78.41',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.039',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.219',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.876',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.153.165',
 'LAST_CHECK_TIME': '18-11-20 00:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.234',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.79.224',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.553',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.32.37.229',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.208',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.190.95.35',
 'LAST_CHECK_TIME': '18-11-19 23:51',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.052',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.2',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.827',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '119.1.97.193',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '60916',
 'SPEED': '0.398',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.138.140',
 'LAST_CHECK_TIME': '18-11-19 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.226',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.100',
 'LAST_CHECK_TIME': '18-11-19 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.91',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.64.78',
 'LAST_CHECK_TIME': '18-11-19 23:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.026',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '101.236.54.166',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.02',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '223.203.0.14',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.025',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.99.255.28',
 'LAST_CHECK_TIME': '18-11-19 22:46',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.133',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.42',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.99.133.223',
 'LAST_CHECK_TIME': '18-11-20 17:06',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.212',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.147.198',
 'LAST_CHECK_TIME': '18-11-20 17:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '1.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.150.45',
 'LAST_CHECK_TIME': '18-11-20 16:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.873',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.45.88.109',
 'LAST_CHECK_TIME': '18-11-20 16:22',
 'LOCATION': '',
 'PORT': '61710',
 'SPEED': '0.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.163.152.130',
 'LAST_CHECK_TIME': '18-11-20 16:15',
 'LOCATION': '',
 'PORT': '60596',
 'SPEED': '0.173',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.114',
 'LAST_CHECK_TIME': '18-11-20 16:14',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.179',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.156',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.652',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.223.85.244',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.568',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.155.164',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '3.235',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.68.73',
 'LAST_CHECK_TIME': '18-11-19 22:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.584',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.213.234',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.387',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.71',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.041',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.115.181.125',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.7',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.215.149.170',
 'LAST_CHECK_TIME': '18-11-19 22:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.079',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.189',
 'LAST_CHECK_TIME': '18-11-19 22:22',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.204',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.59.193.14',
 'LAST_CHECK_TIME': '18-11-19 22:15',
 'LOCATION': '',
 'PORT': '47138',
 'SPEED': '7.113',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.170.179.89',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '50799',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.25.206',
 'LAST_CHECK_TIME': '18-11-20 15:55',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.433',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.110.5.254',
 'LAST_CHECK_TIME': '18-11-20 15:45',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.51',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.159.233',
 'LAST_CHECK_TIME': '18-11-20 15:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.323',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.134.204',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.477',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.249',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '61234',
 'SPEED': '2.87',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.185.5.9',
 'LAST_CHECK_TIME': '18-11-20 14:52',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.118',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '36.48.132.203',
 'LAST_CHECK_TIME': '18-11-20 14:44',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.127',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.90.92',
 'LAST_CHECK_TIME': '18-11-20 14:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.405',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.36.247',
 'LAST_CHECK_TIME': '18-11-19 22:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.609',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.36',
 'LAST_CHECK_TIME': '18-11-19 22:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.768',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.193.214',
 'LAST_CHECK_TIME': '18-11-19 22:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.388',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.41.205',
 'LAST_CHECK_TIME': '18-11-19 21:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.818',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '14.204.20.95',
 'LAST_CHECK_TIME': '18-11-19 21:40',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '2.262',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.80.249',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.322',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.165.77',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.302',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.157.171',
 'LAST_CHECK_TIME': '18-11-19 21:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.97.196',
 'LAST_CHECK_TIME': '18-11-19 21:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.287',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.170.140',
 'LAST_CHECK_TIME': '18-11-19 21:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.2',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.143.219',
 'LAST_CHECK_TIME': '18-11-19 21:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.223',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.26.86',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.107',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '6.593',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.138.159.221',
 'LAST_CHECK_TIME': '18-11-20 14:21',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.242',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.91',
 'LAST_CHECK_TIME': '18-11-20 14:20',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.59.11',
 'LAST_CHECK_TIME': '18-11-20 14:12',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.457',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.17.253.106',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '60004',
 'SPEED': '0.926',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.438',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.40.109.154',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '31610',
 'SPEED': '1.458',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.150.73.206',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.214',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.230.41.119',
 'LAST_CHECK_TIME': '18-11-19 20:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.120.189',
 'LAST_CHECK_TIME': '18-11-19 20:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.676',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.22.102.107',
 'LAST_CHECK_TIME': '18-11-19 19:56',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.389',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.164.118',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.16',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.162.198',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.279',
 'TYPE': 'HTTP'}
2018-11-26 10:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.75.106',
 'LAST_CHECK_TIME': '18-11-19 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.429',
 'TYPE': 'HTTPS'}
2018-11-26 10:14:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 10:14:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 233143,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 2, 14, 21, 615250),
 'item_scraped_count': 300,
 'log_count/DEBUG': 304,
 'log_count/INFO': 7,
 'memusage/max': 747655168,
 'memusage/startup': 747655168,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 26, 2, 14, 21, 224397)}
2018-11-26 10:14:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 10:15:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 10:15:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 10:15:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 10:15:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 10:15:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 10:15:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 10:15:32 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 10:15:32 [scrapy.core.engine] INFO: Spider opened
2018-11-26 10:15:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:15:32 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 10:15:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-26 10:15:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici2.html> (referer: None)
2018-11-26 10:15:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici3.html> (referer: None)
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.16.9',
 'LAST_CHECK_TIME': '18-11-21 02:02',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.146.2.234',
 'LAST_CHECK_TIME': '18-11-21 02:01',
 'LOCATION': '',
 'PORT': '39960',
 'SPEED': '0.243',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '211.147.239.101',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '57281',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.77.156',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.227',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.86.80',
 'LAST_CHECK_TIME': '18-11-21 01:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.466',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.71.15',
 'LAST_CHECK_TIME': '18-11-21 01:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.529',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.240.224.252',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '33035',
 'SPEED': '0.186',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.224.101.48',
 'LAST_CHECK_TIME': '18-11-20 13:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.088',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.3.170.89',
 'LAST_CHECK_TIME': '18-11-20 13:30',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.85.248',
 'LAST_CHECK_TIME': '18-11-20 13:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.992',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.72.115.59',
 'LAST_CHECK_TIME': '18-11-20 12:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.27',
 'LAST_CHECK_TIME': '18-11-20 12:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.32',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '120.10.25.4',
 'LAST_CHECK_TIME': '18-11-20 12:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.169',
 'LAST_CHECK_TIME': '18-11-21 00:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.244',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.17.236.83',
 'LAST_CHECK_TIME': '18-11-21 00:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.347',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.115.49.174',
 'LAST_CHECK_TIME': '18-11-21 00:30',
 'LOCATION': '',
 'PORT': '59216',
 'SPEED': '0.146',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.69.13.242',
 'LAST_CHECK_TIME': '18-11-21 00:23',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '3.461',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.127.93.188',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '57985',
 'SPEED': '4.426',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.253.84.183',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '30071',
 'SPEED': '4.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.254',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.718',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '58.62.238.150',
 'LAST_CHECK_TIME': '18-11-21 00:16',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.78.214',
 'LAST_CHECK_TIME': '18-11-21 00:05',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.895',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.86.208.98',
 'LAST_CHECK_TIME': '18-11-21 00:00',
 'LOCATION': '',
 'PORT': '41683',
 'SPEED': '1.181',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.27.43',
 'LAST_CHECK_TIME': '18-11-20 23:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.338',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.218.102.146',
 'LAST_CHECK_TIME': '18-11-20 23:45',
 'LOCATION': '',
 'PORT': '33323',
 'SPEED': '0.019',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.70.66',
 'LAST_CHECK_TIME': '18-11-20 23:41',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.234.181.194',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '33695',
 'SPEED': '3.011',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.122.53',
 'LAST_CHECK_TIME': '18-11-20 12:12',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.912',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.175.218.98',
 'LAST_CHECK_TIME': '18-11-20 12:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.692',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.4.217',
 'LAST_CHECK_TIME': '18-11-20 11:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '2.468',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.156.237',
 'LAST_CHECK_TIME': '18-11-20 11:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.217',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '61.178.127.14',
 'LAST_CHECK_TIME': '18-11-20 11:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.165',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.185.221.142',
 'LAST_CHECK_TIME': '18-11-20 10:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.121',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.25.193',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.558',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.44',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.194',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.59.84.15',
 'LAST_CHECK_TIME': '18-11-20 10:30',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.784',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '49.82.50.36',
 'LAST_CHECK_TIME': '18-11-20 10:21',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '4.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.61.203.134',
 'LAST_CHECK_TIME': '18-11-20 10:15',
 'LOCATION': '',
 'PORT': '51987',
 'SPEED': '0.172',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.178.227.171',
 'LAST_CHECK_TIME': '18-11-20 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.006',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.20',
 'LAST_CHECK_TIME': '18-11-20 09:45',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.25',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.48.51.212',
 'LAST_CHECK_TIME': '18-11-20 09:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.81',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.24.16.198',
 'LAST_CHECK_TIME': '18-11-20 23:31',
 'LOCATION': '',
 'PORT': '43620',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.165.131',
 'LAST_CHECK_TIME': '18-11-20 23:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.229',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.165.234',
 'LAST_CHECK_TIME': '18-11-20 23:23',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.819',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.214.180.122',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '33190',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '118.181.226.216',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '36430',
 'SPEED': '0.261',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.80',
 'LAST_CHECK_TIME': '18-11-20 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.473',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.154.99',
 'LAST_CHECK_TIME': '18-11-20 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.3',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.248',
 'LAST_CHECK_TIME': '18-11-20 23:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.597',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.187.206.207',
 'LAST_CHECK_TIME': '18-11-20 22:55',
 'LOCATION': '',
 'PORT': '46693',
 'SPEED': '4.125',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.178.149.237',
 'LAST_CHECK_TIME': '18-11-20 22:40',
 'LOCATION': '',
 'PORT': '59042',
 'SPEED': '1.809',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '49.71.81.165',
 'LAST_CHECK_TIME': '18-11-20 22:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '4.586',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.190',
 'LAST_CHECK_TIME': '18-11-20 22:15',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.172.191.226',
 'LAST_CHECK_TIME': '18-11-20 09:24',
 'LOCATION': '',
 'PORT': '33384',
 'SPEED': '4.076',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.72.195.140',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.612',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.20',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '5.48',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.228',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.803',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.169.199.126',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.416',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.24.170',
 'LAST_CHECK_TIME': '18-11-20 08:46',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.977',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.186.228',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.735',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.74.147',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.247',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.77.167',
 'LAST_CHECK_TIME': '18-11-20 08:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.215',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.173.72.153',
 'LAST_CHECK_TIME': '18-11-20 08:05',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.165.130.111',
 'LAST_CHECK_TIME': '18-11-20 07:55',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.527',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.104.38',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.781',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.116',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.421',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '113.103.15.139',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.913',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.78.43.87',
 'LAST_CHECK_TIME': '18-11-20 22:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.142',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.89.33.59',
 'LAST_CHECK_TIME': '18-11-20 21:45',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.11',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.176.186',
 'LAST_CHECK_TIME': '18-11-20 21:44',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.537',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.223.115.30',
 'LAST_CHECK_TIME': '18-11-20 21:22',
 'LOCATION': '',
 'PORT': '51618',
 'SPEED': '0.073',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.184.127.79',
 'LAST_CHECK_TIME': '18-11-20 21:17',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.164.78',
 'LAST_CHECK_TIME': '18-11-20 21:16',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.348',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.219.106.147',
 'LAST_CHECK_TIME': '18-11-20 21:10',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.228.49.232',
 'LAST_CHECK_TIME': '18-11-20 21:02',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.692',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '113.121.243.50',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '38118',
 'SPEED': '1.19',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.154.23',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '0.505',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.183.121.126',
 'LAST_CHECK_TIME': '18-11-20 20:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.081',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.25.163',
 'LAST_CHECK_TIME': '18-11-20 20:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.839',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.91.11',
 'LAST_CHECK_TIME': '18-11-20 20:42',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.427',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.132',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6675',
 'SPEED': '1.199',
 'TYPE': 'socks4/5'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.175.136.195',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '54584',
 'SPEED': '0.187',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.192.216',
 'LAST_CHECK_TIME': '18-11-20 07:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.536',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.55.21.194',
 'LAST_CHECK_TIME': '18-11-20 07:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.224',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.210.133.98',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '32741',
 'SPEED': '0.214',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.18.115',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.176.36.251',
 'LAST_CHECK_TIME': '18-11-20 07:01',
 'LOCATION': '',
 'PORT': '37000',
 'SPEED': '0.357',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '106.14.214.94',
 'LAST_CHECK_TIME': '18-11-20 06:56',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.104',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.157.174.133',
 'LAST_CHECK_TIME': '18-11-20 06:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.39',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.17.236.52',
 'LAST_CHECK_TIME': '18-11-20 06:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.802',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '222.182.56.218',
 'LAST_CHECK_TIME': '18-11-20 03:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.113.27.170',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '47849',
 'SPEED': '0.094',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.119.65.16',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '39.76.14.191',
 'LAST_CHECK_TIME': '18-11-20 03:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.635',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.61',
 'LAST_CHECK_TIME': '18-11-20 02:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '1.189',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.24.111',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.193',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.10',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.498',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.67.25.83',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '41681',
 'SPEED': '0.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.15.202.34',
 'LAST_CHECK_TIME': '18-11-20 20:21',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.104',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.236.98.78',
 'LAST_CHECK_TIME': '18-11-20 20:02',
 'LOCATION': '',
 'PORT': '43682',
 'SPEED': '0.165',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.68.115',
 'LAST_CHECK_TIME': '18-11-20 19:50',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.805',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.166.159',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.28',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.156.179',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.467',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.168.136.31',
 'LAST_CHECK_TIME': '18-11-20 19:22',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.184',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.44.62',
 'LAST_CHECK_TIME': '18-11-20 19:21',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.031',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '114.99.167.121',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.599',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.174.225.26',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '60984',
 'SPEED': '0.14',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.161.208',
 'LAST_CHECK_TIME': '18-11-20 19:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.194.214',
 'LAST_CHECK_TIME': '18-11-20 19:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.529',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.202',
 'LAST_CHECK_TIME': '18-11-20 02:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.823',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.25.124',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.925',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.43',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.501',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '36.33.32.158',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '59019',
 'SPEED': '0.205',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.54',
 'LAST_CHECK_TIME': '18-11-20 02:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.845',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.77.72',
 'LAST_CHECK_TIME': '18-11-20 01:52',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.577',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.64.130',
 'LAST_CHECK_TIME': '18-11-20 01:46',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.816',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.148.79.233',
 'LAST_CHECK_TIME': '18-11-20 01:44',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.246',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '220.173.106.168',
 'LAST_CHECK_TIME': '18-11-20 01:38',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.284',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.194.141',
 'LAST_CHECK_TIME': '18-11-20 01:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.641',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.162.208',
 'LAST_CHECK_TIME': '18-11-20 01:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.568',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.228.49.227',
 'LAST_CHECK_TIME': '18-11-20 01:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.85',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.254.94.105',
 'LAST_CHECK_TIME': '18-11-20 18:55',
 'LOCATION': '',
 'PORT': '58999',
 'SPEED': '3.252',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.142.132.146',
 'LAST_CHECK_TIME': '18-11-20 18:33',
 'LOCATION': '',
 'PORT': '40655',
 'SPEED': '3.836',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.168.13.26',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '4.068',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '117.21.191.154',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.106.91.58',
 'LAST_CHECK_TIME': '18-11-20 18:22',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.202.216.218',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.18',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.143.180',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '7.255',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.235.135.210',
 'LAST_CHECK_TIME': '18-11-20 17:50',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '3.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.57.214',
 'LAST_CHECK_TIME': '18-11-20 17:45',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.24.153',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.156',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.42',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.99.133.223',
 'LAST_CHECK_TIME': '18-11-20 17:06',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.212',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.147.198',
 'LAST_CHECK_TIME': '18-11-20 17:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '1.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.107.144',
 'LAST_CHECK_TIME': '18-11-20 00:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.783',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.78.41',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.039',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.219',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.876',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.153.165',
 'LAST_CHECK_TIME': '18-11-20 00:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.234',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.79.224',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.553',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.32.37.229',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.208',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.190.95.35',
 'LAST_CHECK_TIME': '18-11-19 23:51',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.052',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.2',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.827',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '119.1.97.193',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '60916',
 'SPEED': '0.398',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.138.140',
 'LAST_CHECK_TIME': '18-11-19 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.226',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.100',
 'LAST_CHECK_TIME': '18-11-19 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.91',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.64.78',
 'LAST_CHECK_TIME': '18-11-19 23:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.026',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '101.236.54.166',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.02',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '223.203.0.14',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.025',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.150.45',
 'LAST_CHECK_TIME': '18-11-20 16:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.873',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.45.88.109',
 'LAST_CHECK_TIME': '18-11-20 16:22',
 'LOCATION': '',
 'PORT': '61710',
 'SPEED': '0.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.163.152.130',
 'LAST_CHECK_TIME': '18-11-20 16:15',
 'LOCATION': '',
 'PORT': '60596',
 'SPEED': '0.173',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.114',
 'LAST_CHECK_TIME': '18-11-20 16:14',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.179',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.156',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.652',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.223.85.244',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.568',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.155.164',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '3.235',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.170.179.89',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '50799',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.25.206',
 'LAST_CHECK_TIME': '18-11-20 15:55',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.433',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.110.5.254',
 'LAST_CHECK_TIME': '18-11-20 15:45',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.51',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.159.233',
 'LAST_CHECK_TIME': '18-11-20 15:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.323',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.134.204',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.477',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.249',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '61234',
 'SPEED': '2.87',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.99.255.28',
 'LAST_CHECK_TIME': '18-11-19 22:46',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.133',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.68.73',
 'LAST_CHECK_TIME': '18-11-19 22:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.584',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.213.234',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.387',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.71',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.041',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.115.181.125',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.7',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.215.149.170',
 'LAST_CHECK_TIME': '18-11-19 22:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.079',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.189',
 'LAST_CHECK_TIME': '18-11-19 22:22',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.204',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.59.193.14',
 'LAST_CHECK_TIME': '18-11-19 22:15',
 'LOCATION': '',
 'PORT': '47138',
 'SPEED': '7.113',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.36.247',
 'LAST_CHECK_TIME': '18-11-19 22:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.609',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.36',
 'LAST_CHECK_TIME': '18-11-19 22:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.768',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.193.214',
 'LAST_CHECK_TIME': '18-11-19 22:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.388',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.41.205',
 'LAST_CHECK_TIME': '18-11-19 21:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.818',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.185.5.9',
 'LAST_CHECK_TIME': '18-11-20 14:52',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.118',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '36.48.132.203',
 'LAST_CHECK_TIME': '18-11-20 14:44',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.127',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.90.92',
 'LAST_CHECK_TIME': '18-11-20 14:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.405',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.26.86',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.107',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '6.593',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.138.159.221',
 'LAST_CHECK_TIME': '18-11-20 14:21',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.242',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.91',
 'LAST_CHECK_TIME': '18-11-20 14:20',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.59.11',
 'LAST_CHECK_TIME': '18-11-20 14:12',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.457',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.17.253.106',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '60004',
 'SPEED': '0.926',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.438',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.40.109.154',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '31610',
 'SPEED': '1.458',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '14.204.20.95',
 'LAST_CHECK_TIME': '18-11-19 21:40',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '2.262',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.80.249',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.322',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.165.77',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.302',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.157.171',
 'LAST_CHECK_TIME': '18-11-19 21:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.97.196',
 'LAST_CHECK_TIME': '18-11-19 21:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.287',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.170.140',
 'LAST_CHECK_TIME': '18-11-19 21:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.2',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.143.219',
 'LAST_CHECK_TIME': '18-11-19 21:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.223',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.230.41.119',
 'LAST_CHECK_TIME': '18-11-19 20:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.120.189',
 'LAST_CHECK_TIME': '18-11-19 20:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.676',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.22.102.107',
 'LAST_CHECK_TIME': '18-11-19 19:56',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.389',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.164.118',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.16',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.150.73.206',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.214',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.162.198',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.279',
 'TYPE': 'HTTP'}
2018-11-26 10:15:32 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.75.106',
 'LAST_CHECK_TIME': '18-11-19 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.429',
 'TYPE': 'HTTPS'}
2018-11-26 10:15:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 10:15:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 233143,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 2, 15, 32, 537112),
 'item_scraped_count': 300,
 'log_count/DEBUG': 304,
 'log_count/INFO': 7,
 'memusage/max': 750194688,
 'memusage/startup': 750194688,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 26, 2, 15, 32, 150154)}
2018-11-26 10:15:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 10:16:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 10:16:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 10:16:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 10:16:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 10:16:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 10:16:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 10:16:00 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 10:16:00 [scrapy.core.engine] INFO: Spider opened
2018-11-26 10:16:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:16:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 10:16:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:16:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:16:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:16:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:16:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:16:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:17:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:17:03 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:17:03 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:17:03 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:17:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_1.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 10:17:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_3.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 10:17:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_2.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 10:17:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 10:17:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 9,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 9,
 'downloader/request_bytes': 2106,
 'downloader/request_count': 9,
 'downloader/request_method_count/GET': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 2, 17, 4, 156180),
 'log_count/DEBUG': 10,
 'log_count/ERROR': 3,
 'log_count/INFO': 8,
 'memusage/max': 757346304,
 'memusage/startup': 757346304,
 'retry/count': 6,
 'retry/max_reached': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 6,
 'scheduler/dequeued': 9,
 'scheduler/dequeued/memory': 9,
 'scheduler/enqueued': 9,
 'scheduler/enqueued/memory': 9,
 'start_time': datetime.datetime(2018, 11, 26, 2, 16, 0, 797688)}
2018-11-26 10:17:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 10:17:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 10:17:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 10:17:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 10:17:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 10:17:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 10:17:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 10:17:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 10:17:34 [scrapy.core.engine] INFO: Spider opened
2018-11-26 10:17:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:17:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 10:17:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici1.html> (referer: None)
2018-11-26 10:17:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici2.html> (referer: None)
2018-11-26 10:17:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///home/ubuntu/Documents/xici3.html> (referer: None)
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.114.149.66',
 'LAST_CHECK_TIME': '18-11-21 10:35',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.027',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.7.176.75',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.192',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.155.82',
 'LAST_CHECK_TIME': '18-11-21 10:34',
 'LOCATION': '',
 'PORT': '443',
 'SPEED': '3.462',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.115.78.240',
 'LAST_CHECK_TIME': '18-11-21 10:33',
 'LOCATION': '',
 'PORT': '38157',
 'SPEED': '3.703',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.182.121.252',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.319',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.69.82.110',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '44693',
 'SPEED': '0.311',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.225.1',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.3.150.210',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '41258',
 'SPEED': '5.525',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.32.221.21',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '3.929',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.90.229',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.236',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.138.33.20',
 'LAST_CHECK_TIME': '18-11-21 10:32',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.158',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.55.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.190.94.224',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.278',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.16.9',
 'LAST_CHECK_TIME': '18-11-21 02:02',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.146.2.234',
 'LAST_CHECK_TIME': '18-11-21 02:01',
 'LOCATION': '',
 'PORT': '39960',
 'SPEED': '0.243',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '211.147.239.101',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '57281',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.77.156',
 'LAST_CHECK_TIME': '18-11-21 01:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.227',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.86.80',
 'LAST_CHECK_TIME': '18-11-21 01:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.466',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.71.15',
 'LAST_CHECK_TIME': '18-11-21 01:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.529',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.240.224.252',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '33035',
 'SPEED': '0.186',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.224.101.48',
 'LAST_CHECK_TIME': '18-11-20 13:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.088',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.3.170.89',
 'LAST_CHECK_TIME': '18-11-20 13:30',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.85.248',
 'LAST_CHECK_TIME': '18-11-20 13:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.992',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '111.72.115.59',
 'LAST_CHECK_TIME': '18-11-20 12:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.27',
 'LAST_CHECK_TIME': '18-11-20 12:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.32',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.135.217.7',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.324',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.53.128.83',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.102',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '117.64.224.150',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.176',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '140.207.50.246',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '51426',
 'SPEED': '0.158',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.236.237.145',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.138',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.234.5.128',
 'LAST_CHECK_TIME': '18-11-21 10:31',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.065',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.238.186.188',
 'LAST_CHECK_TIME': '18-11-21 10:27',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '2.015',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.183.233.6',
 'LAST_CHECK_TIME': '18-11-21 10:26',
 'LOCATION': '',
 'PORT': '54896',
 'SPEED': '3.406',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.17.45.90',
 'LAST_CHECK_TIME': '18-11-21 10:24',
 'LOCATION': '',
 'PORT': '43411',
 'SPEED': '0.15',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.71',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '42788',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.103',
 'LAST_CHECK_TIME': '18-11-21 10:22',
 'LOCATION': '',
 'PORT': '49955',
 'SPEED': '2.847',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '220.169.127.172',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '51469',
 'SPEED': '0.208',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.86.181.70',
 'LAST_CHECK_TIME': '18-11-21 10:21',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.13',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.30.221.39',
 'LAST_CHECK_TIME': '18-11-21 10:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.166',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.169',
 'LAST_CHECK_TIME': '18-11-21 00:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.244',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.17.236.83',
 'LAST_CHECK_TIME': '18-11-21 00:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.347',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.115.49.174',
 'LAST_CHECK_TIME': '18-11-21 00:30',
 'LOCATION': '',
 'PORT': '59216',
 'SPEED': '0.146',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.69.13.242',
 'LAST_CHECK_TIME': '18-11-21 00:23',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '3.461',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.127.93.188',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '57985',
 'SPEED': '4.426',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.253.84.183',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '30071',
 'SPEED': '4.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.254',
 'LAST_CHECK_TIME': '18-11-21 00:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.718',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '58.62.238.150',
 'LAST_CHECK_TIME': '18-11-21 00:16',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.78.214',
 'LAST_CHECK_TIME': '18-11-21 00:05',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.895',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.86.208.98',
 'LAST_CHECK_TIME': '18-11-21 00:00',
 'LOCATION': '',
 'PORT': '41683',
 'SPEED': '1.181',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.27.43',
 'LAST_CHECK_TIME': '18-11-20 23:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.338',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.218.102.146',
 'LAST_CHECK_TIME': '18-11-20 23:45',
 'LOCATION': '',
 'PORT': '33323',
 'SPEED': '0.019',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.70.66',
 'LAST_CHECK_TIME': '18-11-20 23:41',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.234.181.194',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '33695',
 'SPEED': '3.011',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '120.10.25.4',
 'LAST_CHECK_TIME': '18-11-20 12:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.122.53',
 'LAST_CHECK_TIME': '18-11-20 12:12',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.912',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.175.218.98',
 'LAST_CHECK_TIME': '18-11-20 12:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.692',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.4.217',
 'LAST_CHECK_TIME': '18-11-20 11:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '2.468',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.156.237',
 'LAST_CHECK_TIME': '18-11-20 11:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.217',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '61.178.127.14',
 'LAST_CHECK_TIME': '18-11-20 11:21',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.165',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.185.221.142',
 'LAST_CHECK_TIME': '18-11-20 10:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.121',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.25.193',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.558',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.44',
 'LAST_CHECK_TIME': '18-11-20 10:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.194',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.59.84.15',
 'LAST_CHECK_TIME': '18-11-20 10:30',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.784',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '49.82.50.36',
 'LAST_CHECK_TIME': '18-11-20 10:21',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '4.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.61.203.134',
 'LAST_CHECK_TIME': '18-11-20 10:15',
 'LOCATION': '',
 'PORT': '51987',
 'SPEED': '0.172',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.178.227.171',
 'LAST_CHECK_TIME': '18-11-20 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.006',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.20',
 'LAST_CHECK_TIME': '18-11-20 09:45',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.25',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.12.7.54',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.106',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.17',
 'LAST_CHECK_TIME': '18-11-21 10:15',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.206',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.7.61.8',
 'LAST_CHECK_TIME': '18-11-21 10:12',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '1.275',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.95',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '43150',
 'SPEED': '4.819',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.76.162',
 'LAST_CHECK_TIME': '18-11-21 10:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.196',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '113.108.242.36',
 'LAST_CHECK_TIME': '18-11-21 10:10',
 'LOCATION': '',
 'PORT': '47713',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '49.71.66.82',
 'LAST_CHECK_TIME': '18-11-21 10:07',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.191.201.38',
 'LAST_CHECK_TIME': '18-11-21 10:04',
 'LOCATION': '',
 'PORT': '45461',
 'SPEED': '0.284',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.235.181.175',
 'LAST_CHECK_TIME': '18-11-21 09:58',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.153',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.98',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '37614',
 'SPEED': '0.211',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.210.120.153',
 'LAST_CHECK_TIME': '18-11-21 09:55',
 'LOCATION': '',
 'PORT': '54402',
 'SPEED': '2.225',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.54.248.42',
 'LAST_CHECK_TIME': '18-11-21 09:53',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '1.773',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '106.58.112.84',
 'LAST_CHECK_TIME': '18-11-21 09:46',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.477',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '112.98.126.100',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '41578',
 'SPEED': '2.683',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.81',
 'LAST_CHECK_TIME': '18-11-20 23:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.24.16.198',
 'LAST_CHECK_TIME': '18-11-20 23:31',
 'LOCATION': '',
 'PORT': '43620',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.165.131',
 'LAST_CHECK_TIME': '18-11-20 23:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.229',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.165.234',
 'LAST_CHECK_TIME': '18-11-20 23:23',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.819',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.214.180.122',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '33190',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '118.181.226.216',
 'LAST_CHECK_TIME': '18-11-20 23:22',
 'LOCATION': '',
 'PORT': '36430',
 'SPEED': '0.261',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.40.80',
 'LAST_CHECK_TIME': '18-11-20 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.473',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.154.99',
 'LAST_CHECK_TIME': '18-11-20 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.3',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.248',
 'LAST_CHECK_TIME': '18-11-20 23:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.597',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.187.206.207',
 'LAST_CHECK_TIME': '18-11-20 22:55',
 'LOCATION': '',
 'PORT': '46693',
 'SPEED': '4.125',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.178.149.237',
 'LAST_CHECK_TIME': '18-11-20 22:40',
 'LOCATION': '',
 'PORT': '59042',
 'SPEED': '1.809',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '49.71.81.165',
 'LAST_CHECK_TIME': '18-11-20 22:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '4.586',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.190',
 'LAST_CHECK_TIME': '18-11-20 22:15',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.78.43.87',
 'LAST_CHECK_TIME': '18-11-20 22:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.142',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.48.51.212',
 'LAST_CHECK_TIME': '18-11-20 09:34',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.123',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.172.191.226',
 'LAST_CHECK_TIME': '18-11-20 09:24',
 'LOCATION': '',
 'PORT': '33384',
 'SPEED': '4.076',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.72.195.140',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.612',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.20',
 'LAST_CHECK_TIME': '18-11-20 09:22',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '5.48',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.228',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.803',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '60.169.199.126',
 'LAST_CHECK_TIME': '18-11-20 09:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.416',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.24.170',
 'LAST_CHECK_TIME': '18-11-20 08:46',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.977',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.186.228',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.735',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.74.147',
 'LAST_CHECK_TIME': '18-11-20 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.247',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.77.167',
 'LAST_CHECK_TIME': '18-11-20 08:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.215',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.173.72.153',
 'LAST_CHECK_TIME': '18-11-20 08:05',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.165.130.111',
 'LAST_CHECK_TIME': '18-11-20 07:55',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.527',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.104.38',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.781',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.116',
 'LAST_CHECK_TIME': '18-11-20 07:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.421',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.133.245.70',
 'LAST_CHECK_TIME': '18-11-21 09:45',
 'LOCATION': '',
 'PORT': '35652',
 'SPEED': '0.192',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.223.77.203',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.562',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '122.237.107.148',
 'LAST_CHECK_TIME': '18-11-21 09:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.129',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.122.92.252',
 'LAST_CHECK_TIME': '18-11-21 09:42',
 'LOCATION': '',
 'PORT': '37901',
 'SPEED': '0.497',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.69.218',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.298',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.128.9.235',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '59593',
 'SPEED': '0.032',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.189.152.86',
 'LAST_CHECK_TIME': '18-11-21 09:22',
 'LOCATION': '',
 'PORT': '52277',
 'SPEED': '0.352',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.114',
 'LAST_CHECK_TIME': '18-11-21 09:15',
 'LOCATION': '',
 'PORT': '45691',
 'SPEED': '0.018',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.162.168.192',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '40274',
 'SPEED': '0.139',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '116.192.171.51',
 'LAST_CHECK_TIME': '18-11-21 09:01',
 'LOCATION': '',
 'PORT': '48565',
 'SPEED': '3.016',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.64.32.100',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.16',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.70.103',
 'LAST_CHECK_TIME': '18-11-21 09:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.209',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.160.247.63',
 'LAST_CHECK_TIME': '18-11-21 08:51',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.154',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.15.121.235',
 'LAST_CHECK_TIME': '18-11-21 08:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.286',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.89.33.59',
 'LAST_CHECK_TIME': '18-11-20 21:45',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.11',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.176.186',
 'LAST_CHECK_TIME': '18-11-20 21:44',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.537',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.223.115.30',
 'LAST_CHECK_TIME': '18-11-20 21:22',
 'LOCATION': '',
 'PORT': '51618',
 'SPEED': '0.073',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '27.184.127.79',
 'LAST_CHECK_TIME': '18-11-20 21:17',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.066',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.164.78',
 'LAST_CHECK_TIME': '18-11-20 21:16',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.348',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.219.106.147',
 'LAST_CHECK_TIME': '18-11-20 21:10',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.228.49.232',
 'LAST_CHECK_TIME': '18-11-20 21:02',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.692',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '113.121.243.50',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '38118',
 'SPEED': '1.19',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.154.23',
 'LAST_CHECK_TIME': '18-11-20 21:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '0.505',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.183.121.126',
 'LAST_CHECK_TIME': '18-11-20 20:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.081',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.25.163',
 'LAST_CHECK_TIME': '18-11-20 20:47',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.839',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.91.11',
 'LAST_CHECK_TIME': '18-11-20 20:42',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.427',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.193.132',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6675',
 'SPEED': '1.199',
 'TYPE': 'socks4/5'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.24.111',
 'LAST_CHECK_TIME': '18-11-20 20:33',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.193',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '113.103.15.139',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.913',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.175.136.195',
 'LAST_CHECK_TIME': '18-11-20 07:33',
 'LOCATION': '',
 'PORT': '54584',
 'SPEED': '0.187',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.192.216',
 'LAST_CHECK_TIME': '18-11-20 07:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.536',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.55.21.194',
 'LAST_CHECK_TIME': '18-11-20 07:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '1.224',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '58.210.133.98',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '32741',
 'SPEED': '0.214',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.52.18.115',
 'LAST_CHECK_TIME': '18-11-20 07:22',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '42.176.36.251',
 'LAST_CHECK_TIME': '18-11-20 07:01',
 'LOCATION': '',
 'PORT': '37000',
 'SPEED': '0.357',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '106.14.214.94',
 'LAST_CHECK_TIME': '18-11-20 06:56',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.104',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.157.174.133',
 'LAST_CHECK_TIME': '18-11-20 06:20',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.39',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.17.236.52',
 'LAST_CHECK_TIME': '18-11-20 06:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.802',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '222.182.56.218',
 'LAST_CHECK_TIME': '18-11-20 03:32',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '116.113.27.170',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '47849',
 'SPEED': '0.094',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.119.65.16',
 'LAST_CHECK_TIME': '18-11-20 03:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '39.76.14.191',
 'LAST_CHECK_TIME': '18-11-20 03:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.635',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '101.236.62.20',
 'LAST_CHECK_TIME': '18-11-21 08:44',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.023',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.221.136',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.135',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.162.223',
 'LAST_CHECK_TIME': '18-11-21 08:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.265',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.135.92.68',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '38094',
 'SPEED': '0.112',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '58.240.7.195',
 'LAST_CHECK_TIME': '18-11-21 08:22',
 'LOCATION': '',
 'PORT': '32617',
 'SPEED': '0.207',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '61.178.238.122',
 'LAST_CHECK_TIME': '18-11-21 08:20',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.338',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.139.245.130',
 'LAST_CHECK_TIME': '18-11-21 08:17',
 'LOCATION': '',
 'PORT': '58424',
 'SPEED': '4.812',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.217.68.51',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '54355',
 'SPEED': '6.414',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '183.159.91.31',
 'LAST_CHECK_TIME': '18-11-21 08:16',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.556',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.73.195',
 'LAST_CHECK_TIME': '18-11-21 08:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.249',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '60.216.101.46',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '59351',
 'SPEED': '0.11',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.193.135.242',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '54219',
 'SPEED': '0.027',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.35.102.61',
 'LAST_CHECK_TIME': '18-11-21 07:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.48',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '210.72.14.142',
 'LAST_CHECK_TIME': '18-11-21 07:44',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.912',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.10',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.498',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.67.25.83',
 'LAST_CHECK_TIME': '18-11-20 20:30',
 'LOCATION': '',
 'PORT': '41681',
 'SPEED': '0.342',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '106.15.202.34',
 'LAST_CHECK_TIME': '18-11-20 20:21',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.104',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '116.236.98.78',
 'LAST_CHECK_TIME': '18-11-20 20:02',
 'LOCATION': '',
 'PORT': '43682',
 'SPEED': '0.165',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.68.115',
 'LAST_CHECK_TIME': '18-11-20 19:50',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.805',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.166.159',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.28',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.156.179',
 'LAST_CHECK_TIME': '18-11-20 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.467',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.168.136.31',
 'LAST_CHECK_TIME': '18-11-20 19:22',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.184',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.44.62',
 'LAST_CHECK_TIME': '18-11-20 19:21',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.031',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '114.99.167.121',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.599',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.174.225.26',
 'LAST_CHECK_TIME': '18-11-20 19:15',
 'LOCATION': '',
 'PORT': '60984',
 'SPEED': '0.14',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.161.208',
 'LAST_CHECK_TIME': '18-11-20 19:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.194.214',
 'LAST_CHECK_TIME': '18-11-20 19:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.529',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.254.94.105',
 'LAST_CHECK_TIME': '18-11-20 18:55',
 'LOCATION': '',
 'PORT': '58999',
 'SPEED': '3.252',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '110.87.25.61',
 'LAST_CHECK_TIME': '18-11-20 02:45',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '1.189',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.202',
 'LAST_CHECK_TIME': '18-11-20 02:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.823',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.25.124',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.925',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.43',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.501',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '36.33.32.158',
 'LAST_CHECK_TIME': '18-11-20 02:30',
 'LOCATION': '',
 'PORT': '59019',
 'SPEED': '0.205',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '123.180.69.54',
 'LAST_CHECK_TIME': '18-11-20 02:11',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.845',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.77.72',
 'LAST_CHECK_TIME': '18-11-20 01:52',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.577',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.64.130',
 'LAST_CHECK_TIME': '18-11-20 01:46',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.816',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '175.148.79.233',
 'LAST_CHECK_TIME': '18-11-20 01:44',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.246',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '220.173.106.168',
 'LAST_CHECK_TIME': '18-11-20 01:38',
 'LOCATION': '',
 'PORT': '63000',
 'SPEED': '0.284',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.234.194.141',
 'LAST_CHECK_TIME': '18-11-20 01:33',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '5.641',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.162.208',
 'LAST_CHECK_TIME': '18-11-20 01:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '3.568',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.228.49.227',
 'LAST_CHECK_TIME': '18-11-20 01:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.85',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.219.107.144',
 'LAST_CHECK_TIME': '18-11-20 00:44',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.783',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '182.88.190.207',
 'LAST_CHECK_TIME': '18-11-21 07:36',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.426',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '125.115.183.18',
 'LAST_CHECK_TIME': '18-11-21 07:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.237',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.48.73.16',
 'LAST_CHECK_TIME': '18-11-21 07:16',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.155',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '124.232.133.201',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '30819',
 'SPEED': '0.152',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.76.117',
 'LAST_CHECK_TIME': '18-11-21 07:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.195',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '222.94.151.166',
 'LAST_CHECK_TIME': '18-11-21 06:50',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.142',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.229.18.254',
 'LAST_CHECK_TIME': '18-11-21 06:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.728',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.24.215.49',
 'LAST_CHECK_TIME': '18-11-21 06:11',
 'LOCATION': '',
 'PORT': '57248',
 'SPEED': '0.14',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.200.8.193',
 'LAST_CHECK_TIME': '18-11-21 06:01',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '1.061',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.32.37.28',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.355',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.38.81',
 'LAST_CHECK_TIME': '18-11-21 05:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.687',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '59.57.151.126',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '37749',
 'SPEED': '6.328',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '120.84.130.112',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '0.17',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '219.135.162.198',
 'LAST_CHECK_TIME': '18-11-21 05:15',
 'LOCATION': '',
 'PORT': '47201',
 'SPEED': '3.052',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '219.142.132.146',
 'LAST_CHECK_TIME': '18-11-20 18:33',
 'LOCATION': '',
 'PORT': '40655',
 'SPEED': '3.836',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.168.13.26',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '8000',
 'SPEED': '4.068',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '117.21.191.154',
 'LAST_CHECK_TIME': '18-11-20 18:30',
 'LOCATION': '',
 'PORT': '32431',
 'SPEED': '0.194',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.106.91.58',
 'LAST_CHECK_TIME': '18-11-20 18:22',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '0.269',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.202.216.218',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '53281',
 'SPEED': '0.18',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.31.143.180',
 'LAST_CHECK_TIME': '18-11-20 18:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '7.255',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '124.235.135.210',
 'LAST_CHECK_TIME': '18-11-20 17:50',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '3.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.57.214',
 'LAST_CHECK_TIME': '18-11-20 17:45',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.24.153',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '7.156',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.42',
 'LAST_CHECK_TIME': '18-11-20 17:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.367',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '119.99.133.223',
 'LAST_CHECK_TIME': '18-11-20 17:06',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.212',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.147.198',
 'LAST_CHECK_TIME': '18-11-20 17:00',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '1.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '222.94.150.45',
 'LAST_CHECK_TIME': '18-11-20 16:44',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.873',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.45.88.109',
 'LAST_CHECK_TIME': '18-11-20 16:22',
 'LOCATION': '',
 'PORT': '61710',
 'SPEED': '0.842',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.78.41',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.039',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.225.24.219',
 'LAST_CHECK_TIME': '18-11-20 00:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '5.876',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.153.165',
 'LAST_CHECK_TIME': '18-11-20 00:11',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.234',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.79.224',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.553',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '59.32.37.229',
 'LAST_CHECK_TIME': '18-11-19 23:55',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '3.208',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '118.190.95.35',
 'LAST_CHECK_TIME': '18-11-19 23:51',
 'LOCATION': '',
 'PORT': '9001',
 'SPEED': '0.052',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.70.2',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '4.827',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '119.1.97.193',
 'LAST_CHECK_TIME': '18-11-19 23:31',
 'LOCATION': '',
 'PORT': '60916',
 'SPEED': '0.398',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.138.140',
 'LAST_CHECK_TIME': '18-11-19 23:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.226',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.72.100',
 'LAST_CHECK_TIME': '18-11-19 23:10',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.91',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.64.78',
 'LAST_CHECK_TIME': '18-11-19 23:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.026',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '101.236.54.166',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.02',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '223.203.0.14',
 'LAST_CHECK_TIME': '18-11-19 22:55',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '0.025',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.99.255.28',
 'LAST_CHECK_TIME': '18-11-19 22:46',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.133',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '221.234.249.18',
 'LAST_CHECK_TIME': '18-11-21 05:07',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.058',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '36.110.14.66',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50519',
 'SPEED': '0.061',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '119.254.94.123',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '50972',
 'SPEED': '0.589',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.244.78.198',
 'LAST_CHECK_TIME': '18-11-21 05:00',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.172',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '123.185.67.48',
 'LAST_CHECK_TIME': '18-11-21 04:55',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.149',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '110.72.192.105',
 'LAST_CHECK_TIME': '18-11-21 04:32',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.69',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.219.106.26',
 'LAST_CHECK_TIME': '18-11-21 04:30',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '4.865',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '171.38.25.235',
 'LAST_CHECK_TIME': '18-11-21 04:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.83',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '118.181.226.22',
 'LAST_CHECK_TIME': '18-11-21 03:15',
 'LOCATION': '',
 'PORT': '37346',
 'SPEED': '5.685',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.249.45.162',
 'LAST_CHECK_TIME': '18-11-21 03:11',
 'LOCATION': '',
 'PORT': '35586',
 'SPEED': '0.051',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '27.184.49.208',
 'LAST_CHECK_TIME': '18-11-21 03:10',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.067',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '42.59.86.81',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '2.397',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.72.195',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.181',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '115.46.67.47',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.935',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.163.152.130',
 'LAST_CHECK_TIME': '18-11-20 16:15',
 'LOCATION': '',
 'PORT': '60596',
 'SPEED': '0.173',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.15.114',
 'LAST_CHECK_TIME': '18-11-20 16:14',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.179',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.46.89.156',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.652',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '115.223.85.244',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '8010',
 'SPEED': '1.568',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '111.72.155.164',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '53128',
 'SPEED': '3.235',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '61.170.179.89',
 'LAST_CHECK_TIME': '18-11-20 16:00',
 'LOCATION': '',
 'PORT': '50799',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '110.87.25.206',
 'LAST_CHECK_TIME': '18-11-20 15:55',
 'LOCATION': '',
 'PORT': '6666',
 'SPEED': '0.433',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '180.110.5.254',
 'LAST_CHECK_TIME': '18-11-20 15:45',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.51',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.37.159.233',
 'LAST_CHECK_TIME': '18-11-20 15:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '6.323',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.134.204',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.477',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '59.32.37.249',
 'LAST_CHECK_TIME': '18-11-20 14:55',
 'LOCATION': '',
 'PORT': '61234',
 'SPEED': '2.87',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '123.185.5.9',
 'LAST_CHECK_TIME': '18-11-20 14:52',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.118',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '36.48.132.203',
 'LAST_CHECK_TIME': '18-11-20 14:44',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.127',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.68.73',
 'LAST_CHECK_TIME': '18-11-19 22:45',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.584',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '182.88.213.234',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.387',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '221.229.18.71',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.041',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.115.181.125',
 'LAST_CHECK_TIME': '18-11-19 22:33',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.7',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.215.149.170',
 'LAST_CHECK_TIME': '18-11-19 22:23',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.079',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '180.110.5.189',
 'LAST_CHECK_TIME': '18-11-19 22:22',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.204',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.59.193.14',
 'LAST_CHECK_TIME': '18-11-19 22:15',
 'LOCATION': '',
 'PORT': '47138',
 'SPEED': '7.113',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.36.247',
 'LAST_CHECK_TIME': '18-11-19 22:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '2.609',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.69.36',
 'LAST_CHECK_TIME': '18-11-19 22:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.768',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.193.214',
 'LAST_CHECK_TIME': '18-11-19 22:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.388',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.38.41.205',
 'LAST_CHECK_TIME': '18-11-19 21:55',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '5.818',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '14.204.20.95',
 'LAST_CHECK_TIME': '18-11-19 21:40',
 'LOCATION': '',
 'PORT': '8080',
 'SPEED': '2.262',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '218.59.228.18',
 'LAST_CHECK_TIME': '18-11-21 03:00',
 'LOCATION': '',
 'PORT': '61976',
 'SPEED': '3.116',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.73.180',
 'LAST_CHECK_TIME': '18-11-21 02:41',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.271',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici1.html>
{'IP': '175.148.75.4',
 'LAST_CHECK_TIME': '18-11-21 02:33',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.161',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '171.38.90.92',
 'LAST_CHECK_TIME': '18-11-20 14:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.405',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '121.225.26.86',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.178',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '183.15.122.107',
 'LAST_CHECK_TIME': '18-11-20 14:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '6.593',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.138.159.221',
 'LAST_CHECK_TIME': '18-11-20 14:21',
 'LOCATION': '',
 'PORT': '808',
 'SPEED': '0.242',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '221.229.18.91',
 'LAST_CHECK_TIME': '18-11-20 14:20',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '2.855',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '101.236.59.11',
 'LAST_CHECK_TIME': '18-11-20 14:12',
 'LOCATION': '',
 'PORT': '8866',
 'SPEED': '0.026',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:01',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.457',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '218.17.253.106',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '60004',
 'SPEED': '0.926',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '182.88.14.31',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.438',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '125.40.109.154',
 'LAST_CHECK_TIME': '18-11-20 14:00',
 'LOCATION': '',
 'PORT': '31610',
 'SPEED': '1.458',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici2.html>
{'IP': '175.150.73.206',
 'LAST_CHECK_TIME': '18-11-20 13:45',
 'LOCATION': '',
 'PORT': '1133',
 'SPEED': '0.214',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.80.249',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.322',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.165.77',
 'LAST_CHECK_TIME': '18-11-19 21:30',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '1.302',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.157.171',
 'LAST_CHECK_TIME': '18-11-19 21:22',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.189',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.97.196',
 'LAST_CHECK_TIME': '18-11-19 21:15',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.287',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.170.140',
 'LAST_CHECK_TIME': '18-11-19 21:11',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.2',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '121.31.143.219',
 'LAST_CHECK_TIME': '18-11-19 21:00',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.223',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '114.230.41.119',
 'LAST_CHECK_TIME': '18-11-19 20:22',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '0.317',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '183.15.120.189',
 'LAST_CHECK_TIME': '18-11-19 20:00',
 'LOCATION': '',
 'PORT': '3128',
 'SPEED': '3.676',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '218.22.102.107',
 'LAST_CHECK_TIME': '18-11-19 19:56',
 'LOCATION': '',
 'PORT': '80',
 'SPEED': '6.389',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '125.120.164.118',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8118',
 'SPEED': '0.16',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '171.37.162.198',
 'LAST_CHECK_TIME': '18-11-19 19:51',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.279',
 'TYPE': 'HTTP'}
2018-11-26 10:17:34 [scrapy.core.scraper] DEBUG: Scraped from <200 file:///home/ubuntu/Documents/xici3.html>
{'IP': '115.46.75.106',
 'LAST_CHECK_TIME': '18-11-19 19:33',
 'LOCATION': '',
 'PORT': '8123',
 'SPEED': '0.429',
 'TYPE': 'HTTPS'}
2018-11-26 10:17:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 10:17:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 233143,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 2, 17, 34, 398570),
 'item_scraped_count': 300,
 'log_count/DEBUG': 304,
 'log_count/INFO': 7,
 'memusage/max': 760889344,
 'memusage/startup': 760889344,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 26, 2, 17, 34, 23756)}
2018-11-26 10:17:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 10:17:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 10:17:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 10:17:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 10:17:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 10:17:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 10:17:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 10:17:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 10:17:43 [scrapy.core.engine] INFO: Spider opened
2018-11-26 10:17:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:17:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 10:18:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 10:18:46 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:46 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:46 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_2.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_3.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_1.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 10:18:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 10:18:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 9,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 9,
 'downloader/request_bytes': 2106,
 'downloader/request_count': 9,
 'downloader/request_method_count/GET': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 2, 18, 46, 808383),
 'log_count/DEBUG': 10,
 'log_count/ERROR': 3,
 'log_count/INFO': 8,
 'memusage/max': 769273856,
 'memusage/startup': 769273856,
 'retry/count': 6,
 'retry/max_reached': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 6,
 'scheduler/dequeued': 9,
 'scheduler/dequeued/memory': 9,
 'scheduler/enqueued': 9,
 'scheduler/enqueued/memory': 9,
 'start_time': datetime.datetime(2018, 11, 26, 2, 17, 43, 538965)}
2018-11-26 10:18:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 11:16:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 11:16:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 11:16:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 11:16:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 11:16:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 11:16:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 11:16:05 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 11:16:05 [scrapy.core.engine] INFO: Spider opened
2018-11-26 11:16:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 11:16:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 11:16:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:16:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:16:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:16:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:16:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:16:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:17:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 11:17:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_2.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:17:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_3.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:17:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://www.bturl.cc/search/mkv_ctime_1.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-11-26 11:17:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_2.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 11:17:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_3.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 11:17:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.bturl.cc/search/mkv_ctime_1.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-26 11:17:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 11:17:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 9,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 9,
 'downloader/request_bytes': 2106,
 'downloader/request_count': 9,
 'downloader/request_method_count/GET': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 3, 17, 9, 283414),
 'log_count/DEBUG': 10,
 'log_count/ERROR': 3,
 'log_count/INFO': 8,
 'memusage/max': 865878016,
 'memusage/startup': 865878016,
 'retry/count': 6,
 'retry/max_reached': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 6,
 'scheduler/dequeued': 9,
 'scheduler/dequeued/memory': 9,
 'scheduler/enqueued': 9,
 'scheduler/enqueued/memory': 9,
 'start_time': datetime.datetime(2018, 11, 26, 3, 16, 5, 998621)}
2018-11-26 11:17:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 11:46:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 11:46:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 11:46:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 11:46:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 11:46:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 11:46:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 11:46:17 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 11:46:17 [scrapy.core.engine] INFO: Spider opened
2018-11-26 11:46:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 11:46:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 11:46:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_2.html> (referer: None)
2018-11-26 11:46:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/9a7e1c22defe15a25b0217570e2835a94065dc7d.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_3.html> (referer: None)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/47edd83574f9885b75d7298b7c2737b67d3cc8da.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ee15dc4e226ed3bd65afdeec4fca51840629211a.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1c0e64ee3bfd7b2783ddaad6310f08f2720a8ef3.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b5e54a6ddca5368fe3976a9469305b526c8e8fd.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2727abfbb6429e73abf27ab8c06ed95751192ab8.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e51876affc0ee1934ebb80495373b8856efb47f.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3092570032fd66b590e6bce0bb72bd645df4ccf4.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f53180663b7320c8557408c631f1ae779a55a3fe.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/919c64056e8acb9109b45a30312f9319bdce5169.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1ab7f80ca1213003bfc49eab789e2b811d3cedd7.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/0ced8a022ae5d260285cea81d5d7b525c0d92e48.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/07343fd8572bc808f3a6ca140463088565d4c17b.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/20a1b80d1e37e733484db75dd289c8022a6c8554.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/296c44c0c74d6e2fc89edd85667c90cd68fb03e1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ffa0423e91eede10d00b2a6aef3de040063e7878.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/21a6f405633a123d474aa28761c8482e3bd75c85.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/889bc388426a01dd95459516c98de4eee135a650.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/7a167f2d053ea67d1985adf7b9d31e93a9d74468.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/311d826ad5b372c1f16f5a2c1ccdc13e938ad1b1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 11:46:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 11:46:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 13170,
 'downloader/request_count': 33,
 'downloader/request_method_count/GET': 33,
 'downloader/response_bytes': 76212,
 'downloader/response_count': 33,
 'downloader/response_status_count/200': 33,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 3, 46, 21, 33233),
 'log_count/DEBUG': 34,
 'log_count/INFO': 7,
 'memusage/max': 870436864,
 'memusage/startup': 870436864,
 'request_depth_max': 1,
 'response_received_count': 33,
 'scheduler/dequeued': 33,
 'scheduler/dequeued/memory': 33,
 'scheduler/enqueued': 33,
 'scheduler/enqueued/memory': 33,
 'start_time': datetime.datetime(2018, 11, 26, 3, 46, 17, 721111)}
2018-11-26 11:46:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:15:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:15:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:15:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:15:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:15:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:15:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:15:36 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:15:36 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:15:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:15:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_3.html> (referer: None)
2018-11-26 17:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/07343fd8572bc808f3a6ca140463088565d4c17b.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/311d826ad5b372c1f16f5a2c1ccdc13e938ad1b1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/296c44c0c74d6e2fc89edd85667c90cd68fb03e1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/21a6f405633a123d474aa28761c8482e3bd75c85.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/0ced8a022ae5d260285cea81d5d7b525c0d92e48.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/7a167f2d053ea67d1985adf7b9d31e93a9d74468.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/919c64056e8acb9109b45a30312f9319bdce5169.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_2.html> (referer: None)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/889bc388426a01dd95459516c98de4eee135a650.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/9a7e1c22defe15a25b0217570e2835a94065dc7d.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ffa0423e91eede10d00b2a6aef3de040063e7878.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f53180663b7320c8557408c631f1ae779a55a3fe.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e51876affc0ee1934ebb80495373b8856efb47f.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3092570032fd66b590e6bce0bb72bd645df4ccf4.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1c0e64ee3bfd7b2783ddaad6310f08f2720a8ef3.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ee15dc4e226ed3bd65afdeec4fca51840629211a.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b5e54a6ddca5368fe3976a9469305b526c8e8fd.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1ab7f80ca1213003bfc49eab789e2b811d3cedd7.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2727abfbb6429e73abf27ab8c06ed95751192ab8.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/47edd83574f9885b75d7298b7c2737b67d3cc8da.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:15:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/20a1b80d1e37e733484db75dd289c8022a6c8554.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:15:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:15:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:15:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 13170,
 'downloader/request_count': 33,
 'downloader/request_method_count/GET': 33,
 'downloader/response_bytes': 76322,
 'downloader/response_count': 33,
 'downloader/response_status_count/200': 33,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 15, 52, 123899),
 'log_count/DEBUG': 34,
 'log_count/INFO': 7,
 'memusage/max': 873689088,
 'memusage/startup': 873689088,
 'request_depth_max': 1,
 'response_received_count': 33,
 'scheduler/dequeued': 33,
 'scheduler/dequeued/memory': 33,
 'scheduler/enqueued': 33,
 'scheduler/enqueued/memory': 33,
 'start_time': datetime.datetime(2018, 11, 26, 9, 15, 36, 89871)}
2018-11-26 17:15:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:18:16 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:18:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:18:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:18:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:18:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:18:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:18:16 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:18:16 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:18:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:18:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv'}
2018-11-26 17:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv'}
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv'}
2018-11-26 17:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv'}
2018-11-26 17:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv'}
2018-11-26 17:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv'}
2018-11-26 17:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv'}
2018-11-26 17:18:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:18:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7778,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 30342,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 18, 19, 524738),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/INFO': 7,
 'memusage/max': 874692608,
 'memusage/startup': 874692608,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 18, 16, 205643)}
2018-11-26 17:18:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:18:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:18:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:18:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:18:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:18:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:18:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:18:37 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:18:37 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:18:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:18:37 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:18:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:18:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18'}
2018-11-26 17:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:18:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21'}
2018-11-26 17:18:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26'}
2018-11-26 17:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:18:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24'}
2018-11-26 17:18:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:18:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12'}
2018-11-26 17:18:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:18:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09'}
2018-11-26 17:18:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:18:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13'}
2018-11-26 17:18:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:18:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18'}
2018-11-26 17:18:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:18:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13'}
2018-11-26 17:18:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:18:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17'}
2018-11-26 17:18:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:18:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7854,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 30172,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 18, 52, 207933),
 'item_scraped_count': 10,
 'log_count/DEBUG': 32,
 'log_count/INFO': 7,
 'memusage/max': 877006848,
 'memusage/startup': 877006848,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 18, 37, 776032)}
2018-11-26 17:18:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:18:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:18:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:18:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:18:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:18:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:18:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:18:53 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:18:53 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:18:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:18:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:18:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18'}
2018-11-26 17:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13'}
2018-11-26 17:18:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:18:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26'}
2018-11-26 17:18:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:18:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09'}
2018-11-26 17:18:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:18:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:18:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17'}
2018-11-26 17:18:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:18:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12'}
2018-11-26 17:18:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:18:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:18:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13'}
2018-11-26 17:18:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24'}
2018-11-26 17:19:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:19:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21'}
2018-11-26 17:19:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:19:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18'}
2018-11-26 17:19:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:19:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7892,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 29959,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 19, 8, 205288),
 'item_scraped_count': 10,
 'log_count/DEBUG': 32,
 'log_count/INFO': 7,
 'memusage/max': 877006848,
 'memusage/startup': 877006848,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 18, 53, 649915)}
2018-11-26 17:19:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:19:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:19:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:19:13 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:19:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:19:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:19:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17'}
2018-11-26 17:19:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:19:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21'}
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:19:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18'}
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24'}
2018-11-26 17:19:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13'}
2018-11-26 17:19:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:19:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18'}
2018-11-26 17:19:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:19:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13'}
2018-11-26 17:19:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:19:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12'}
2018-11-26 17:19:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:19:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26'}
2018-11-26 17:19:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:19:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09'}
2018-11-26 17:19:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:19:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7892,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 29891,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 19, 25, 871550),
 'item_scraped_count': 10,
 'log_count/DEBUG': 32,
 'log_count/INFO': 7,
 'memusage/max': 877813760,
 'memusage/startup': 877813760,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 19, 13, 797092)}
2018-11-26 17:19:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:19:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:19:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:19:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:19:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:19:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:19:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:19:31 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:19:31 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:19:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:19:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:19:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:19:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:19:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:19:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4390,
 'downloader/request_count': 11,
 'downloader/request_method_count/GET': 11,
 'downloader/response_bytes': 26636,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 11,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 19, 35, 295845),
 'log_count/DEBUG': 12,
 'log_count/INFO': 7,
 'memusage/max': 884731904,
 'memusage/startup': 884731904,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2018, 11, 26, 9, 19, 31, 492936)}
2018-11-26 17:19:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:22:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:22:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:22:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:22:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:22:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:22:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:22:04 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:22:04 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:22:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:22:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:22:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:22:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18'}
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:22:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26'}
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18'}
2018-11-26 17:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21'}
2018-11-26 17:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12'}
2018-11-26 17:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13'}
2018-11-26 17:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17'}
2018-11-26 17:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:22:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13'}
2018-11-26 17:22:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09'}
2018-11-26 17:22:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:22:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7892,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 29832,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 22, 20, 625168),
 'item_scraped_count': 9,
 'log_count/DEBUG': 31,
 'log_count/INFO': 7,
 'memusage/max': 893206528,
 'memusage/startup': 893206528,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 22, 4, 623895)}
2018-11-26 17:22:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:22:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:22:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:22:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:22:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:22:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:22:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:22:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:22:34 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:22:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:22:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:22:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18'}
2018-11-26 17:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24'}
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12'}
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21'}
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17'}
2018-11-26 17:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26'}
2018-11-26 17:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13'}
2018-11-26 17:22:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:22:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18'}
2018-11-26 17:22:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:22:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13'}
2018-11-26 17:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:22:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09'}
2018-11-26 17:22:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:22:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7892,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 29966,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 22, 40, 495015),
 'item_scraped_count': 10,
 'log_count/DEBUG': 32,
 'log_count/INFO': 7,
 'memusage/max': 893206528,
 'memusage/startup': 893206528,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 22, 34, 82884)}
2018-11-26 17:22:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:23:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:23:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:23:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:23:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:23:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:23:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:23:29 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:23:29 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:23:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:23:29 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:23:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:23:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:23:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4390,
 'downloader/request_count': 11,
 'downloader/request_method_count/GET': 11,
 'downloader/response_bytes': 26665,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 11,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 23, 42, 60982),
 'log_count/DEBUG': 12,
 'log_count/INFO': 7,
 'memusage/max': 893206528,
 'memusage/startup': 893206528,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2018, 11, 26, 9, 23, 29, 662830)}
2018-11-26 17:23:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:23:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:23:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:23:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:23:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:23:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:23:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:23:46 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:23:46 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:23:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:23:46 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18'}
2018-11-26 17:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:23:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26'}
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24'}
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17'}
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:23:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18'}
2018-11-26 17:23:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09'}
2018-11-26 17:23:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13'}
2018-11-26 17:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:23:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12'}
2018-11-26 17:23:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21'}
2018-11-26 17:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:24:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13'}
2018-11-26 17:24:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:24:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7854,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 30052,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 24, 1, 23018),
 'item_scraped_count': 10,
 'log_count/DEBUG': 32,
 'log_count/INFO': 7,
 'memusage/max': 893206528,
 'memusage/startup': 893206528,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 23, 46, 651264)}
2018-11-26 17:24:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:24:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:24:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:24:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:24:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:24:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:24:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:24:31 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:24:31 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:24:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:24:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:24:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:24:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24'}
2018-11-26 17:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18'}
2018-11-26 17:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:24:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17'}
2018-11-26 17:24:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:24:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26'}
2018-11-26 17:24:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:24:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12'}
2018-11-26 17:24:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18'}
2018-11-26 17:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:24:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13'}
2018-11-26 17:24:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:24:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:24:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13'}
2018-11-26 17:24:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:24:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21'}
2018-11-26 17:24:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:24:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09'}
2018-11-26 17:24:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:24:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7854,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 30082,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 24, 37, 623733),
 'item_scraped_count': 10,
 'log_count/DEBUG': 32,
 'log_count/INFO': 7,
 'memusage/max': 893206528,
 'memusage/startup': 893206528,
 'request_depth_max': 2,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2018, 11, 26, 9, 24, 31, 873517)}
2018-11-26 17:24:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:25:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:25:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:25:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:25:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:25:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:25:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:25:00 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:25:00 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:25:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:25:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:25:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_3.html> (referer: None)
2018-11-26 17:25:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_2.html> (referer: None)
2018-11-26 17:25:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/0ced8a022ae5d260285cea81d5d7b525c0d92e48.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/296c44c0c74d6e2fc89edd85667c90cd68fb03e1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%28> (referer: None)
2018-11-26 17:25:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%28>
{'baidu': '(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': '(1996)..mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:0CED8A022AE5D260285CEA81D5D7B525C0D92E48'}
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/20a1b80d1e37e733484db75dd289c8022a6c8554.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/21a6f405633a123d474aa28761c8482e3bd75c85.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20v%20konce%20ulicy%20> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f53180663b7320c8557408c631f1ae779a55a3fe.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/07343fd8572bc808f3a6ca140463088565d4c17b.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=queen%20hungary%20rhapsody%20> (referer: None)
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20v%20konce%20ulicy%20>
{'baidu': 'dom v konce ulicy ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'dom v konce ulicy',
 'filename': 'Dom.v.konce.ulicy.2012.x264.BDRip.720p.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:296C44C0C74D6E2FC89EDD85667C90CD68FB03E1'}
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/889bc388426a01dd95459516c98de4eee135a650.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/9a7e1c22defe15a25b0217570e2835a94065dc7d.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=queen%20hungary%20rhapsody%20>
{'baidu': 'queen hungary rhapsody ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'Queen Hungary rhapso',
 'filename': 'Queen.Hungary rhapsody.1986.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:20A1B80D1E37E733484DB75DD289C8022A6C8554'}
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ffa0423e91eede10d00b2a6aef3de040063e7878.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=pod%20pokrovom%20nebes%20> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e51876affc0ee1934ebb80495373b8856efb47f.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=solo> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=penthouse-thekeyparty-> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1c0e64ee3bfd7b2783ddaad6310f08f2720a8ef3.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20bolshoy%20mamochki%20> (referer: None)
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=pod%20pokrovom%20nebes%20>
{'baidu': 'pod pokrovom nebes ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'pokrovom',
 'filename': 'Pod.pokrovom.nebes.1990.BDRip.1080p.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:07343FD8572BC808F3A6CA140463088565D4C17B'}
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=solo>
{'baidu': 'solo',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Solo10_Kaden Kross_1.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:F53180663B7320C8557408C631F1AE779A55A3FE'}
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=penthouse-thekeyparty->
{'baidu': 'penthouse-thekeyparty-',
 'click': '',
 'ctime': ' ',
 'fanyi': 'penthouse-thekeypart',
 'filename': 'Penthouse-TheKeyParty-2012-1080p.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:9A7E1C22DEFE15A25B0217570E2835A94065DC7D'}
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20bolshoy%20mamochki%20>
{'baidu': 'dom bolshoy mamochki ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'dom bolshoy mamochki',
 'filename': 'Dom.bolshoy.mamochki.2000.x264.HDTVRip.1080.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:889BC388426A01DD95459516C98DE4EEE135A650'}
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/311d826ad5b372c1f16f5a2c1ccdc13e938ad1b1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b5e54a6ddca5368fe3976a9469305b526c8e8fd.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20awkward%20sexual%20adventure%20> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sbcdevonmarcojerry_> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=une%20nouvelle%20amie%20> (referer: None)
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20awkward%20sexual%20adventure%20>
{'baidu': 'my awkward sexual adventure ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'My.Awkward.Sexual.Adventure.2012.BDRip.720p.mkv',
 'length': '3918-09-15',
 'link': 'magnet:?xt=urn:btih:1C0E64EE3BFD7B2783DDAAD6310F08F2720A8EF3'}
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ee15dc4e226ed3bd65afdeec4fca51840629211a.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sbcdevonmarcojerry_>
{'baidu': 'sbcdevonmarcojerry_',
 'click': '',
 'ctime': ' ',
 'fanyi': 'sbcdevonmarcojerry_',
 'filename': 'sbcdevonmarcojerry_720.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:FFA0423E91EEDE10D00B2A6AEF3DE040063E7878'}
2018-11-26 17:25:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=une%20nouvelle%20amie%20>
{'baidu': 'une nouvelle amie ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Une.Nouvelle.Amie.2014.D.WEB-DL.720p.uniongang.tv.mkv',
 'length': '2384-12-08',
 'link': 'magnet:?xt=urn:btih:3E51876AFFC0EE1934EBB80495373B8856EFB47F'}
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/919c64056e8acb9109b45a30312f9319bdce5169.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sucker%20punch%20extended%20cut%20> (referer: None)
2018-11-26 17:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1ab7f80ca1213003bfc49eab789e2b811d3cedd7.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2727abfbb6429e73abf27ab8c06ed95751192ab8.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sucker%20punch%20extended%20cut%20>
{'baidu': 'sucker punch extended cut ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Sucker.Punch.Extended.Cut.2011.Dub&L1.BDRip.1080p-TVB.k236.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:6B5E54A6DDCA5368FE3976A9469305B526C8E8FD'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=stalingrad%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=source%20code%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hischniki%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/7a167f2d053ea67d1985adf7b9d31e93a9d74468.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3092570032fd66b590e6bce0bb72bd645df4ccf4.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=stalingrad%20>
{'baidu': 'stalingrad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Stalingrad.1993.x264.BDRip(1080p)-FfClub.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:2727ABFBB6429E73ABF27AB8C06ED95751192AB8'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=source%20code%20>
{'baidu': 'source code ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Source.Code.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:1AB7F80CA1213003BFC49EAB789E2B811D3CEDD7'}
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hischniki%20>
{'baidu': 'hischniki ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'hischniki',
 'filename': 'Hischniki.2010.x264.1080p.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:919C64056E8ACB9109B45A30312F9319BDCE5169'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=rio%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%28> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:EBAA70F406CDE3234A92479E86B731A41935989B'}
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13',
 'link': 'magnet:?xt=urn:btih:435B89E721F60F82554E192EA0ADB8ADDE29B8CF'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20flight%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18',
 'link': 'magnet:?xt=urn:btih:792ABA7D44A584A5E154A2660BDCE4DA5724E010'}
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12',
 'link': 'magnet:?xt=urn:btih:6B12F1E15239C20BE7447328DB709DCCBE0783BB'}
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=rio%20>
{'baidu': 'rio ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Rio.2011.D.BDrip.1080p-TVB-k236-UG.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:EE15DC4E226ED3BD65AFDEEC4FCA51840629211A'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20flight%20>
{'baidu': 'last flight ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Last.Flight.2014.D.WEB-DL.1080p.uniongang.tv.mkv',
 'length': '2384-12-08',
 'link': 'magnet:?xt=urn:btih:3092570032FD66B590E6BCE0BB72BD645DF4CCF4'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13',
 'link': 'magnet:?xt=urn:btih:69DBE08038FCE60A06A7BF7A330E3A0DD839BEB9'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26',
 'link': 'magnet:?xt=urn:btih:80B49F8BD5A4F245422EEE094EF57EB2DA31088C'}
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09',
 'link': 'magnet:?xt=urn:btih:A7507BA6C8FCC8BC1FA30D82876164998A88D95D'}
2018-11-26 17:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:25:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21',
 'link': 'magnet:?xt=urn:btih:277732B181DB8BB8D1FF697487DA5AC44945D516'}
2018-11-26 17:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/47edd83574f9885b75d7298b7c2737b67d3cc8da.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=apollo%20> (referer: None)
2018-11-26 17:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:25:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=apollo%20>
{'baidu': 'apollo ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Apollo.18.2011.BDRip.1080p.mkv',
 'length': '4394-04-16',
 'link': 'magnet:?xt=urn:btih:47EDD83574F9885B75D7298B7C2737B67D3CC8DA'}
2018-11-26 17:25:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24',
 'link': 'magnet:?xt=urn:btih:6DC443CA0052CFD4C3D57D17B2961ABBE01CC5BC'}
2018-11-26 17:25:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:25:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17',
 'link': 'magnet:?xt=urn:btih:35CCE9D3325631F826751C8FC9A3B775BAAB7A40'}
2018-11-26 17:25:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zhizn%20zhukov%20> (referer: None)
2018-11-26 17:25:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zhizn%20zhukov%20>
{'baidu': 'zhizn zhukov ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'zhizn',
 'filename': 'Zhizn.Zhukov.1998.x264.BDRip.(720p)_Kinozal.TV-HD.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:21A6F405633A123D474AA28761C8482E3BD75C85'}
2018-11-26 17:25:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:25:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 23654,
 'downloader/request_count': 62,
 'downloader/request_method_count/GET': 62,
 'downloader/response_bytes': 85707,
 'downloader/response_count': 62,
 'downloader/response_status_count/200': 62,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 25, 9, 595676),
 'item_scraped_count': 28,
 'log_count/DEBUG': 92,
 'log_count/INFO': 7,
 'memusage/max': 894328832,
 'memusage/startup': 894328832,
 'request_depth_max': 2,
 'response_received_count': 62,
 'scheduler/dequeued': 62,
 'scheduler/dequeued/memory': 62,
 'scheduler/enqueued': 62,
 'scheduler/enqueued/memory': 62,
 'start_time': datetime.datetime(2018, 11, 26, 9, 25, 0, 736073)}
2018-11-26 17:25:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-26 17:27:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-26 17:27:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-26 17:27:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-26 17:27:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-26 17:27:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-26 17:27:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-26 17:27:31 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-26 17:27:31 [scrapy.core.engine] INFO: Spider opened
2018-11-26 17:27:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-26 17:27:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_3.html> (referer: None)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_2.html> (referer: None)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/311d826ad5b372c1f16f5a2c1ccdc13e938ad1b1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/mkv_time_1.html> (referer: None)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/07343fd8572bc808f3a6ca140463088565d4c17b.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/296c44c0c74d6e2fc89edd85667c90cd68fb03e1.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f53180663b7320c8557408c631f1ae779a55a3fe.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/21a6f405633a123d474aa28761c8482e3bd75c85.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20v%20konce%20ulicy%20> (referer: None)
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=pod%20pokrovom%20nebes%20> (referer: None)
2018-11-26 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20v%20konce%20ulicy%20>
{'baidu': 'dom v konce ulicy ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'dom v konce ulicy',
 'filename': 'Dom.v.konce.ulicy.2012.x264.BDRip.720p.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:296C44C0C74D6E2FC89EDD85667C90CD68FB03E1'}
2018-11-26 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/919c64056e8acb9109b45a30312f9319bdce5169.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zhizn%20zhukov%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=pod%20pokrovom%20nebes%20>
{'baidu': 'pod pokrovom nebes ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'pokrovom',
 'filename': 'Pod.pokrovom.nebes.1990.BDRip.1080p.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:07343FD8572BC808F3A6CA140463088565D4C17B'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ffa0423e91eede10d00b2a6aef3de040063e7878.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/9a7e1c22defe15a25b0217570e2835a94065dc7d.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/20a1b80d1e37e733484db75dd289c8022a6c8554.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zhizn%20zhukov%20>
{'baidu': 'zhizn zhukov ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'zhizn',
 'filename': 'Zhizn.Zhukov.1998.x264.BDRip.(720p)_Kinozal.TV-HD.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:21A6F405633A123D474AA28761C8482E3BD75C85'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hischniki%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2727abfbb6429e73abf27ab8c06ed95751192ab8.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=penthouse-thekeyparty-> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3092570032fd66b590e6bce0bb72bd645df4ccf4.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1c0e64ee3bfd7b2783ddaad6310f08f2720a8ef3.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hischniki%20>
{'baidu': 'hischniki ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'hischniki',
 'filename': 'Hischniki.2010.x264.1080p.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:919C64056E8ACB9109B45A30312F9319BDCE5169'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=queen%20hungary%20rhapsody%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sbcdevonmarcojerry_> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/0ced8a022ae5d260285cea81d5d7b525c0d92e48.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=penthouse-thekeyparty->
{'baidu': 'penthouse-thekeyparty-',
 'click': '',
 'ctime': ' ',
 'fanyi': 'penthouse-thekeypart',
 'filename': 'Penthouse-TheKeyParty-2012-1080p.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:9A7E1C22DEFE15A25B0217570E2835A94065DC7D'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=stalingrad%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=solo> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/889bc388426a01dd95459516c98de4eee135a650.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=queen%20hungary%20rhapsody%20>
{'baidu': 'queen hungary rhapsody ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Queen.Hungary rhapsody.1986.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:20A1B80D1E37E733484DB75DD289C8022A6C8554'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ee15dc4e226ed3bd65afdeec4fca51840629211a.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20flight%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sbcdevonmarcojerry_>
{'baidu': 'sbcdevonmarcojerry_',
 'click': '',
 'ctime': ' ',
 'fanyi': 'sbcdevonmarcojerry_',
 'filename': 'sbcdevonmarcojerry_720.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:FFA0423E91EEDE10D00B2A6AEF3DE040063E7878'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20awkward%20sexual%20adventure%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=stalingrad%20>
{'baidu': 'stalingrad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Stalingrad.1993.x264.BDRip(1080p)-FfClub.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:2727ABFBB6429E73ABF27AB8C06ED95751192AB8'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%28> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=solo>
{'baidu': 'solo',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Solo10_Kaden Kross_1.mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:F53180663B7320C8557408C631F1AE779A55A3FE'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b5e54a6ddca5368fe3976a9469305b526c8e8fd.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/ebaa70f406cde3234a92479e86b731a41935989b.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/277732b181db8bb8d1ff697487da5ac44945d516.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20bolshoy%20mamochki%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=last%20flight%20>
{'baidu': 'last flight ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Last.Flight.2014.D.WEB-DL.1080p.uniongang.tv.mkv',
 'length': '2384-12-08',
 'link': 'magnet:?xt=urn:btih:3092570032FD66B590E6BCE0BB72BD645DF4CCF4'}
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20awkward%20sexual%20adventure%20>
{'baidu': 'my awkward sexual adventure ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'My.Awkward.Sexual.Adventure.2012.BDRip.720p.mkv',
 'length': '3918-09-15',
 'link': 'magnet:?xt=urn:btih:1C0E64EE3BFD7B2783DDAAD6310F08F2720A8EF3'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=rio%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%28>
{'baidu': '(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': '(1996)..mkv',
 'length': '2038-01-19',
 'link': 'magnet:?xt=urn:btih:0CED8A022AE5D260285CEA81D5D7B525C0D92E48'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/435b89e721f60f82554e192ea0adb8adde29b8cf.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sucker%20punch%20extended%20cut%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dom%20bolshoy%20mamochki%20>
{'baidu': 'dom bolshoy mamochki ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'dom bolshoy mamochki',
 'filename': 'Dom.bolshoy.mamochki.2000.x264.HDTVRip.1080.mkv',
 'length': '2070-01-01',
 'link': 'magnet:?xt=urn:btih:889BC388426A01DD95459516C98DE4EEE135A650'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/792aba7d44a584a5e154a2660bdce4da5724e010.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=rio%20>
{'baidu': 'rio ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Rio.2011.D.BDrip.1080p-TVB-k236-UG.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:EE15DC4E226ED3BD65AFDEEC4FCA51840629211A'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/47edd83574f9885b75d7298b7c2737b67d3cc8da.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e51876affc0ee1934ebb80495373b8856efb47f.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/35cce9d3325631f826751c8fc9a3b775baab7a40.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/69dbe08038fce60a06a7bf7a330e3a0dd839beb9.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sucker%20punch%20extended%20cut%20>
{'baidu': 'sucker punch extended cut ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Sucker.Punch.Extended.Cut.2011.Dub&L1.BDRip.1080p-TVB.k236.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:6B5E54A6DDCA5368FE3976A9469305B526C8E8FD'}
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ironclad%20>
{'baidu': 'ironclad ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Ironclad.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:EBAA70F406CDE3234A92479E86B731A41935989B'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=deadpooll%20>
{'baidu': 'deadpooll ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'deadpooll',
 'filename': 'DeaDPooLL.2o16.D.WEBRip.1080P.mkv',
 'length': '4776-02-21',
 'link': 'magnet:?xt=urn:btih:277732B181DB8BB8D1FF697487DA5AC44945D516'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/a7507ba6c8fcc8bc1fa30d82876164998a88d95d.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=apollo%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=une%20nouvelle%20amie%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6b12f1e15239c20be7447328db709dccbe0783bb.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=inside%20the%20living%20body%20>
{'baidu': 'inside the living body ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Inside.The.Living.Body.2007.HDTV.720p.L4.1.x264.AC3.5.1.mkv',
 'length': '40255-02-13',
 'link': 'magnet:?xt=urn:btih:435B89E721F60F82554E192EA0ADB8ADDE29B8CF'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/7a167f2d053ea67d1985adf7b9d31e93a9d74468.html> (referer: https://www.ciliba.biz/s/mkv_time_3.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=metropolis%20%28>
{'baidu': 'metropolis (',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': 'Metropolis (2001) (Physical Bluray NoRaw - 720p x264 ITA 5.1 JAP '
             '5.1 ENG 5.1 AC3 SUB-ITA-ENG) by scana001.mkv',
 'length': '41077-07-18',
 'link': 'magnet:?xt=urn:btih:792ABA7D44A584A5E154A2660BDCE4DA5724E010'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/80b49f8bd5a4f245422eee094ef57eb2da31088c.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=apollo%20>
{'baidu': 'apollo ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Apollo.18.2011.BDRip.1080p.mkv',
 'length': '4394-04-16',
 'link': 'magnet:?xt=urn:btih:47EDD83574F9885B75D7298B7C2737B67D3CC8DA'}
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28> (referer: None)
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=une%20nouvelle%20amie%20>
{'baidu': 'une nouvelle amie ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Une.Nouvelle.Amie.2014.D.WEB-DL.720p.uniongang.tv.mkv',
 'length': '2384-12-08',
 'link': 'magnet:?xt=urn:btih:3E51876AFFC0EE1934EBB80495373B8856EFB47F'}
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20tsien%28>
{'baidu': ' tsien(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'tsien(',
 'filename': ' Tsien(2012)..mkv',
 'length': '44322-11-17',
 'link': 'magnet:?xt=urn:btih:35CCE9D3325631F826751C8FC9A3B775BAAB7A40'}
2018-11-26 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20x%28>
{'baidu': ' x(',
 'click': '',
 'ctime': ' ',
 'fanyi': 'x(',
 'filename': ' X(1999)..mkv',
 'length': '44445-12-13',
 'link': 'magnet:?xt=urn:btih:69DBE08038FCE60A06A7BF7A330E3A0DD839BEB9'}
2018-11-26 17:27:34 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%28> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20> (referer: None)
2018-11-26 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/6dc443ca0052cfd4c3d57d17b2961abbe01cc5bc.html> (referer: https://www.ciliba.biz/s/mkv_time_1.html)
2018-11-26 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28> (referer: None)
2018-11-26 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20legend%20of%20awesomest%20maximus%28>
{'baidu': ' legend of awesomest maximus(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Legend of Awesomest Maximus(2011)301..mkv',
 'length': '44465-05-09',
 'link': 'magnet:?xt=urn:btih:A7507BA6C8FCC8BC1FA30D82876164998A88D95D'}
2018-11-26 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saint%20seiya%20lost%20canvas%20ova%20>
{'baidu': 'saint seiya lost canvas ova ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Saint Seiya Lost Canvas Ova 1 HD Sasukek.mkv',
 'length': '41464-01-12',
 'link': 'magnet:?xt=urn:btih:6B12F1E15239C20BE7447328DB709DCCBE0783BB'}
2018-11-26 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20want%20to%20sing%28>
{'baidu': ' want to sing(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' Want to Sing(1971)mkv.mkv',
 'length': '44531-02-26',
 'link': 'magnet:?xt=urn:btih:80B49F8BD5A4F245422EEE094EF57EB2DA31088C'}
2018-11-26 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28> (referer: None)
2018-11-26 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%20of%20the%20fairy%20princess%28>
{'baidu': ' of the fairy princess(',
 'click': '',
 'ctime': ' ',
 'fanyi': '(',
 'filename': ' of the Fairy Princess(1952)..mkv',
 'length': '44480-07-24',
 'link': 'magnet:?xt=urn:btih:6DC443CA0052CFD4C3D57D17B2961ABBE01CC5BC'}
2018-11-26 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/1ab7f80ca1213003bfc49eab789e2b811d3cedd7.html> (referer: https://www.ciliba.biz/s/mkv_time_2.html)
2018-11-26 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=source%20code%20> (referer: None)
2018-11-26 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=source%20code%20>
{'baidu': 'source code ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Source.Code.2011.D.BDRip.1080p.UG.k236.mkv',
 'length': '4762-07-18',
 'link': 'magnet:?xt=urn:btih:1AB7F80CA1213003BFC49EAB789E2B811D3CEDD7'}
2018-11-26 17:27:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-26 17:27:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 24662,
 'downloader/request_count': 62,
 'downloader/request_method_count/GET': 62,
 'downloader/response_bytes': 85634,
 'downloader/response_count': 62,
 'downloader/response_status_count/200': 62,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 26, 9, 27, 35, 661984),
 'item_scraped_count': 28,
 'log_count/DEBUG': 92,
 'log_count/INFO': 7,
 'memusage/max': 898539520,
 'memusage/startup': 898539520,
 'request_depth_max': 2,
 'response_received_count': 62,
 'scheduler/dequeued': 62,
 'scheduler/dequeued/memory': 62,
 'scheduler/enqueued': 62,
 'scheduler/enqueued/memory': 62,
 'start_time': datetime.datetime(2018, 11, 26, 9, 27, 31, 783949)}
2018-11-26 17:27:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 09:20:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 09:20:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 09:20:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 09:20:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 09:20:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 09:20:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 09:20:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 09:20:43 [scrapy.core.engine] INFO: Spider opened
2018-11-27 09:20:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 09:20:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 09:20:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 09:20:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 09:20:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/978CE797B3E431A223BE0AFE2084F33E51934128.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/1B6403D6E3E28B0541823144784D116523E66E7B.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:43 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/477A738D3C771C7E467323DE07D91C943B696EC6.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/C828DC0931BFD9640540B013702907939490DC3B.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.cc/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-11-27 09:22:43 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 09:22:44 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-11-27 09:22:44 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-11-27 09:23:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 09:23:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 09:23:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 09:23:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 09:23:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 09:23:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 09:23:40 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 09:23:40 [scrapy.core.engine] INFO: Spider opened
2018-11-27 09:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 09:23:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 09:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 09:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 09:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 09:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20> (referer: None)
2018-11-27 09:23:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20>
{'baidu': 'starship troopers ',
 'click': '13',
 'ctime': '2015-11-07',
 'fanyi': '',
 'filename': 'Starship.Troopers.1997.Paul.Verhoeven.BDRemux1080p.Rus.Dub.5xAVO.Eng.DTS.Comm.mkv',
 'length': '33.4 GB',
 'link': 'magnet:?xt=urn:btih:E76E85E100098A201A32BDB2F1AEC8280981B37B'}
2018-11-27 09:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:41 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20-%20invasion%20> (referer: None)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20-%20invasion%20>
{'baidu': 'starship troopers - invasion ',
 'click': '1534',
 'ctime': '2015-10-14',
 'fanyi': ',',
 'filename': 'Starship Troopers - Invasion 2012 BluRay AVC DTS-HD MA 5.1',
 'length': '34.1 GB',
 'link': 'magnet:?xt=urn:btih:96BFF6E0B46FC40B954937CC92114B4AB3007177'}
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20traitor%20of%20mars%20> (referer: None)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20traitor%20of%20mars%20>
{'baidu': 'starship troopers traitor of mars ',
 'click': '816',
 'ctime': '2018-04-06',
 'fanyi': '',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BDRemux.HEVC.HDR.IVA(RUS.ENG).ExKinoRay.mkv',
 'length': '42.2 GB',
 'link': 'magnet:?xt=urn:btih:FFC0BB406F5E403B043ED191123C074ECC80EFE5'}
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20%28> (referer: None)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E3%80%90www%20gaoqing%20tv%E3%80%91%E6%98%9F%E6%B2%B3%E6%88%98%E9%98%9F%20%E5%85%A5%E4%BE%B5%20%E8%93%9D%E5%85%89%E5%8E%9F%E7%9B%98%20%5B%E7%BE%8E%E7%89%88%20%E7%AE%80%E7%B9%81%E4%B8%AD%E6%96%87%E5%AD%97%E5%B9%95%5D%20starship%20troopers%20invasion%20> (referer: None)
2018-11-27 09:23:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20%28>
{'baidu': 'starship troopers (',
 'click': '143',
 'ctime': '2018-02-13',
 'fanyi': '(',
 'filename': 'Starship Troopers (1997) BDRemux 1080p [UK Transfer]',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:1B6403D6E3E28B0541823144784D116523E66E7B'}
2018-11-27 09:23:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E3%80%90www%20gaoqing%20tv%E3%80%91%E6%98%9F%E6%B2%B3%E6%88%98%E9%98%9F%20%E5%85%A5%E4%BE%B5%20%E8%93%9D%E5%85%89%E5%8E%9F%E7%9B%98%20%5B%E7%BE%8E%E7%89%88%20%E7%AE%80%E7%B9%81%E4%B8%AD%E6%96%87%E5%AD%97%E5%B9%95%5D%20starship%20troopers%20invasion%20>
{'baidu': 'www gaoqing tv   [ ] starship troopers '
          'invasion ',
 'click': '1567',
 'ctime': '2015-10-13',
 'fanyi': 'Starship troopers in',
 'filename': 'www.gaoqing.tv   [ ] '
             'Starship.Troopers.Invasion.2012.BluRay.AVC.DTS-HD.MA5.1-CHDBits',
 'length': '36.7 GB',
 'link': 'magnet:?xt=urn:btih:D4362A0294444BF17AB6C0AE3A68615B8666F7FF'}
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20%5B> (referer: None)
2018-11-27 09:23:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20%5B>
{'baidu': 'starship troopers [',
 'click': '1555',
 'ctime': '2018-02-12',
 'fanyi': '(',
 'filename': 'Starship Troopers [4K Remux][2160p][HDR][AC3 5.1-DTS '
             '5.1Castellano DTS-MA 7.1-Ingles+Subs][ES-EN]',
 'length': '52.6 GB',
 'link': 'magnet:?xt=urn:btih:85372B1AFC033D4B1DBF0B656C7D09AEBE08D115'}
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20traitors%20mars%20> (referer: None)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E6%98%9F%E6%B2%B3%E6%88%98%E9%98%9F%EF%BC%9A%E7%81%AB%E6%98%9F%E5%8F%9B%E5%9B%BD%E8%80%85%20starship%20troopers%20traitors%20mars%20> (referer: None)
2018-11-27 09:23:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20traitors%20mars%20>
{'baidu': 'starship troopers traitors mars ',
 'click': '905',
 'ctime': '2017-09-21',
 'fanyi': '',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-27 09:23:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E6%98%9F%E6%B2%B3%E6%88%98%E9%98%9F%EF%BC%9A%E7%81%AB%E6%98%9F%E5%8F%9B%E5%9B%BD%E8%80%85%20starship%20troopers%20traitors%20mars%20>
{'baidu': ' starship troopers traitors mars ',
 'click': '477',
 'ctime': '2017-12-15',
 'fanyi': 'Starship troopers: M',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20boxset%20> (referer: None)
2018-11-27 09:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20-%20invasion%20%28> (referer: None)
2018-11-27 09:23:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20boxset%20>
{'baidu': 'starship troopers boxset ',
 'click': '3',
 'ctime': '2017-09-20',
 'fanyi': 'boxset',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 09:23:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=starship%20troopers%20-%20invasion%20%28>
{'baidu': 'starship troopers - invasion (',
 'click': '170',
 'ctime': '2017-03-30',
 'fanyi': 'troopers -(starshi',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 09:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:23:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 09:23:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 22660,
 'downloader/request_count': 59,
 'downloader/request_method_count/GET': 59,
 'downloader/response_bytes': 209425,
 'downloader/response_count': 59,
 'downloader/response_status_count/200': 59,
 'dupefilter/filtered': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 1, 23, 45, 665932),
 'item_scraped_count': 10,
 'log_count/DEBUG': 71,
 'log_count/INFO': 7,
 'memusage/max': 641163264,
 'memusage/startup': 641163264,
 'request_depth_max': 2,
 'response_received_count': 59,
 'scheduler/dequeued': 59,
 'scheduler/dequeued/memory': 59,
 'scheduler/enqueued': 59,
 'scheduler/enqueued/memory': 59,
 'start_time': datetime.datetime(2018, 11, 27, 1, 23, 40, 290001)}
2018-11-27 09:23:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 09:57:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 09:57:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 09:57:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 09:57:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 09:57:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 09:57:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 09:57:46 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 09:57:46 [scrapy.core.engine] INFO: Spider opened
2018-11-27 09:57:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 09:57:46 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:57:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 09:57:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 205533,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 1, 57, 49, 752985),
 'log_count/DEBUG': 49,
 'log_count/INFO': 7,
 'memusage/max': 678604800,
 'memusage/startup': 678604800,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 1, 57, 46, 338202)}
2018-11-27 09:57:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 09:59:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 09:59:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 09:59:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 09:59:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 09:59:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 09:59:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 09:59:25 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 09:59:25 [scrapy.core.engine] INFO: Spider opened
2018-11-27 09:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 09:59:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 09:59:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 09:59:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 09:59:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 09:59:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 09:59:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 09:59:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 205538,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 1, 59, 32, 17237),
 'log_count/DEBUG': 49,
 'log_count/INFO': 7,
 'memusage/max': 691785728,
 'memusage/startup': 691785728,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 1, 59, 25, 514720)}
2018-11-27 09:59:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:00:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:00:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:00:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:00:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:00:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:00:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:00:35 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:00:35 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:00:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:00:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 10:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 10:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:00:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:00:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 205536,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 0, 40, 511126),
 'log_count/DEBUG': 49,
 'log_count/INFO': 7,
 'memusage/max': 697692160,
 'memusage/startup': 697692160,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 0, 35, 580287)}
2018-11-27 10:00:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:11:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:11:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:11:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:11:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:11:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:11:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:11:39 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:11:39 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:11:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:11:39 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 10:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html>
{'click': '448',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.UHD.BluRay.2160p.TrueHD.Atmos.7.1.HEVC.REMUX-FraMeSToR',
 'length': '42.4 GB',
 'link': 'magnet:?xt=urn:btih:2602822DA5C550F41331A83DFADA59E85C3DD0D3'}
2018-11-27 10:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html>
{'click': '13',
 'ctime': '2015-11-07',
 'filename': 'Starship.Troopers.1997.Paul.Verhoeven.BDRemux1080p.Rus.Dub.5xAVO.Eng.DTS.Comm.mkv',
 'length': '33.4 GB',
 'link': 'magnet:?xt=urn:btih:E76E85E100098A201A32BDB2F1AEC8280981B37B'}
2018-11-27 10:11:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html>
{'click': '1567',
 'ctime': '2015-10-13',
 'filename': 'www.gaoqing.tv   [ ] '
             'Starship.Troopers.Invasion.2012.BluRay.AVC.DTS-HD.MA5.1-CHDBits',
 'length': '36.7 GB',
 'link': 'magnet:?xt=urn:btih:D4362A0294444BF17AB6C0AE3A68615B8666F7FF'}
2018-11-27 10:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html>
{'click': '143',
 'ctime': '2018-02-13',
 'filename': 'Starship Troopers (1997) BDRemux 1080p [UK Transfer]',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:1B6403D6E3E28B0541823144784D116523E66E7B'}
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html>
{'click': '2610',
 'ctime': '2015-10-30',
 'filename': 'starship_troopers',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:3CC518A100383B0120F6E1974F7D26C2B5BF796C'}
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html>
{'click': '641',
 'ctime': '2018-04-12',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BDRemux.Dolby.Vision.IVA(ENG.RUS).ExKinoRay',
 'length': '44.4 GB',
 'link': 'magnet:?xt=urn:btih:9EB345E75F2B5E227B806A6E2D17713A72FE3A48'}
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html>
{'click': '41',
 'ctime': '2016-03-20',
 'filename': 'Starship Troopers',
 'length': '39.8 GB',
 'link': 'magnet:?xt=urn:btih:477A738D3C771C7E467323DE07D91C943B696EC6'}
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html>
{'click': '1200',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.1997.1080p.AVC.TrueHD.5.1-Shadowman',
 'length': '41.6 GB',
 'link': 'magnet:?xt=urn:btih:11BE55E3F0624EBEA689A8ED704EB53E7B01B219'}
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html>
{'click': '19',
 'ctime': '2018-09-23',
 'filename': 'Starship Troopers',
 'length': '34.0 GB',
 'link': 'magnet:?xt=urn:btih:C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4'}
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html>
{'click': '1534',
 'ctime': '2015-10-14',
 'filename': 'Starship Troopers - Invasion 2012 BluRay AVC DTS-HD MA 5.1',
 'length': '34.1 GB',
 'link': 'magnet:?xt=urn:btih:96BFF6E0B46FC40B954937CC92114B4AB3007177'}
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html>
{'click': '1806',
 'ctime': '2015-10-11',
 'filename': 'Starship Troopers 3 Marauder 2008 1080p Blu-Ray CEE AVC TrueHD - '
             'EiMi',
 'length': '39.0 GB',
 'link': 'magnet:?xt=urn:btih:DA378F3492E2F8036DCD15DB7C028BE5A0939D0D'}
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html>
{'click': '816',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BDRemux.HEVC.HDR.IVA(RUS.ENG).ExKinoRay.mkv',
 'length': '42.2 GB',
 'link': 'magnet:?xt=urn:btih:FFC0BB406F5E403B043ED191123C074ECC80EFE5'}
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html>
{'click': '851',
 'ctime': '2017-06-20',
 'filename': 'Starship.Troopers.3.Marauder.BD-Remux',
 'length': '28.3 GB',
 'link': 'magnet:?xt=urn:btih:9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3'}
2018-11-27 10:11:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html>
{'click': '891',
 'ctime': '2015-10-10',
 'filename': 'starship_troopers_[tfile.ru]',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00'}
2018-11-27 10:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html>
{'click': '4563',
 'ctime': '2015-10-13',
 'filename': 'STARSHIP_TROOPERS_BD_BLUEBIRD',
 'length': '44.5 GB',
 'link': 'magnet:?xt=urn:btih:D85F8FCC22DAF9B355725C54AD570C34B2803D23'}
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html>
{'click': '170',
 'ctime': '2017-03-30',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html>
{'click': '905',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html>
{'click': '88',
 'ctime': '2017-10-07',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:2F218C1A4219EB9E655AD5170CD35D53A00FF991'}
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html>
{'click': '1520',
 'ctime': '2015-10-22',
 'filename': 'Starship Troopers (1997)',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FEE4A83EA42137C0945CE51BB9E65D137914BE87'}
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html>
{'click': '60',
 'ctime': '2016-01-13',
 'filename': 'Starship.Troopers.1997.BDRX.VC1.LaDIFF.mkv',
 'length': '29.6 GB',
 'link': 'magnet:?xt=urn:btih:BF7E83E32C5360BDD2045F1C948D732850BE72C4'}
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html>
{'click': '125',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:978CE797B3E431A223BE0AFE2084F33E51934128'}
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html>
{'click': '41',
 'ctime': '2018-07-17',
 'filename': '07.08.13.Starship.Troopers.Blu-ray.Remux.VC1.1080P.DTS.LPCM.DD51.O_Silu',
 'length': '30.7 GB',
 'link': 'magnet:?xt=urn:btih:F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55'}
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html>
{'click': '477',
 'ctime': '2017-12-15',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html>
{'click': '1053',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FE87306308BD5E29109EAB07F51748E72ED1B0A9'}
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html>
{'click': '228',
 'ctime': '2016-01-16',
 'filename': 'www.gaoqing.tv [.DIY]St',
 'length': '42.3 GB',
 'link': 'magnet:?xt=urn:btih:6993173C47BA2ACE631A72EBD8C29FF5394C02F3'}
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html>
{'click': '117',
 'ctime': '2017-09-29',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60'}
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html>
{'click': '3',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html>
{'click': '9',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E'}
2018-11-27 10:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html>
{'click': '224',
 'ctime': '2017-09-22',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.BLURAY.EUR',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1A08B510FDCD39348661569020F3BC6A3B6A9282'}
2018-11-27 10:11:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:11:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html>
{'click': '1624',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:78201DE6A506D758CD51A2FC3CC2159257DCE893'}
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html>
{'click': '465',
 'ctime': '2018-03-03',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '50.5 GB',
 'link': 'magnet:?xt=urn:btih:C828DC0931BFD9640540B013702907939490DC3B'}
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html>
{'click': '5950',
 'ctime': '2015-10-21',
 'filename': 'Starship.Troopers.1997.1080p.BluRay.VC-1.LPCM.5.1-FGT',
 'length': '44.5 GB',
 'link': 'magnet:?xt=urn:btih:EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31'}
2018-11-27 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html>
{'click': '733',
 'ctime': '2018-02-15',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '46.5 GB',
 'link': 'magnet:?xt=urn:btih:17F2AC4E0468C5B5C5CE4143C9EE304472394D35'}
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html>
{'click': '359',
 'ctime': '2018-02-12',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ.mkv',
 'length': '46.7 GB',
 'link': 'magnet:?xt=urn:btih:BDD17A76F079DEE7997D5BCF43BAEEE2BA890281'}
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html>
{'click': '1270',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:C9535074BED8CA1F2F18BDEA2308659D95B4B46B'}
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html>
{'click': '4',
 'ctime': '2018-08-23',
 'filename': 'Starship.Troopers.1997.UHD.BluRay.2160p.TrueHD.Atmos.7.1.HEVC.REMUX-FraMeSToR',
 'length': '51.7 GB',
 'link': 'magnet:?xt=urn:btih:B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3'}
2018-11-27 10:11:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html>
{'click': '1555',
 'ctime': '2018-02-12',
 'filename': 'Starship Troopers [4K Remux][2160p][HDR][AC3 5.1-DTS '
             '5.1Castellano DTS-MA 7.1-Ingles+Subs][ES-EN]',
 'length': '52.6 GB',
 'link': 'magnet:?xt=urn:btih:85372B1AFC033D4B1DBF0B656C7D09AEBE08D115'}
2018-11-27 10:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html>
{'click': '930',
 'ctime': '2018-02-23',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-COASTER',
 'length': '58.5 GB',
 'link': 'magnet:?xt=urn:btih:E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1'}
2018-11-27 10:11:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html>
{'click': '879',
 'ctime': '2018-02-18',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT.mkv',
 'length': '65.8 GB',
 'link': 'magnet:?xt=urn:btih:8D64C42B25BA03E26E09ADADD38843D719AB0A27'}
2018-11-27 10:11:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html>
{'click': '58',
 'ctime': '2018-04-15',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.COMPLETE.UHD.BLURAY-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:95EF0B3B128A641B9B65F10A94EA422D0B5A8B00'}
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html>
{'click': '541',
 'ctime': '2018-04-08',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '49.3 GB',
 'link': 'magnet:?xt=urn:btih:85B024A0444D8CEC7BFF8C9E952394375F38E761'}
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html>
{'click': '1190',
 'ctime': '2018-01-27',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '58.6 GB',
 'link': 'magnet:?xt=urn:btih:07304EB28206276F1ED5D4D5D87E2F2ADCA87341'}
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html>
{'click': '70',
 'ctime': '2018-09-19',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:B7A3A3891774E1F4D89E0A8AB64971872979E796'}
2018-11-27 10:11:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html>
{'click': '4',
 'ctime': '2018-09-09',
 'filename': 'Starship.Troopers.1997.COMPLETE.UHD.BLURAY-COASTER',
 'length': '58.5 GB',
 'link': 'magnet:?xt=urn:btih:1109F2DCBA6BCFB13056F2A818E8401AEDE95730'}
2018-11-27 10:11:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:11:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html>
{'click': '1391',
 'ctime': '2018-04-06',
 'filename': 'Starship Troopers Traitor of Mars',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:2A49CB08DD6316BB36C21851DEF05C3AB39E86F6'}
2018-11-27 10:11:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:11:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 205545,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 11, 46, 796307),
 'item_scraped_count': 45,
 'log_count/DEBUG': 94,
 'log_count/INFO': 7,
 'memusage/max': 719802368,
 'memusage/startup': 719802368,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 11, 39, 903260)}
2018-11-27 10:11:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:14:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:14:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:14:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:14:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:14:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:14:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:14:09 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:14:09 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:14:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:14:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:14:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:14:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 10:14:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html>
{'click': '1053',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FE87306308BD5E29109EAB07F51748E72ED1B0A9'}
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html>
{'click': '1520',
 'ctime': '2015-10-22',
 'filename': 'Starship Troopers (1997)',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FEE4A83EA42137C0945CE51BB9E65D137914BE87'}
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html>
{'click': '41',
 'ctime': '2018-07-17',
 'filename': '07.08.13.Starship.Troopers.Blu-ray.Remux.VC1.1080P.DTS.LPCM.DD51.O_Silu',
 'length': '30.7 GB',
 'link': 'magnet:?xt=urn:btih:F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55'}
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html>
{'click': '851',
 'ctime': '2017-06-20',
 'filename': 'Starship.Troopers.3.Marauder.BD-Remux',
 'length': '28.3 GB',
 'link': 'magnet:?xt=urn:btih:9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3'}
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html>
{'click': '224',
 'ctime': '2017-09-22',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.BLURAY.EUR',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1A08B510FDCD39348661569020F3BC6A3B6A9282'}
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html>
{'click': '60',
 'ctime': '2016-01-13',
 'filename': 'Starship.Troopers.1997.BDRX.VC1.LaDIFF.mkv',
 'length': '29.6 GB',
 'link': 'magnet:?xt=urn:btih:BF7E83E32C5360BDD2045F1C948D732850BE72C4'}
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html>
{'click': '117',
 'ctime': '2017-09-29',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60'}
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html>
{'click': '3',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html>
{'click': '1624',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:78201DE6A506D758CD51A2FC3CC2159257DCE893'}
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html>
{'click': '9',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E'}
2018-11-27 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html>
{'click': '170',
 'ctime': '2017-03-30',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html>
{'click': '19',
 'ctime': '2018-09-23',
 'filename': 'Starship Troopers',
 'length': '34.0 GB',
 'link': 'magnet:?xt=urn:btih:C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4'}
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html>
{'click': '88',
 'ctime': '2017-10-07',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:2F218C1A4219EB9E655AD5170CD35D53A00FF991'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html>
{'click': '143',
 'ctime': '2018-02-13',
 'filename': 'Starship Troopers (1997) BDRemux 1080p [UK Transfer]',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:1B6403D6E3E28B0541823144784D116523E66E7B'}
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html>
{'click': '1534',
 'ctime': '2015-10-14',
 'filename': 'Starship Troopers - Invasion 2012 BluRay AVC DTS-HD MA 5.1',
 'length': '34.1 GB',
 'link': 'magnet:?xt=urn:btih:96BFF6E0B46FC40B954937CC92114B4AB3007177'}
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html>
{'click': '5950',
 'ctime': '2015-10-21',
 'filename': 'Starship.Troopers.1997.1080p.BluRay.VC-1.LPCM.5.1-FGT',
 'length': '44.5 GB',
 'link': 'magnet:?xt=urn:btih:EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html>
{'click': '891',
 'ctime': '2015-10-10',
 'filename': 'starship_troopers_[tfile.ru]',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00'}
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html>
{'click': '2610',
 'ctime': '2015-10-30',
 'filename': 'starship_troopers',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:3CC518A100383B0120F6E1974F7D26C2B5BF796C'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html>
{'click': '125',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:978CE797B3E431A223BE0AFE2084F33E51934128'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html>
{'click': '13',
 'ctime': '2015-11-07',
 'filename': 'Starship.Troopers.1997.Paul.Verhoeven.BDRemux1080p.Rus.Dub.5xAVO.Eng.DTS.Comm.mkv',
 'length': '33.4 GB',
 'link': 'magnet:?xt=urn:btih:E76E85E100098A201A32BDB2F1AEC8280981B37B'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html>
{'click': '1567',
 'ctime': '2015-10-13',
 'filename': 'www.gaoqing.tv   [ ] '
             'Starship.Troopers.Invasion.2012.BluRay.AVC.DTS-HD.MA5.1-CHDBits',
 'length': '36.7 GB',
 'link': 'magnet:?xt=urn:btih:D4362A0294444BF17AB6C0AE3A68615B8666F7FF'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html>
{'click': '477',
 'ctime': '2017-12-15',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html>
{'click': '448',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.UHD.BluRay.2160p.TrueHD.Atmos.7.1.HEVC.REMUX-FraMeSToR',
 'length': '42.4 GB',
 'link': 'magnet:?xt=urn:btih:2602822DA5C550F41331A83DFADA59E85C3DD0D3'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html>
{'click': '41',
 'ctime': '2016-03-20',
 'filename': 'Starship Troopers',
 'length': '39.8 GB',
 'link': 'magnet:?xt=urn:btih:477A738D3C771C7E467323DE07D91C943B696EC6'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html>
{'click': '228',
 'ctime': '2016-01-16',
 'filename': 'www.gaoqing.tv [.DIY]St',
 'length': '42.3 GB',
 'link': 'magnet:?xt=urn:btih:6993173C47BA2ACE631A72EBD8C29FF5394C02F3'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html>
{'click': '641',
 'ctime': '2018-04-12',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BDRemux.Dolby.Vision.IVA(ENG.RUS).ExKinoRay',
 'length': '44.4 GB',
 'link': 'magnet:?xt=urn:btih:9EB345E75F2B5E227B806A6E2D17713A72FE3A48'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html>
{'click': '905',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html>
{'click': '4563',
 'ctime': '2015-10-13',
 'filename': 'STARSHIP_TROOPERS_BD_BLUEBIRD',
 'length': '44.5 GB',
 'link': 'magnet:?xt=urn:btih:D85F8FCC22DAF9B355725C54AD570C34B2803D23'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html>
{'click': '1806',
 'ctime': '2015-10-11',
 'filename': 'Starship Troopers 3 Marauder 2008 1080p Blu-Ray CEE AVC TrueHD - '
             'EiMi',
 'length': '39.0 GB',
 'link': 'magnet:?xt=urn:btih:DA378F3492E2F8036DCD15DB7C028BE5A0939D0D'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html>
{'click': '359',
 'ctime': '2018-02-12',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ.mkv',
 'length': '46.7 GB',
 'link': 'magnet:?xt=urn:btih:BDD17A76F079DEE7997D5BCF43BAEEE2BA890281'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html>
{'click': '541',
 'ctime': '2018-04-08',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '49.3 GB',
 'link': 'magnet:?xt=urn:btih:85B024A0444D8CEC7BFF8C9E952394375F38E761'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html>
{'click': '733',
 'ctime': '2018-02-15',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '46.5 GB',
 'link': 'magnet:?xt=urn:btih:17F2AC4E0468C5B5C5CE4143C9EE304472394D35'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html>
{'click': '465',
 'ctime': '2018-03-03',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '50.5 GB',
 'link': 'magnet:?xt=urn:btih:C828DC0931BFD9640540B013702907939490DC3B'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html>
{'click': '1200',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.1997.1080p.AVC.TrueHD.5.1-Shadowman',
 'length': '41.6 GB',
 'link': 'magnet:?xt=urn:btih:11BE55E3F0624EBEA689A8ED704EB53E7B01B219'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html>
{'click': '1555',
 'ctime': '2018-02-12',
 'filename': 'Starship Troopers [4K Remux][2160p][HDR][AC3 5.1-DTS '
             '5.1Castellano DTS-MA 7.1-Ingles+Subs][ES-EN]',
 'length': '52.6 GB',
 'link': 'magnet:?xt=urn:btih:85372B1AFC033D4B1DBF0B656C7D09AEBE08D115'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html>
{'click': '58',
 'ctime': '2018-04-15',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.COMPLETE.UHD.BLURAY-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:95EF0B3B128A641B9B65F10A94EA422D0B5A8B00'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html>
{'click': '1391',
 'ctime': '2018-04-06',
 'filename': 'Starship Troopers Traitor of Mars',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:2A49CB08DD6316BB36C21851DEF05C3AB39E86F6'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html>
{'click': '70',
 'ctime': '2018-09-19',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:B7A3A3891774E1F4D89E0A8AB64971872979E796'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html>
{'click': '879',
 'ctime': '2018-02-18',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT.mkv',
 'length': '65.8 GB',
 'link': 'magnet:?xt=urn:btih:8D64C42B25BA03E26E09ADADD38843D719AB0A27'}
2018-11-27 10:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html>
{'click': '1190',
 'ctime': '2018-01-27',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '58.6 GB',
 'link': 'magnet:?xt=urn:btih:07304EB28206276F1ED5D4D5D87E2F2ADCA87341'}
2018-11-27 10:14:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html>
{'click': '4',
 'ctime': '2018-08-23',
 'filename': 'Starship.Troopers.1997.UHD.BluRay.2160p.TrueHD.Atmos.7.1.HEVC.REMUX-FraMeSToR',
 'length': '51.7 GB',
 'link': 'magnet:?xt=urn:btih:B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3'}
2018-11-27 10:14:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:14:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html>
{'click': '930',
 'ctime': '2018-02-23',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-COASTER',
 'length': '58.5 GB',
 'link': 'magnet:?xt=urn:btih:E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1'}
2018-11-27 10:14:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html>
{'click': '816',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BDRemux.HEVC.HDR.IVA(RUS.ENG).ExKinoRay.mkv',
 'length': '42.2 GB',
 'link': 'magnet:?xt=urn:btih:FFC0BB406F5E403B043ED191123C074ECC80EFE5'}
2018-11-27 10:14:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html>
{'click': '4',
 'ctime': '2018-09-09',
 'filename': 'Starship.Troopers.1997.COMPLETE.UHD.BLURAY-COASTER',
 'length': '58.5 GB',
 'link': 'magnet:?xt=urn:btih:1109F2DCBA6BCFB13056F2A818E8401AEDE95730'}
2018-11-27 10:14:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:14:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html>
{'click': '1270',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:C9535074BED8CA1F2F18BDEA2308659D95B4B46B'}
2018-11-27 10:14:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:14:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 205541,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 14, 15, 159138),
 'item_scraped_count': 45,
 'log_count/DEBUG': 94,
 'log_count/INFO': 7,
 'memusage/max': 738402304,
 'memusage/startup': 738402304,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 14, 9, 527270)}
2018-11-27 10:14:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:16:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:16:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:16:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:16:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:16:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:16:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:16:41 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:16:41 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:16:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:16:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_2.html> (referer: None)
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html>
{'click': '477',
 'ctime': '2017-12-15',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html>
{'click': '60',
 'ctime': '2016-01-13',
 'filename': 'Starship.Troopers.1997.BDRX.VC1.LaDIFF.mkv',
 'length': '29.6 GB',
 'link': 'magnet:?xt=urn:btih:BF7E83E32C5360BDD2045F1C948D732850BE72C4'}
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_1.html> (referer: None)
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html>
{'click': '851',
 'ctime': '2017-06-20',
 'filename': 'Starship.Troopers.3.Marauder.BD-Remux',
 'length': '28.3 GB',
 'link': 'magnet:?xt=urn:btih:9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3'}
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html>
{'click': '224',
 'ctime': '2017-09-22',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.BLURAY.EUR',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1A08B510FDCD39348661569020F3BC6A3B6A9282'}
2018-11-27 10:16:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html>
{'click': '1520',
 'ctime': '2015-10-22',
 'filename': 'Starship Troopers (1997)',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FEE4A83EA42137C0945CE51BB9E65D137914BE87'}
2018-11-27 10:16:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html>
{'click': '117',
 'ctime': '2017-09-29',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60'}
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html>
{'click': '3',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html>
{'click': '1624',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:78201DE6A506D758CD51A2FC3CC2159257DCE893'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html>
{'click': '905',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html>
{'click': '41',
 'ctime': '2018-07-17',
 'filename': '07.08.13.Starship.Troopers.Blu-ray.Remux.VC1.1080P.DTS.LPCM.DD51.O_Silu',
 'length': '30.7 GB',
 'link': 'magnet:?xt=urn:btih:F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html>
{'click': '170',
 'ctime': '2017-03-30',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/E76E85E100098A201A32BDB2F1AEC8280981B37B.html>
{'click': '13',
 'ctime': '2015-11-07',
 'filename': 'Starship.Troopers.1997.Paul.Verhoeven.BDRemux1080p.Rus.Dub.5xAVO.Eng.DTS.Comm.mkv',
 'length': '33.4 GB',
 'link': 'magnet:?xt=urn:btih:E76E85E100098A201A32BDB2F1AEC8280981B37B'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/96BFF6E0B46FC40B954937CC92114B4AB3007177.html>
{'click': '1534',
 'ctime': '2015-10-14',
 'filename': 'Starship Troopers - Invasion 2012 BluRay AVC DTS-HD MA 5.1',
 'length': '34.1 GB',
 'link': 'magnet:?xt=urn:btih:96BFF6E0B46FC40B954937CC92114B4AB3007177'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html>
{'click': '9',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/17F2AC4E0468C5B5C5CE4143C9EE304472394D35.html>
{'click': '733',
 'ctime': '2018-02-15',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '46.5 GB',
 'link': 'magnet:?xt=urn:btih:17F2AC4E0468C5B5C5CE4143C9EE304472394D35'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/D4362A0294444BF17AB6C0AE3A68615B8666F7FF.html>
{'click': '1567',
 'ctime': '2015-10-13',
 'filename': 'www.gaoqing.tv   [ ] '
             'Starship.Troopers.Invasion.2012.BluRay.AVC.DTS-HD.MA5.1-CHDBits',
 'length': '36.7 GB',
 'link': 'magnet:?xt=urn:btih:D4362A0294444BF17AB6C0AE3A68615B8666F7FF'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html>
{'click': '1053',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FE87306308BD5E29109EAB07F51748E72ED1B0A9'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31.html>
{'click': '5950',
 'ctime': '2015-10-21',
 'filename': 'Starship.Troopers.1997.1080p.BluRay.VC-1.LPCM.5.1-FGT',
 'length': '44.5 GB',
 'link': 'magnet:?xt=urn:btih:EEB7A3EE39F5997E6E03CCBAA58317E652FFFF31'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BDD17A76F079DEE7997D5BCF43BAEEE2BA890281.html>
{'click': '359',
 'ctime': '2018-02-12',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ.mkv',
 'length': '46.7 GB',
 'link': 'magnet:?xt=urn:btih:BDD17A76F079DEE7997D5BCF43BAEEE2BA890281'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4.html>
{'click': '19',
 'ctime': '2018-09-23',
 'filename': 'Starship Troopers',
 'length': '34.0 GB',
 'link': 'magnet:?xt=urn:btih:C585835C4F87E45EA48F18E6D8A0B3CCE0DE65D4'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C828DC0931BFD9640540B013702907939490DC3B.html>
{'click': '465',
 'ctime': '2018-03-03',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '50.5 GB',
 'link': 'magnet:?xt=urn:btih:C828DC0931BFD9640540B013702907939490DC3B'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/95EF0B3B128A641B9B65F10A94EA422D0B5A8B00.html>
{'click': '58',
 'ctime': '2018-04-15',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.COMPLETE.UHD.BLURAY-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:95EF0B3B128A641B9B65F10A94EA422D0B5A8B00'}
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3.html>
{'click': '4',
 'ctime': '2018-08-23',
 'filename': 'Starship.Troopers.1997.UHD.BluRay.2160p.TrueHD.Atmos.7.1.HEVC.REMUX-FraMeSToR',
 'length': '51.7 GB',
 'link': 'magnet:?xt=urn:btih:B2AC9B0C3251C5E718A71791CE667DE5ADFB4BE3'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2A49CB08DD6316BB36C21851DEF05C3AB39E86F6.html>
{'click': '1391',
 'ctime': '2018-04-06',
 'filename': 'Starship Troopers Traitor of Mars',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:2A49CB08DD6316BB36C21851DEF05C3AB39E86F6'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C9535074BED8CA1F2F18BDEA2308659D95B4B46B.html>
{'click': '1270',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:C9535074BED8CA1F2F18BDEA2308659D95B4B46B'}
2018-11-27 10:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/85B024A0444D8CEC7BFF8C9E952394375F38E761.html>
{'click': '541',
 'ctime': '2018-04-08',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '49.3 GB',
 'link': 'magnet:?xt=urn:btih:85B024A0444D8CEC7BFF8C9E952394375F38E761'}
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1.html>
{'click': '930',
 'ctime': '2018-02-23',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-COASTER',
 'length': '58.5 GB',
 'link': 'magnet:?xt=urn:btih:E46AE84C56ABB9A2EC394E9087ECAE57D1A3C6A1'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/8D64C42B25BA03E26E09ADADD38843D719AB0A27.html>
{'click': '879',
 'ctime': '2018-02-18',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT.mkv',
 'length': '65.8 GB',
 'link': 'magnet:?xt=urn:btih:8D64C42B25BA03E26E09ADADD38843D719AB0A27'}
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html>
{'click': '88',
 'ctime': '2017-10-07',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:2F218C1A4219EB9E655AD5170CD35D53A00FF991'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1B6403D6E3E28B0541823144784D116523E66E7B.html>
{'click': '143',
 'ctime': '2018-02-13',
 'filename': 'Starship Troopers (1997) BDRemux 1080p [UK Transfer]',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:1B6403D6E3E28B0541823144784D116523E66E7B'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/3CC518A100383B0120F6E1974F7D26C2B5BF796C.html>
{'click': '2610',
 'ctime': '2015-10-30',
 'filename': 'starship_troopers',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:3CC518A100383B0120F6E1974F7D26C2B5BF796C'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/07304EB28206276F1ED5D4D5D87E2F2ADCA87341.html>
{'click': '1190',
 'ctime': '2018-01-27',
 'filename': 'Starship.Troopers.1997.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '58.6 GB',
 'link': 'magnet:?xt=urn:btih:07304EB28206276F1ED5D4D5D87E2F2ADCA87341'}
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/DA378F3492E2F8036DCD15DB7C028BE5A0939D0D.html>
{'click': '1806',
 'ctime': '2015-10-11',
 'filename': 'Starship Troopers 3 Marauder 2008 1080p Blu-Ray CEE AVC TrueHD - '
             'EiMi',
 'length': '39.0 GB',
 'link': 'magnet:?xt=urn:btih:DA378F3492E2F8036DCD15DB7C028BE5A0939D0D'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/85372B1AFC033D4B1DBF0B656C7D09AEBE08D115.html>
{'click': '1555',
 'ctime': '2018-02-12',
 'filename': 'Starship Troopers [4K Remux][2160p][HDR][AC3 5.1-DTS '
             '5.1Castellano DTS-MA 7.1-Ingles+Subs][ES-EN]',
 'length': '52.6 GB',
 'link': 'magnet:?xt=urn:btih:85372B1AFC033D4B1DBF0B656C7D09AEBE08D115'}
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_1.html)
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B7A3A3891774E1F4D89E0A8AB64971872979E796.html>
{'click': '70',
 'ctime': '2018-09-19',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-UHD',
 'length': '50.8 GB',
 'link': 'magnet:?xt=urn:btih:B7A3A3891774E1F4D89E0A8AB64971872979E796'}
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FFC0BB406F5E403B043ED191123C074ECC80EFE5.html>
{'click': '816',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BDRemux.HEVC.HDR.IVA(RUS.ENG).ExKinoRay.mkv',
 'length': '42.2 GB',
 'link': 'magnet:?xt=urn:btih:FFC0BB406F5E403B043ED191123C074ECC80EFE5'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html>
{'click': '125',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:978CE797B3E431A223BE0AFE2084F33E51934128'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1109F2DCBA6BCFB13056F2A818E8401AEDE95730.html>
{'click': '4',
 'ctime': '2018-09-09',
 'filename': 'Starship.Troopers.1997.COMPLETE.UHD.BLURAY-COASTER',
 'length': '58.5 GB',
 'link': 'magnet:?xt=urn:btih:1109F2DCBA6BCFB13056F2A818E8401AEDE95730'}
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2602822DA5C550F41331A83DFADA59E85C3DD0D3.html>
{'click': '448',
 'ctime': '2018-04-06',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.UHD.BluRay.2160p.TrueHD.Atmos.7.1.HEVC.REMUX-FraMeSToR',
 'length': '42.4 GB',
 'link': 'magnet:?xt=urn:btih:2602822DA5C550F41331A83DFADA59E85C3DD0D3'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9EB345E75F2B5E227B806A6E2D17713A72FE3A48.html>
{'click': '641',
 'ctime': '2018-04-12',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BDRemux.Dolby.Vision.IVA(ENG.RUS).ExKinoRay',
 'length': '44.4 GB',
 'link': 'magnet:?xt=urn:btih:9EB345E75F2B5E227B806A6E2D17713A72FE3A48'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/11BE55E3F0624EBEA689A8ED704EB53E7B01B219.html>
{'click': '1200',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.1997.1080p.AVC.TrueHD.5.1-Shadowman',
 'length': '41.6 GB',
 'link': 'magnet:?xt=urn:btih:11BE55E3F0624EBEA689A8ED704EB53E7B01B219'}
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/6993173C47BA2ACE631A72EBD8C29FF5394C02F3.html>
{'click': '228',
 'ctime': '2016-01-16',
 'filename': 'www.gaoqing.tv [.DIY]St',
 'length': '42.3 GB',
 'link': 'magnet:?xt=urn:btih:6993173C47BA2ACE631A72EBD8C29FF5394C02F3'}
2018-11-27 10:16:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00.html>
{'click': '891',
 'ctime': '2015-10-10',
 'filename': 'starship_troopers_[tfile.ru]',
 'length': '37.4 GB',
 'link': 'magnet:?xt=urn:btih:F5B1ED2C9167985524A88AC2C40C3F2A60F2CA00'}
2018-11-27 10:16:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/477A738D3C771C7E467323DE07D91C943B696EC6.html>
{'click': '41',
 'ctime': '2016-03-20',
 'filename': 'Starship Troopers',
 'length': '39.8 GB',
 'link': 'magnet:?xt=urn:btih:477A738D3C771C7E467323DE07D91C943B696EC6'}
2018-11-27 10:16:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_2.html)
2018-11-27 10:16:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/D85F8FCC22DAF9B355725C54AD570C34B2803D23.html>
{'click': '4563',
 'ctime': '2015-10-13',
 'filename': 'STARSHIP_TROOPERS_BD_BLUEBIRD',
 'length': '44.5 GB',
 'link': 'magnet:?xt=urn:btih:D85F8FCC22DAF9B355725C54AD570C34B2803D23'}
2018-11-27 10:16:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:16:47 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 72, in close_spider
    'tn=baidu&wd=' + quote(item['baidu']) + '&rsv_pq=db883fdf0000fbdb&' \
  File "/usr/local/lib/python3.6/dist-packages/scrapy/item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'baidu'
2018-11-27 10:16:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 205533,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 16, 47, 379225),
 'item_scraped_count': 45,
 'log_count/DEBUG': 94,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 766627840,
 'memusage/startup': 766627840,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 16, 41, 880978)}
2018-11-27 10:16:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:18:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:18:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:18:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:18:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:18:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:18:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:18:14 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:18:14 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:18:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:18:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:18:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:18:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_5.html> (referer: None)
2018-11-27 10:18:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html>
{'click': '477',
 'ctime': '2017-12-15',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 10:18:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html>
{'click': '851',
 'ctime': '2017-06-20',
 'filename': 'Starship.Troopers.3.Marauder.BD-Remux',
 'length': '28.3 GB',
 'link': 'magnet:?xt=urn:btih:9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3'}
2018-11-27 10:18:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html>
{'click': '60',
 'ctime': '2016-01-13',
 'filename': 'Starship.Troopers.1997.BDRX.VC1.LaDIFF.mkv',
 'length': '29.6 GB',
 'link': 'magnet:?xt=urn:btih:BF7E83E32C5360BDD2045F1C948D732850BE72C4'}
2018-11-27 10:18:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html>
{'click': '41',
 'ctime': '2018-07-17',
 'filename': '07.08.13.Starship.Troopers.Blu-ray.Remux.VC1.1080P.DTS.LPCM.DD51.O_Silu',
 'length': '30.7 GB',
 'link': 'magnet:?xt=urn:btih:F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55'}
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_4.html> (referer: None)
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html>
{'click': '1053',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FE87306308BD5E29109EAB07F51748E72ED1B0A9'}
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html>
{'click': '224',
 'ctime': '2017-09-22',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.BLURAY.EUR',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1A08B510FDCD39348661569020F3BC6A3B6A9282'}
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html>
{'click': '117',
 'ctime': '2017-09-29',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60'}
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html>
{'click': '3',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html>
{'click': '170',
 'ctime': '2017-03-30',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html>
{'click': '1624',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:78201DE6A506D758CD51A2FC3CC2159257DCE893'}
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html>
{'click': '9',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E'}
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html>
{'click': '1103',
 'ctime': '2015-12-04',
 'filename': 'Starship_Troopers_Invasion.2012.1080p.BDRemux.mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6'}
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html>
{'click': '18',
 'ctime': '2018-10-03',
 'filename': 'Starship Troopers Invasion 2012 BluRay REMUX 1080p AVC DTS-HD '
             'MA5.1-CHD',
 'length': '17.8 GB',
 'link': 'magnet:?xt=urn:btih:0E4B0FB764299CCDF714B0CE01048466386B6885'}
2018-11-27 10:18:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html>
{'click': '88',
 'ctime': '2017-10-07',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:2F218C1A4219EB9E655AD5170CD35D53A00FF991'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html>
{'click': '905',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html>
{'click': '704',
 'ctime': '2015-10-15',
 'filename': 'Trilogia Starship Troopers [BluRay 720p][DUAL '
             'DTS][WwW.ZoNaTorrent.CoM]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:8AF0205BA270C27854D49821124DDDC5D25EB670'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html>
{'click': '3561',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Invasion.2012.x264.BDRemux.(1080p).mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:B60113BC382530AE65058A42E95B4CD095CC9278'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html>
{'click': '554',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SWAGGERUHD',
 'length': '18.1 GB',
 'link': 'magnet:?xt=urn:btih:38E02D6EAFDD9D752306D144FE13F830664CA2A4'}
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html>
{'click': '8201',
 'ctime': '2015-10-13',
 'filename': 'Trilogia Starship Troopers [BluRay 720 px][AC3 5.1-DTS '
             'Castellano-Ingles+Subs]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F03E3BCAEBBCACEA894EB3E2BC4DAD835ADC2473.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html>
{'click': '499',
 'ctime': '2018-04-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SpaceHD13.mkv',
 'length': '18.5 GB',
 'link': 'magnet:?xt=urn:btih:10BBA6CEC5B3D514151321C5CF197C20F473F03D'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html>
{'click': '31',
 'ctime': '2015-10-11',
 'filename': 'STARSHIP_TROOPERS_INVASION_2012_BD_REMUX_HDCLUB',
 'length': '20.1 GB',
 'link': 'magnet:?xt=urn:btih:4003DFFF788762B88C10FB4EA602609D8192BFD5'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html>
{'click': '232',
 'ctime': '2018-04-08',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '22.0 GB',
 'link': 'magnet:?xt=urn:btih:B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1'}
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html>
{'click': '536',
 'ctime': '2017-10-04',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BD25.AVC.DTS-HD.5.1.Paulista',
 'length': '22.1 GB',
 'link': 'magnet:?xt=urn:btih:A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D'}
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html>
{'click': '1572',
 'ctime': '2017-09-19',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.REMUX.AVC.DTS-HD.MA.5.1-FGT',
 'length': '22.8 GB',
 'link': 'magnet:?xt=urn:btih:45464615F5A3417F48C7E4A21850B0A5CD34DFE0'}
2018-11-27 10:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html>
{'click': '11492',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.1997.1080p.BluRay-Skazhutin',
 'length': '22.2 GB',
 'link': 'magnet:?xt=urn:btih:C16EE3B7C9336658ECD107CDF4756790EDB56A7B'}
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html>
{'click': '19',
 'ctime': '2017-05-09',
 'filename': 'Starship.Troopers.3.Marauder.2008.1080p.BluRay.Remux.AVC.TrueHD.5.1.HUN-Paul',
 'length': '23.6 GB',
 'link': 'magnet:?xt=urn:btih:4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A'}
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html>
{'click': '125',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:978CE797B3E431A223BE0AFE2084F33E51934128'}
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html>
{'click': '871',
 'ctime': '2016-02-22',
 'filename': 'Starship Troopers 2 Hero of the Federation 2004 Blu-Ray',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:7B1CD2E099EF76F47BA556CC0B0D6C7747723891'}
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html>
{'click': '37',
 'ctime': '2017-11-04',
 'filename': 'Starship Troopers Trilogy 1080p BluRay x264-FuzePackes',
 'length': '24.6 GB',
 'link': 'magnet:?xt=urn:btih:444EAFA258DEB4DBC319E763A78DBD740F1ECC79'}
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html>
{'click': '10',
 'ctime': '2018-10-25',
 'filename': '11.10.04.Starship.Troopers.1997.BD.REMUX.h264.1080p.THD.DD51.Mysilu',
 'length': '25.3 GB',
 'link': 'magnet:?xt=urn:btih:7A055B138F983B4BBB84AD7B643AFB3D9379E78F'}
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html>
{'click': '582',
 'ctime': '2015-12-21',
 'filename': '_Starship.Troopers_Blu-ray.VC1-REMUX.1080P_DTS.Three.Audio',
 'length': '26.4 GB',
 'link': 'magnet:?xt=urn:btih:B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592'}
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html>
{'click': '3292',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Blu-Ray.1080p.VC-1.HDTracker.ru.mkv',
 'length': '27.0 GB',
 'link': 'magnet:?xt=urn:btih:16A8543938A54E28D7211A88966F68A3C0791A36'}
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html>
{'click': '2390',
 'ctime': '2015-10-29',
 'filename': 'Starship Troopers 2',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:F4F2F86AC7D27035C39CA190B244177CEC4D8F4C'}
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html>
{'click': '1772',
 'ctime': '2018-02-01',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:DC739A0B1A51D41C58AEAF12770332CD6003D620'}
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html>
{'click': '74',
 'ctime': '2015-12-24',
 'filename': 'Starship.Troopers.Invasion.2012.BluRay.REMUX.AVC.DTS-HD.MA5.1-CHDBits.DUAL-KAZESHiNi',
 'length': '18.7 GB',
 'link': 'magnet:?xt=urn:btih:5DCEF2694BC83FD96B91B0301252BEFFC503FA66'}
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html>
{'click': '157',
 'ctime': '2017-09-17',
 'filename': 'Starship Troopers Traitor of Mars',
 'length': '26.8 GB',
 'link': 'magnet:?xt=urn:btih:BF524DF5FF141BA60D9D4E926D75C9863C863CFE'}
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html>
{'click': '979',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux.1080p.NNMClub.mkv',
 'length': '19.3 GB',
 'link': 'magnet:?xt=urn:btih:B99F0E014559E1A5FD84F05833A108D48BDCC92D'}
2018-11-27 10:18:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html>
{'click': '1022',
 'ctime': '2017-10-25',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux .1080p.mkv',
 'length': '19.5 GB',
 'link': 'magnet:?xt=urn:btih:4F02C55014E46C6B0F255BA949BAA13E419F893F'}
2018-11-27 10:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html>
{'click': '264',
 'ctime': '2018-02-16',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE.mkv',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:88118FA77235E9FE29E4B8BB40A0357F7FEA19C3'}
2018-11-27 10:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html>
{'click': '937',
 'ctime': '2018-03-15',
 'filename': 'Starship.Troopers.1997.1080p.BluRay.x264.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '18.9 GB',
 'link': 'magnet:?xt=urn:btih:554ADD554F13536AA1B6F743DE4384D2D2064D9B'}
2018-11-27 10:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html>
{'click': '26',
 'ctime': '2018-08-02',
 'filename': 'Starship.Troopers.1997.1080p.UHD.BluRay.DD5.1.x264.HUN-GS88',
 'length': '19.7 GB',
 'link': 'magnet:?xt=urn:btih:94045211BD25B16B60EB1894BC3123CA1CDFFBEE'}
2018-11-27 10:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html>
{'click': '293',
 'ctime': '2018-05-13',
 'filename': 'Tropas Estelares - (Starship Troopers)',
 'length': '19.8 GB',
 'link': 'magnet:?xt=urn:btih:0B03AA4FE3706A754947C3BED9C7CC6045F45C5D'}
2018-11-27 10:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html>
{'click': '518',
 'ctime': '2017-09-23',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.HUN.1080p.BluRay.Remux.AVC.DTS-HD.MA.5.1-DeeMoN',
 'length': '19.6 GB',
 'link': 'magnet:?xt=urn:btih:640A7AE8E6EFE41DAC04A0942413A8DA647319ED'}
2018-11-27 10:18:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:18:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html>
{'click': '1520',
 'ctime': '2015-10-22',
 'filename': 'Starship Troopers (1997)',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FEE4A83EA42137C0945CE51BB9E65D137914BE87'}
2018-11-27 10:18:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:18:21 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/MyPython/scrapy/magnet/magnet/pipelines.py", line 73, in close_spider
    'tn=baidu&wd=' + quote(item['baidu']) + '&rsv_pq=db883fdf0000fbdb&' \
  File "/usr/local/lib/python3.6/dist-packages/scrapy/item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'baidu'
2018-11-27 10:18:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 160347,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 18, 21, 170967),
 'item_scraped_count': 44,
 'log_count/DEBUG': 93,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 769224704,
 'memusage/startup': 769224704,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 18, 14, 127712)}
2018-11-27 10:18:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:19:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:19:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:20:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:20:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:20:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:20:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:20:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:20:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:20:05 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:20:05 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:20:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:20:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:20:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_5.html> (referer: None)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_4.html> (referer: None)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html>
{'click': '3561',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Invasion.2012.x264.BDRemux.(1080p).mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:B60113BC382530AE65058A42E95B4CD095CC9278'}
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html>
{'click': '704',
 'ctime': '2015-10-15',
 'filename': 'Trilogia Starship Troopers [BluRay 720p][DUAL '
             'DTS][WwW.ZoNaTorrent.CoM]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:8AF0205BA270C27854D49821124DDDC5D25EB670'}
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html>
{'click': '554',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SWAGGERUHD',
 'length': '18.1 GB',
 'link': 'magnet:?xt=urn:btih:38E02D6EAFDD9D752306D144FE13F830664CA2A4'}
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html>
{'click': '937',
 'ctime': '2018-03-15',
 'filename': 'Starship.Troopers.1997.1080p.BluRay.x264.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '18.9 GB',
 'link': 'magnet:?xt=urn:btih:554ADD554F13536AA1B6F743DE4384D2D2064D9B'}
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html>
{'click': '979',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux.1080p.NNMClub.mkv',
 'length': '19.3 GB',
 'link': 'magnet:?xt=urn:btih:B99F0E014559E1A5FD84F05833A108D48BDCC92D'}
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html>
{'click': '18',
 'ctime': '2018-10-03',
 'filename': 'Starship Troopers Invasion 2012 BluRay REMUX 1080p AVC DTS-HD '
             'MA5.1-CHD',
 'length': '17.8 GB',
 'link': 'magnet:?xt=urn:btih:0E4B0FB764299CCDF714B0CE01048466386B6885'}
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html>
{'click': '8201',
 'ctime': '2015-10-13',
 'filename': 'Trilogia Starship Troopers [BluRay 720 px][AC3 5.1-DTS '
             'Castellano-Ingles+Subs]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D'}
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html>
{'click': '499',
 'ctime': '2018-04-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SpaceHD13.mkv',
 'length': '18.5 GB',
 'link': 'magnet:?xt=urn:btih:10BBA6CEC5B3D514151321C5CF197C20F473F03D'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html>
{'click': '74',
 'ctime': '2015-12-24',
 'filename': 'Starship.Troopers.Invasion.2012.BluRay.REMUX.AVC.DTS-HD.MA5.1-CHDBits.DUAL-KAZESHiNi',
 'length': '18.7 GB',
 'link': 'magnet:?xt=urn:btih:5DCEF2694BC83FD96B91B0301252BEFFC503FA66'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html>
{'click': '518',
 'ctime': '2017-09-23',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.HUN.1080p.BluRay.Remux.AVC.DTS-HD.MA.5.1-DeeMoN',
 'length': '19.6 GB',
 'link': 'magnet:?xt=urn:btih:640A7AE8E6EFE41DAC04A0942413A8DA647319ED'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html>
{'click': '26',
 'ctime': '2018-08-02',
 'filename': 'Starship.Troopers.1997.1080p.UHD.BluRay.DD5.1.x264.HUN-GS88',
 'length': '19.7 GB',
 'link': 'magnet:?xt=urn:btih:94045211BD25B16B60EB1894BC3123CA1CDFFBEE'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html>
{'click': '293',
 'ctime': '2018-05-13',
 'filename': 'Tropas Estelares - (Starship Troopers)',
 'length': '19.8 GB',
 'link': 'magnet:?xt=urn:btih:0B03AA4FE3706A754947C3BED9C7CC6045F45C5D'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html>
{'click': '31',
 'ctime': '2015-10-11',
 'filename': 'STARSHIP_TROOPERS_INVASION_2012_BD_REMUX_HDCLUB',
 'length': '20.1 GB',
 'link': 'magnet:?xt=urn:btih:4003DFFF788762B88C10FB4EA602609D8192BFD5'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html>
{'click': '232',
 'ctime': '2018-04-08',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '22.0 GB',
 'link': 'magnet:?xt=urn:btih:B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html>
{'click': '1053',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FE87306308BD5E29109EAB07F51748E72ED1B0A9'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html>
{'click': '871',
 'ctime': '2016-02-22',
 'filename': 'Starship Troopers 2 Hero of the Federation 2004 Blu-Ray',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:7B1CD2E099EF76F47BA556CC0B0D6C7747723891'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html>
{'click': '1103',
 'ctime': '2015-12-04',
 'filename': 'Starship_Troopers_Invasion.2012.1080p.BDRemux.mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html>
{'click': '1520',
 'ctime': '2015-10-22',
 'filename': 'Starship Troopers (1997)',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FEE4A83EA42137C0945CE51BB9E65D137914BE87'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html>
{'click': '477',
 'ctime': '2017-12-15',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html>
{'click': '1022',
 'ctime': '2017-10-25',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux .1080p.mkv',
 'length': '19.5 GB',
 'link': 'magnet:?xt=urn:btih:4F02C55014E46C6B0F255BA949BAA13E419F893F'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F03E3BCAEBBCACEA894EB3E2BC4DAD835ADC2473.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html>
{'click': '905',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html>
{'click': '88',
 'ctime': '2017-10-07',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:2F218C1A4219EB9E655AD5170CD35D53A00FF991'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html>
{'click': '60',
 'ctime': '2016-01-13',
 'filename': 'Starship.Troopers.1997.BDRX.VC1.LaDIFF.mkv',
 'length': '29.6 GB',
 'link': 'magnet:?xt=urn:btih:BF7E83E32C5360BDD2045F1C948D732850BE72C4'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html>
{'click': '41',
 'ctime': '2018-07-17',
 'filename': '07.08.13.Starship.Troopers.Blu-ray.Remux.VC1.1080P.DTS.LPCM.DD51.O_Silu',
 'length': '30.7 GB',
 'link': 'magnet:?xt=urn:btih:F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html>
{'click': '125',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:978CE797B3E431A223BE0AFE2084F33E51934128'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html>
{'click': '851',
 'ctime': '2017-06-20',
 'filename': 'Starship.Troopers.3.Marauder.BD-Remux',
 'length': '28.3 GB',
 'link': 'magnet:?xt=urn:btih:9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html>
{'click': '224',
 'ctime': '2017-09-22',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.BLURAY.EUR',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1A08B510FDCD39348661569020F3BC6A3B6A9282'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html>
{'click': '3',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html>
{'click': '2390',
 'ctime': '2015-10-29',
 'filename': 'Starship Troopers 2',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:F4F2F86AC7D27035C39CA190B244177CEC4D8F4C'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html>
{'click': '11492',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.1997.1080p.BluRay-Skazhutin',
 'length': '22.2 GB',
 'link': 'magnet:?xt=urn:btih:C16EE3B7C9336658ECD107CDF4756790EDB56A7B'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html>
{'click': '19',
 'ctime': '2017-05-09',
 'filename': 'Starship.Troopers.3.Marauder.2008.1080p.BluRay.Remux.AVC.TrueHD.5.1.HUN-Paul',
 'length': '23.6 GB',
 'link': 'magnet:?xt=urn:btih:4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html>
{'click': '1572',
 'ctime': '2017-09-19',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.REMUX.AVC.DTS-HD.MA.5.1-FGT',
 'length': '22.8 GB',
 'link': 'magnet:?xt=urn:btih:45464615F5A3417F48C7E4A21850B0A5CD34DFE0'}
2018-11-27 10:20:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html>
{'click': '9',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E'}
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html>
{'click': '37',
 'ctime': '2017-11-04',
 'filename': 'Starship Troopers Trilogy 1080p BluRay x264-FuzePackes',
 'length': '24.6 GB',
 'link': 'magnet:?xt=urn:btih:444EAFA258DEB4DBC319E763A78DBD740F1ECC79'}
2018-11-27 10:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html>
{'click': '582',
 'ctime': '2015-12-21',
 'filename': '_Starship.Troopers_Blu-ray.VC1-REMUX.1080P_DTS.Three.Audio',
 'length': '26.4 GB',
 'link': 'magnet:?xt=urn:btih:B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592'}
2018-11-27 10:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html>
{'click': '170',
 'ctime': '2017-03-30',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 10:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html>
{'click': '3292',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Blu-Ray.1080p.VC-1.HDTracker.ru.mkv',
 'length': '27.0 GB',
 'link': 'magnet:?xt=urn:btih:16A8543938A54E28D7211A88966F68A3C0791A36'}
2018-11-27 10:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html>
{'click': '10',
 'ctime': '2018-10-25',
 'filename': '11.10.04.Starship.Troopers.1997.BD.REMUX.h264.1080p.THD.DD51.Mysilu',
 'length': '25.3 GB',
 'link': 'magnet:?xt=urn:btih:7A055B138F983B4BBB84AD7B643AFB3D9379E78F'}
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html>
{'click': '157',
 'ctime': '2017-09-17',
 'filename': 'Starship Troopers Traitor of Mars',
 'length': '26.8 GB',
 'link': 'magnet:?xt=urn:btih:BF524DF5FF141BA60D9D4E926D75C9863C863CFE'}
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html>
{'click': '264',
 'ctime': '2018-02-16',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE.mkv',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:88118FA77235E9FE29E4B8BB40A0357F7FEA19C3'}
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html>
{'click': '1624',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:78201DE6A506D758CD51A2FC3CC2159257DCE893'}
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html>
{'click': '536',
 'ctime': '2017-10-04',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BD25.AVC.DTS-HD.5.1.Paulista',
 'length': '22.1 GB',
 'link': 'magnet:?xt=urn:btih:A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D'}
2018-11-27 10:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html>
{'click': '1772',
 'ctime': '2018-02-01',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:DC739A0B1A51D41C58AEAF12770332CD6003D620'}
2018-11-27 10:20:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html>
{'click': '117',
 'ctime': '2017-09-29',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60'}
2018-11-27 10:20:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:20:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 160296,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 20, 9, 297614),
 'item_scraped_count': 44,
 'log_count/DEBUG': 93,
 'log_count/INFO': 7,
 'memusage/max': 771678208,
 'memusage/startup': 771678208,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 20, 5, 6861)}
2018-11-27 10:20:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:20:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:20:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:20:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:20:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:20:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:20:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:20:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:20:30 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:20:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:20:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_4.html> (referer: None)
2018-11-27 10:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_5.html> (referer: None)
2018-11-27 10:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html>
{'click': '19',
 'ctime': '2017-05-09',
 'filename': 'Starship.Troopers.3.Marauder.2008.1080p.BluRay.Remux.AVC.TrueHD.5.1.HUN-Paul',
 'length': '23.6 GB',
 'link': 'magnet:?xt=urn:btih:4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A'}
2018-11-27 10:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html>
{'click': '536',
 'ctime': '2017-10-04',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BD25.AVC.DTS-HD.5.1.Paulista',
 'length': '22.1 GB',
 'link': 'magnet:?xt=urn:btih:A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html>
{'click': '871',
 'ctime': '2016-02-22',
 'filename': 'Starship Troopers 2 Hero of the Federation 2004 Blu-Ray',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:7B1CD2E099EF76F47BA556CC0B0D6C7747723891'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html>
{'click': '232',
 'ctime': '2018-04-08',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '22.0 GB',
 'link': 'magnet:?xt=urn:btih:B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html>
{'click': '11492',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.1997.1080p.BluRay-Skazhutin',
 'length': '22.2 GB',
 'link': 'magnet:?xt=urn:btih:C16EE3B7C9336658ECD107CDF4756790EDB56A7B'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html>
{'click': '37',
 'ctime': '2017-11-04',
 'filename': 'Starship Troopers Trilogy 1080p BluRay x264-FuzePackes',
 'length': '24.6 GB',
 'link': 'magnet:?xt=urn:btih:444EAFA258DEB4DBC319E763A78DBD740F1ECC79'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html>
{'click': '157',
 'ctime': '2017-09-17',
 'filename': 'Starship Troopers Traitor of Mars',
 'length': '26.8 GB',
 'link': 'magnet:?xt=urn:btih:BF524DF5FF141BA60D9D4E926D75C9863C863CFE'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html>
{'click': '3292',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Blu-Ray.1080p.VC-1.HDTracker.ru.mkv',
 'length': '27.0 GB',
 'link': 'magnet:?xt=urn:btih:16A8543938A54E28D7211A88966F68A3C0791A36'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html>
{'click': '1772',
 'ctime': '2018-02-01',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:DC739A0B1A51D41C58AEAF12770332CD6003D620'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html>
{'click': '31',
 'ctime': '2015-10-11',
 'filename': 'STARSHIP_TROOPERS_INVASION_2012_BD_REMUX_HDCLUB',
 'length': '20.1 GB',
 'link': 'magnet:?xt=urn:btih:4003DFFF788762B88C10FB4EA602609D8192BFD5'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html>
{'click': '3561',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Invasion.2012.x264.BDRemux.(1080p).mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:B60113BC382530AE65058A42E95B4CD095CC9278'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html>
{'click': '1103',
 'ctime': '2015-12-04',
 'filename': 'Starship_Troopers_Invasion.2012.1080p.BDRemux.mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html>
{'click': '264',
 'ctime': '2018-02-16',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE.mkv',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:88118FA77235E9FE29E4B8BB40A0357F7FEA19C3'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html>
{'click': '582',
 'ctime': '2015-12-21',
 'filename': '_Starship.Troopers_Blu-ray.VC1-REMUX.1080P_DTS.Three.Audio',
 'length': '26.4 GB',
 'link': 'magnet:?xt=urn:btih:B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html>
{'click': '18',
 'ctime': '2018-10-03',
 'filename': 'Starship Troopers Invasion 2012 BluRay REMUX 1080p AVC DTS-HD '
             'MA5.1-CHD',
 'length': '17.8 GB',
 'link': 'magnet:?xt=urn:btih:0E4B0FB764299CCDF714B0CE01048466386B6885'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html>
{'click': '1520',
 'ctime': '2015-10-22',
 'filename': 'Starship Troopers (1997)',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FEE4A83EA42137C0945CE51BB9E65D137914BE87'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html>
{'click': '8201',
 'ctime': '2015-10-13',
 'filename': 'Trilogia Starship Troopers [BluRay 720 px][AC3 5.1-DTS '
             'Castellano-Ingles+Subs]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html>
{'click': '10',
 'ctime': '2018-10-25',
 'filename': '11.10.04.Starship.Troopers.1997.BD.REMUX.h264.1080p.THD.DD51.Mysilu',
 'length': '25.3 GB',
 'link': 'magnet:?xt=urn:btih:7A055B138F983B4BBB84AD7B643AFB3D9379E78F'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html>
{'click': '1572',
 'ctime': '2017-09-19',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.REMUX.AVC.DTS-HD.MA.5.1-FGT',
 'length': '22.8 GB',
 'link': 'magnet:?xt=urn:btih:45464615F5A3417F48C7E4A21850B0A5CD34DFE0'}
2018-11-27 10:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html>
{'click': '88',
 'ctime': '2017-10-07',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:2F218C1A4219EB9E655AD5170CD35D53A00FF991'}
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html>
{'click': '851',
 'ctime': '2017-06-20',
 'filename': 'Starship.Troopers.3.Marauder.BD-Remux',
 'length': '28.3 GB',
 'link': 'magnet:?xt=urn:btih:9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3'}
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html>
{'click': '704',
 'ctime': '2015-10-15',
 'filename': 'Trilogia Starship Troopers [BluRay 720p][DUAL '
             'DTS][WwW.ZoNaTorrent.CoM]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:8AF0205BA270C27854D49821124DDDC5D25EB670'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html>
{'click': '1053',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FE87306308BD5E29109EAB07F51748E72ED1B0A9'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html>
{'click': '60',
 'ctime': '2016-01-13',
 'filename': 'Starship.Troopers.1997.BDRX.VC1.LaDIFF.mkv',
 'length': '29.6 GB',
 'link': 'magnet:?xt=urn:btih:BF7E83E32C5360BDD2045F1C948D732850BE72C4'}
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html>
{'click': '117',
 'ctime': '2017-09-29',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html>
{'click': '905',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html>
{'click': '1624',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:78201DE6A506D758CD51A2FC3CC2159257DCE893'}
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html>
{'click': '3',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html>
{'click': '554',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SWAGGERUHD',
 'length': '18.1 GB',
 'link': 'magnet:?xt=urn:btih:38E02D6EAFDD9D752306D144FE13F830664CA2A4'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html>
{'click': '9',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html>
{'click': '477',
 'ctime': '2017-12-15',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html>
{'click': '41',
 'ctime': '2018-07-17',
 'filename': '07.08.13.Starship.Troopers.Blu-ray.Remux.VC1.1080P.DTS.LPCM.DD51.O_Silu',
 'length': '30.7 GB',
 'link': 'magnet:?xt=urn:btih:F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55'}
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html>
{'click': '2390',
 'ctime': '2015-10-29',
 'filename': 'Starship Troopers 2',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:F4F2F86AC7D27035C39CA190B244177CEC4D8F4C'}
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html>
{'click': '125',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:978CE797B3E431A223BE0AFE2084F33E51934128'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html>
{'click': '499',
 'ctime': '2018-04-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SpaceHD13.mkv',
 'length': '18.5 GB',
 'link': 'magnet:?xt=urn:btih:10BBA6CEC5B3D514151321C5CF197C20F473F03D'}
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html>
{'click': '74',
 'ctime': '2015-12-24',
 'filename': 'Starship.Troopers.Invasion.2012.BluRay.REMUX.AVC.DTS-HD.MA5.1-CHDBits.DUAL-KAZESHiNi',
 'length': '18.7 GB',
 'link': 'magnet:?xt=urn:btih:5DCEF2694BC83FD96B91B0301252BEFFC503FA66'}
2018-11-27 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html>
{'click': '1022',
 'ctime': '2017-10-25',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux .1080p.mkv',
 'length': '19.5 GB',
 'link': 'magnet:?xt=urn:btih:4F02C55014E46C6B0F255BA949BAA13E419F893F'}
2018-11-27 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html>
{'click': '937',
 'ctime': '2018-03-15',
 'filename': 'Starship.Troopers.1997.1080p.BluRay.x264.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '18.9 GB',
 'link': 'magnet:?xt=urn:btih:554ADD554F13536AA1B6F743DE4384D2D2064D9B'}
2018-11-27 10:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F03E3BCAEBBCACEA894EB3E2BC4DAD835ADC2473.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html>
{'click': '979',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux.1080p.NNMClub.mkv',
 'length': '19.3 GB',
 'link': 'magnet:?xt=urn:btih:B99F0E014559E1A5FD84F05833A108D48BDCC92D'}
2018-11-27 10:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html>
{'click': '26',
 'ctime': '2018-08-02',
 'filename': 'Starship.Troopers.1997.1080p.UHD.BluRay.DD5.1.x264.HUN-GS88',
 'length': '19.7 GB',
 'link': 'magnet:?xt=urn:btih:94045211BD25B16B60EB1894BC3123CA1CDFFBEE'}
2018-11-27 10:20:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html>
{'click': '170',
 'ctime': '2017-03-30',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 10:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:20:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html>
{'click': '518',
 'ctime': '2017-09-23',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.HUN.1080p.BluRay.Remux.AVC.DTS-HD.MA.5.1-DeeMoN',
 'length': '19.6 GB',
 'link': 'magnet:?xt=urn:btih:640A7AE8E6EFE41DAC04A0942413A8DA647319ED'}
2018-11-27 10:20:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html>
{'click': '224',
 'ctime': '2017-09-22',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.BLURAY.EUR',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1A08B510FDCD39348661569020F3BC6A3B6A9282'}
2018-11-27 10:20:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:20:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html>
{'click': '293',
 'ctime': '2018-05-13',
 'filename': 'Tropas Estelares - (Starship Troopers)',
 'length': '19.8 GB',
 'link': 'magnet:?xt=urn:btih:0B03AA4FE3706A754947C3BED9C7CC6045F45C5D'}
2018-11-27 10:20:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:20:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 160256,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 20, 38, 12598),
 'item_scraped_count': 44,
 'log_count/DEBUG': 93,
 'log_count/INFO': 7,
 'memusage/max': 776323072,
 'memusage/startup': 776323072,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 20, 30, 946469)}
2018-11-27 10:20:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:22:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:22:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:22:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:22:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:22:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:22:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:22:05 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:22:05 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:22:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:22:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:22:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_3.html> (referer: None)
2018-11-27 10:22:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3.html>
{'click': '851',
 'ctime': '2017-06-20',
 'filename': 'Starship.Troopers.3.Marauder.BD-Remux',
 'length': '28.3 GB',
 'link': 'magnet:?xt=urn:btih:9107E0AE6D59AE8D8DB788A3079D3CC8620BBDA3'}
2018-11-27 10:22:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_4.html> (referer: None)
2018-11-27 10:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/Starship%20Troopers_length_5.html> (referer: None)
2018-11-27 10:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/80C7740FAE7F211B46E6166F94D880A0A4B70505.html>
{'click': '477',
 'ctime': '2017-12-15',
 'filename': '.Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:80C7740FAE7F211B46E6166F94D880A0A4B70505'}
2018-11-27 10:22:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2F218C1A4219EB9E655AD5170CD35D53A00FF991.html>
{'click': '88',
 'ctime': '2017-10-07',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:2F218C1A4219EB9E655AD5170CD35D53A00FF991'}
2018-11-27 10:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60.html>
{'click': '117',
 'ctime': '2017-09-29',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1C8EB343311A0FAAF4085CEA2E1C1A2095E32C60'}
2018-11-27 10:22:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF7E83E32C5360BDD2045F1C948D732850BE72C4.html>
{'click': '60',
 'ctime': '2016-01-13',
 'filename': 'Starship.Troopers.1997.BDRX.VC1.LaDIFF.mkv',
 'length': '29.6 GB',
 'link': 'magnet:?xt=urn:btih:BF7E83E32C5360BDD2045F1C948D732850BE72C4'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E.html>
{'click': '9',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:9C395EE8E329A9457C65B0F5F6BD1920F5B0F98E'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55.html>
{'click': '41',
 'ctime': '2018-07-17',
 'filename': '07.08.13.Starship.Troopers.Blu-ray.Remux.VC1.1080P.DTS.LPCM.DD51.O_Silu',
 'length': '30.7 GB',
 'link': 'magnet:?xt=urn:btih:F5CD0BB8AD0108028B7EE243E2F55F8DDFEC5E55'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34.html>
{'click': '3',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.BOXSET.1080p.BluRay.x264-MiXED',
 'length': '31.2 GB',
 'link': 'magnet:?xt=urn:btih:972516DF8B43AA4326AC9A1E0A92ADCCD0C68C34'}
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/1A08B510FDCD39348661569020F3BC6A3B6A9282.html>
{'click': '224',
 'ctime': '2017-09-22',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.BLURAY.EUR',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:1A08B510FDCD39348661569020F3BC6A3B6A9282'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4938C207E280A27C22C999B3A8FE3CE2F10AC8F7.html>
{'click': '170',
 'ctime': '2017-03-30',
 'filename': 'Starship Troopers - Invasion (2012) AVC 1080p BD50 - JP',
 'length': '32.7 GB',
 'link': 'magnet:?xt=urn:btih:4938C207E280A27C22C999B3A8FE3CE2F10AC8F7'}
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4003DFFF788762B88C10FB4EA602609D8192BFD5.html>
{'click': '31',
 'ctime': '2015-10-11',
 'filename': 'STARSHIP_TROOPERS_INVASION_2012_BD_REMUX_HDCLUB',
 'length': '20.1 GB',
 'link': 'magnet:?xt=urn:btih:4003DFFF788762B88C10FB4EA602609D8192BFD5'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FEE4A83EA42137C0945CE51BB9E65D137914BE87.html>
{'click': '1520',
 'ctime': '2015-10-22',
 'filename': 'Starship Troopers (1997)',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FEE4A83EA42137C0945CE51BB9E65D137914BE87'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/78201DE6A506D758CD51A2FC3CC2159257DCE893.html>
{'click': '1624',
 'ctime': '2017-09-20',
 'filename': 'Starship.Troopers.Traitor.Of.Mars.2017.MULTi.COMPLETE.BLURAY-BD4U',
 'length': '31.1 GB',
 'link': 'magnet:?xt=urn:btih:78201DE6A506D758CD51A2FC3CC2159257DCE893'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/F4F2F86AC7D27035C39CA190B244177CEC4D8F4C.html>
{'click': '2390',
 'ctime': '2015-10-29',
 'filename': 'Starship Troopers 2',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:F4F2F86AC7D27035C39CA190B244177CEC4D8F4C'}
2018-11-27 10:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1.html>
{'click': '232',
 'ctime': '2018-04-08',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '22.0 GB',
 'link': 'magnet:?xt=urn:btih:B89E3E863DE43794B94B0F85BF3DA9DC036FFFD1'}
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0E4B0FB764299CCDF714B0CE01048466386B6885.html>
{'click': '18',
 'ctime': '2018-10-03',
 'filename': 'Starship Troopers Invasion 2012 BluRay REMUX 1080p AVC DTS-HD '
             'MA5.1-CHD',
 'length': '17.8 GB',
 'link': 'magnet:?xt=urn:btih:0E4B0FB764299CCDF714B0CE01048466386B6885'}
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7B1CD2E099EF76F47BA556CC0B0D6C7747723891.html>
{'click': '871',
 'ctime': '2016-02-22',
 'filename': 'Starship Troopers 2 Hero of the Federation 2004 Blu-Ray',
 'length': '20.8 GB',
 'link': 'magnet:?xt=urn:btih:7B1CD2E099EF76F47BA556CC0B0D6C7747723891'}
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B60113BC382530AE65058A42E95B4CD095CC9278.html>
{'click': '3561',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Invasion.2012.x264.BDRemux.(1080p).mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:B60113BC382530AE65058A42E95B4CD095CC9278'}
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/FE87306308BD5E29109EAB07F51748E72ED1B0A9.html>
{'click': '1053',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '28.4 GB',
 'link': 'magnet:?xt=urn:btih:FE87306308BD5E29109EAB07F51748E72ED1B0A9'}
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/8AF0205BA270C27854D49821124DDDC5D25EB670.html>
{'click': '704',
 'ctime': '2015-10-15',
 'filename': 'Trilogia Starship Troopers [BluRay 720p][DUAL '
             'DTS][WwW.ZoNaTorrent.CoM]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:8AF0205BA270C27854D49821124DDDC5D25EB670'}
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D.html>
{'click': '8201',
 'ctime': '2015-10-13',
 'filename': 'Trilogia Starship Troopers [BluRay 720 px][AC3 5.1-DTS '
             'Castellano-Ingles+Subs]',
 'length': '18.0 GB',
 'link': 'magnet:?xt=urn:btih:97D83A82F4F2A3128ADB9D1A6A0834C6C71C230D'}
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6.html>
{'click': '1103',
 'ctime': '2015-12-04',
 'filename': 'Starship_Troopers_Invasion.2012.1080p.BDRemux.mkv',
 'length': '17.5 GB',
 'link': 'magnet:?xt=urn:btih:38999E9E391F0C8FCB14B4B101DD39E6A7FB70B6'}
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/10BBA6CEC5B3D514151321C5CF197C20F473F03D.html>
{'click': '499',
 'ctime': '2018-04-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SpaceHD13.mkv',
 'length': '18.5 GB',
 'link': 'magnet:?xt=urn:btih:10BBA6CEC5B3D514151321C5CF197C20F473F03D'}
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53.html>
{'click': '905',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.AVC.DTS-HD.MA.5.1-FGT',
 'length': '28.6 GB',
 'link': 'magnet:?xt=urn:btih:2CEFAB1F934EF69347D2215D432E8DAD9A8AFB53'}
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/5DCEF2694BC83FD96B91B0301252BEFFC503FA66.html>
{'click': '74',
 'ctime': '2015-12-24',
 'filename': 'Starship.Troopers.Invasion.2012.BluRay.REMUX.AVC.DTS-HD.MA5.1-CHDBits.DUAL-KAZESHiNi',
 'length': '18.7 GB',
 'link': 'magnet:?xt=urn:btih:5DCEF2694BC83FD96B91B0301252BEFFC503FA66'}
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B99F0E014559E1A5FD84F05833A108D48BDCC92D.html>
{'click': '979',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux.1080p.NNMClub.mkv',
 'length': '19.3 GB',
 'link': 'magnet:?xt=urn:btih:B99F0E014559E1A5FD84F05833A108D48BDCC92D'}
2018-11-27 10:22:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4F02C55014E46C6B0F255BA949BAA13E419F893F.html>
{'click': '1022',
 'ctime': '2017-10-25',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BDRemux .1080p.mkv',
 'length': '19.5 GB',
 'link': 'magnet:?xt=urn:btih:4F02C55014E46C6B0F255BA949BAA13E419F893F'}
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D.html>
{'click': '536',
 'ctime': '2017-10-04',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.BD25.AVC.DTS-HD.5.1.Paulista',
 'length': '22.1 GB',
 'link': 'magnet:?xt=urn:btih:A1C8DF5CFA025990FB7FF481EAFA8B60565DE19D'}
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/94045211BD25B16B60EB1894BC3123CA1CDFFBEE.html>
{'click': '26',
 'ctime': '2018-08-02',
 'filename': 'Starship.Troopers.1997.1080p.UHD.BluRay.DD5.1.x264.HUN-GS88',
 'length': '19.7 GB',
 'link': 'magnet:?xt=urn:btih:94045211BD25B16B60EB1894BC3123CA1CDFFBEE'}
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/0B03AA4FE3706A754947C3BED9C7CC6045F45C5D.html>
{'click': '293',
 'ctime': '2018-05-13',
 'filename': 'Tropas Estelares - (Starship Troopers)',
 'length': '19.8 GB',
 'link': 'magnet:?xt=urn:btih:0B03AA4FE3706A754947C3BED9C7CC6045F45C5D'}
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/38E02D6EAFDD9D752306D144FE13F830664CA2A4.html>
{'click': '554',
 'ctime': '2018-04-05',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.2160p.UHD.BluRay.x265-SWAGGERUHD',
 'length': '18.1 GB',
 'link': 'magnet:?xt=urn:btih:38E02D6EAFDD9D752306D144FE13F830664CA2A4'}
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/554ADD554F13536AA1B6F743DE4384D2D2064D9B.html>
{'click': '937',
 'ctime': '2018-03-15',
 'filename': 'Starship.Troopers.1997.1080p.BluRay.x264.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '18.9 GB',
 'link': 'magnet:?xt=urn:btih:554ADD554F13536AA1B6F743DE4384D2D2064D9B'}
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/7A055B138F983B4BBB84AD7B643AFB3D9379E78F.html>
{'click': '10',
 'ctime': '2018-10-25',
 'filename': '11.10.04.Starship.Troopers.1997.BD.REMUX.h264.1080p.THD.DD51.Mysilu',
 'length': '25.3 GB',
 'link': 'magnet:?xt=urn:btih:7A055B138F983B4BBB84AD7B643AFB3D9379E78F'}
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_3.html)
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/978CE797B3E431A223BE0AFE2084F33E51934128.html>
{'click': '125',
 'ctime': '2017-09-21',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.Blu-ray.AVC.DTS-HD.MA.5.1-HDHome',
 'length': '28.7 GB',
 'link': 'magnet:?xt=urn:btih:978CE797B3E431A223BE0AFE2084F33E51934128'}
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/640A7AE8E6EFE41DAC04A0942413A8DA647319ED.html>
{'click': '518',
 'ctime': '2017-09-23',
 'filename': 'Starship.Troopers.Traitor.of.Mars.2017.HUN.1080p.BluRay.Remux.AVC.DTS-HD.MA.5.1-DeeMoN',
 'length': '19.6 GB',
 'link': 'magnet:?xt=urn:btih:640A7AE8E6EFE41DAC04A0942413A8DA647319ED'}
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/444EAFA258DEB4DBC319E763A78DBD740F1ECC79.html>
{'click': '37',
 'ctime': '2017-11-04',
 'filename': 'Starship Troopers Trilogy 1080p BluRay x264-FuzePackes',
 'length': '24.6 GB',
 'link': 'magnet:?xt=urn:btih:444EAFA258DEB4DBC319E763A78DBD740F1ECC79'}
2018-11-27 10:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/BF524DF5FF141BA60D9D4E926D75C9863C863CFE.html>
{'click': '157',
 'ctime': '2017-09-17',
 'filename': 'Starship Troopers Traitor of Mars',
 'length': '26.8 GB',
 'link': 'magnet:?xt=urn:btih:BF524DF5FF141BA60D9D4E926D75C9863C863CFE'}
2018-11-27 10:22:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592.html>
{'click': '582',
 'ctime': '2015-12-21',
 'filename': '_Starship.Troopers_Blu-ray.VC1-REMUX.1080P_DTS.Three.Audio',
 'length': '26.4 GB',
 'link': 'magnet:?xt=urn:btih:B386ADA1AD72A0A4309D594CF1CCD7E1C0F23592'}
2018-11-27 10:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/45464615F5A3417F48C7E4A21850B0A5CD34DFE0.html>
{'click': '1572',
 'ctime': '2017-09-19',
 'filename': 'Starship.Troopers.Traitors.Mars.2017.1080p.BluRay.REMUX.AVC.DTS-HD.MA.5.1-FGT',
 'length': '22.8 GB',
 'link': 'magnet:?xt=urn:btih:45464615F5A3417F48C7E4A21850B0A5CD34DFE0'}
2018-11-27 10:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/88118FA77235E9FE29E4B8BB40A0357F7FEA19C3.html>
{'click': '264',
 'ctime': '2018-02-16',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE.mkv',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:88118FA77235E9FE29E4B8BB40A0357F7FEA19C3'}
2018-11-27 10:22:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/DC739A0B1A51D41C58AEAF12770332CD6003D620.html>
{'click': '1772',
 'ctime': '2018-02-01',
 'filename': 'Starship.Troopers.1997.2160p.UHD.BluRay.X265-IAMABLE',
 'length': '28.0 GB',
 'link': 'magnet:?xt=urn:btih:DC739A0B1A51D41C58AEAF12770332CD6003D620'}
2018-11-27 10:22:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F03E3BCAEBBCACEA894EB3E2BC4DAD835ADC2473.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_5.html)
2018-11-27 10:22:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A.html>
{'click': '19',
 'ctime': '2017-05-09',
 'filename': 'Starship.Troopers.3.Marauder.2008.1080p.BluRay.Remux.AVC.TrueHD.5.1.HUN-Paul',
 'length': '23.6 GB',
 'link': 'magnet:?xt=urn:btih:4C9BAF80DA442600ED6E1BDD4E5858B02B08D47A'}
2018-11-27 10:22:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/C16EE3B7C9336658ECD107CDF4756790EDB56A7B.html>
{'click': '11492',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.1997.1080p.BluRay-Skazhutin',
 'length': '22.2 GB',
 'link': 'magnet:?xt=urn:btih:C16EE3B7C9336658ECD107CDF4756790EDB56A7B'}
2018-11-27 10:22:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html> (referer: https://www.bturl.so/search/Starship%20Troopers_length_4.html)
2018-11-27 10:22:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.bturl.so/16A8543938A54E28D7211A88966F68A3C0791A36.html>
{'click': '3292',
 'ctime': '2015-10-10',
 'filename': 'Starship.Troopers.Blu-Ray.1080p.VC-1.HDTracker.ru.mkv',
 'length': '27.0 GB',
 'link': 'magnet:?xt=urn:btih:16A8543938A54E28D7211A88966F68A3C0791A36'}
2018-11-27 10:22:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:22:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18303,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 160311,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 22, 14, 783067),
 'item_scraped_count': 44,
 'log_count/DEBUG': 93,
 'log_count/INFO': 7,
 'memusage/max': 778694656,
 'memusage/startup': 778694656,
 'request_depth_max': 1,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2018, 11, 27, 2, 22, 5, 772062)}
2018-11-27 10:22:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:34:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:34:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:34:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:34:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:34:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:34:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:34:19 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:34:19 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:34:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:34:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_3.html> (referer: None)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_1.html> (referer: None)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_2.html> (referer: None)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7413161D93646A9D4826F0E7B4B6D20190CC11D7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/32BC10297FB6165DC02DACF565CDD4A33E5A12F0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0D1F01478B2FBD42447E12DBD8512380D4EDC04F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2845E8EABB19306AA52C7363EF4FB53B0792217E.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E95E20C81EC198FD2E1E4A8C1E532E439CB642C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10093BA1F1E86658D0EC39708CF1E097AA83DB02.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20> (referer: None)
2018-11-27 10:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20> (referer: None)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20> (referer: None)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20> (referer: None)
2018-11-27 10:34:22 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4A5C7ACA043648109EA55D452D5E779B53196757.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20>
{'baidu': 'avatar ',
 'click': '3',
 'ctime': '2018-11-26',
 'fanyi': '',
 'filename': 'Avatar.2009.Extended.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.mkv',
 'length': '101.9 GB',
 'link': 'magnet:?xt=urn:btih:A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4'}
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20>
{'baidu': 'the lost world jurassic park ',
 'click': '1224',
 'ctime': '2018-05-25',
 'fanyi': '',
 'filename': 'The.Lost.World.Jurassic.Park.1997.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.3xUKR.ENG).ExKinoRay.mkv',
 'length': '99.7 GB',
 'link': 'magnet:?xt=urn:btih:0D1F01478B2FBD42447E12DBD8512380D4EDC04F'}
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20> (referer: None)
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20>
{'baidu': "my best friend's wedding ",
 'click': '356',
 'ctime': '2015-10-30',
 'fanyi': '',
 'filename': "My.Best.Friend's.Wedding.1997.2160p.WEB-DL.2xRus.2xUkr.Eng-TrollUHD-ULTRAHDCLUB.mkv",
 'length': '100.5 GB',
 'link': 'magnet:?xt=urn:btih:32BC10297FB6165DC02DACF565CDD4A33E5A12F0'}
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20>
{'baidu': 'forrest gump ',
 'click': '1878',
 'ctime': '2018-06-13',
 'fanyi': '',
 'filename': 'Forrest.Gump.1994.UHD.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '91.9 GB',
 'link': 'magnet:?xt=urn:btih:7413161D93646A9D4826F0E7B4B6D20190CC11D7'}
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20> (referer: None)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DEFC01CE8510988F00615C02E41F175F1DEB3C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20>
{'baidu': 'ghostbusters ii ',
 'click': '720',
 'ctime': '2017-04-17',
 'fanyi': '2',
 'filename': 'Ghostbusters.II.1989.2160p.WEB-DL.8xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '103.9 GB',
 'link': 'magnet:?xt=urn:btih:E95E20C81EC198FD2E1E4A8C1E532E439CB642C0'}
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20>
{'baidu': 'watchmen ',
 'click': '1951',
 'ctime': '2018-04-24',
 'fanyi': '',
 'filename': 'Watchmen.2009.The.Ultimate.Cut.UHD.BDRemux.2160p.HEVC.HDR.IVA(4xRUS.ENG).ExKinoRay.mkv',
 'length': '95.7 GB',
 'link': 'magnet:?xt=urn:btih:2845E8EABB19306AA52C7363EF4FB53B0792217E'}
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5FD6172D4BBDF64BCE29D28BFD68D2DD9F49B704.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20> (referer: None)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/69B886B35068D58A057B4462CF1BBBB36324B257.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6EEE5ED342EC9E10293C4EEDEBCCF311BF9E4CB3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14BD82A8A83A48F394177E36C2817F207DF15C52.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20>
{'baidu': 'saving private ryan ',
 'click': '19',
 'ctime': '2018-05-25',
 'fanyi': '',
 'filename': 'Saving.Private.Ryan.1998.2160p.BDREMUX.HEVC.HDR.IVA(11xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '104.2 GB',
 'link': 'magnet:?xt=urn:btih:4A5C7ACA043648109EA55D452D5E779B53196757'}
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/500F668900B36CD297D753729D5AD8073320777D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3B68E98EC4522D7A2C3DAE1614BB32D3E8A41155.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_> (referer: None)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20> (referer: None)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20> (referer: None)
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_>
{'baidu': 'aliens_',
 'click': '809',
 'ctime': '2018-04-19',
 'fanyi': 'aliens_',
 'filename': 'Aliens_1986_Directors_Cut_2160p_4K_SDR_WEB-DL_AMZ_HHD.mkv',
 'length': '94.4 GB',
 'link': 'magnet:?xt=urn:btih:5FD6172D4BBDF64BCE29D28BFD68D2DD9F49B704'}
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20>
{'baidu': 'fury ',
 'click': '8',
 'ctime': '2016-07-07',
 'fanyi': '',
 'filename': 'Fury.2014.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '116.4 GB',
 'link': 'magnet:?xt=urn:btih:14BD82A8A83A48F394177E36C2817F207DF15C52'}
2018-11-27 10:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20>
{'baidu': 'the fifth element ',
 'click': '3536',
 'ctime': '2015-12-01',
 'fanyi': '',
 'filename': 'The.Fifth.Element.1997.2160p.WEB-DL.2xRus.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '90.8 GB',
 'link': 'magnet:?xt=urn:btih:0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC'}
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5C0372A9D620AD2B87312408A8A32183F85E0F3B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/959A6A8EA8730CE8736EB839587C1CAA8FECC77F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/52CE23F4D532B12B80EC30A9D30D8A5370ACF00C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6FA9CE5B9A08CAB64DC268B0512F950AC896569D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/71B18BEF36AEA4319D804083C31CB98873C59BF4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20> (referer: None)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6DFA4CED20D48D0E581E318B9EDC8B35D63FF8BD.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9BFF492E9E81B0DFF2FBAC8D66E258F5C62A7A7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> (referer: None)
2018-11-27 10:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20>
{'baidu': 'the bridge on the river kwai ',
 'click': '495',
 'ctime': '2017-04-03',
 'fanyi': '',
 'filename': 'The.Bridge.on.the.River.Kwai.1957.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '107.2 GB',
 'link': 'magnet:?xt=urn:btih:B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2'}
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20> (referer: None)
2018-11-27 10:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20>
{'baidu': 'men in black ',
 'click': '873',
 'ctime': '2015-11-12',
 'fanyi': '',
 'filename': 'Men.in.Black.1997.2160p.WEB-DL.3xRus.Eng.mkv',
 'length': '109.3 GB',
 'link': 'magnet:?xt=urn:btih:959A6A8EA8730CE8736EB839587C1CAA8FECC77F'}
2018-11-27 10:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20>
{'baidu': 'fight club ',
 'click': '169',
 'ctime': '2018-09-26',
 'fanyi': '',
 'filename': 'Fight.Club.1999.UHD.Re-Grade.6000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '104.9 GB',
 'link': 'magnet:?xt=urn:btih:6FA9CE5B9A08CAB64DC268B0512F950AC896569D'}
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4FC481642590C70E6DDDE18C1727457ECB02F902.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7F20772B573F2FB7C82C11F9D357911E4F5B9427.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/769B333547BF5B4C137D11FC3121CE1B23B604C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F661BD9AC3C06D4DA5E285A1172AE5890DF00A72.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20> (referer: None)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEA8AF04251AB2DE967407801EF8D19822FFC3C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5F7C8C25DD17B77A650D3DC2B002639A1B89C707.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20> (referer: None)
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20> (referer: None)
2018-11-27 10:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20>
{'baidu': 'corazones de acero ',
 'click': '80',
 'ctime': '2015-12-26',
 'fanyi': '',
 'filename': 'Corazones de Acero 2014 2160p 4K x265 HEVC WEB-DL DTSHD MA '
             'HDTeam.mkv',
 'length': '114.3 GB',
 'link': 'magnet:?xt=urn:btih:7F20772B573F2FB7C82C11F9D357911E4F5B9427'}
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F140154E9E81D99DF4ECFB7C676578426040D01F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20>
{'baidu': 'titanic ',
 'click': '736',
 'ctime': '2018-09-05',
 'fanyi': '',
 'filename': 'Titanic.1997.UHD.Remux.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '112.8 GB',
 'link': 'magnet:?xt=urn:btih:A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1'}
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20> (referer: None)
2018-11-27 10:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20>
{'baidu': 'the lord of the rings ',
 'click': '771',
 'ctime': '2018-09-17',
 'fanyi': '',
 'filename': 'The.Lord.of.the.Rings.2001.The.Fellowship.of.the.Ring.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '113.3 GB',
 'link': 'magnet:?xt=urn:btih:F661BD9AC3C06D4DA5E285A1172AE5890DF00A72'}
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14DA430E8D7F940A8E7781E476EE40BCDE92E721.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20>
{'baidu': 'jurassic park ',
 'click': '1272',
 'ctime': '2018-05-26',
 'fanyi': '',
 'filename': 'Jurassic.Park.1993.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '115.1 GB',
 'link': 'magnet:?xt=urn:btih:FEA8AF04251AB2DE967407801EF8D19822FFC3C0'}
2018-11-27 10:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9FE34633C5C5B9CC103B605513BA139808A3834A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/ED9D08819BF8A91BA6D0234ACB5A6D2032E62A8B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9AC91CD6C3521E591D85D25E3EC11C8A9925A47C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A57AE65752452CE57723908B7B7AE1E49BE33185.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B6525F8E9BD05A95C5D5D96294EB83E15A930C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A1F18A9201B070CBD50BA321C1BF461A4F5A91F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20> (referer: None)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0577E3A8CD391D8C3A273AC418C804E690D8035A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20> (referer: None)
2018-11-27 10:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20>
{'baidu': 'lawrence of arabia ',
 'click': '638',
 'ctime': '2016-09-23',
 'fanyi': '',
 'filename': 'Lawrence.of.Arabia.1962.2160p.WEB-DL.5xRus.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:9FE34633C5C5B9CC103B605513BA139808A3834A'}
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20> (referer: None)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F0CB71BAC2BD8470A16576F08AE8EF88DF3F2C40.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5484184C0C9BD8B2A6A7C7DCB22D222381D30C2C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20>
{'baidu': 'lawrence of arabia [ ] web-dl ',
 'click': '679',
 'ctime': '2018-06-25',
 'fanyi': '[la',
 'filename': 'Lawrence of Arabia [ ] WEB-DL 2160p.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:2A1F18A9201B070CBD50BA321C1BF461A4F5A91F'}
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EFF751D5A529715E3B9F2A9F98B02266D263E40B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20>
{'baidu': '       ',
 'click': '1063',
 'ctime': '2018-07-16',
 'fanyi': '',
 'filename': '  .   '
             '.2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '119.5 GB',
 'link': 'magnet:?xt=urn:btih:0577E3A8CD391D8C3A273AC418C804E690D8035A'}
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20> (referer: None)
2018-11-27 10:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20>
{'baidu': 'ghostbusters ',
 'click': '3458',
 'ctime': '2015-11-10',
 'fanyi': '',
 'filename': 'Ghostbusters.1984.2160p.WEB-DL.10xRus.3xUkr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '136.4 GB',
 'link': 'magnet:?xt=urn:btih:F0CB71BAC2BD8470A16576F08AE8EF88DF3F2C40'}
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6363D3550D86E1F94CF7BCE716F2A278F79E73FE.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D595F46390E2C51123CA8DD56891BE1EE2AE3226.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:34:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:34:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 25587,
 'downloader/request_count': 69,
 'downloader/request_method_count/GET': 69,
 'downloader/response_bytes': 126329,
 'downloader/response_count': 69,
 'downloader/response_status_count/200': 69,
 'dupefilter/filtered': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 34, 24, 896705),
 'item_scraped_count': 21,
 'log_count/DEBUG': 92,
 'log_count/INFO': 7,
 'memusage/max': 778694656,
 'memusage/startup': 778694656,
 'request_depth_max': 2,
 'response_received_count': 69,
 'scheduler/dequeued': 69,
 'scheduler/dequeued/memory': 69,
 'scheduler/enqueued': 69,
 'scheduler/enqueued/memory': 69,
 'start_time': datetime.datetime(2018, 11, 27, 2, 34, 19, 586008)}
2018-11-27 10:34:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 10:35:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 10:35:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic
2018-11-27 10:35:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 10:35:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 10:35:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 10:35:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 10:35:46 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 10:35:46 [scrapy.core.engine] INFO: Spider opened
2018-11-27 10:35:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 10:35:46 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 10:35:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_1.html> (referer: None)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14BD82A8A83A48F394177E36C2817F207DF15C52.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D595F46390E2C51123CA8DD56891BE1EE2AE3226.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20> (referer: None)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_2.html> (referer: None)
2018-11-27 10:35:48 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0577E3A8CD391D8C3A273AC418C804E690D8035A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20>
{'baidu': 'fury ',
 'click': '8',
 'ctime': '2016-07-07',
 'fanyi': '',
 'filename': 'Fury.2014.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '116.4 GB',
 'link': 'magnet:?xt=urn:btih:14BD82A8A83A48F394177E36C2817F207DF15C52'}
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/500F668900B36CD297D753729D5AD8073320777D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A1F18A9201B070CBD50BA321C1BF461A4F5A91F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B6525F8E9BD05A95C5D5D96294EB83E15A930C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20> (referer: None)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9FE34633C5C5B9CC103B605513BA139808A3834A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EFF751D5A529715E3B9F2A9F98B02266D263E40B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_3.html> (referer: None)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6363D3550D86E1F94CF7BCE716F2A278F79E73FE.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20>
{'baidu': '       ',
 'click': '1063',
 'ctime': '2018-07-16',
 'fanyi': '',
 'filename': '  .   '
             '.2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '119.5 GB',
 'link': 'magnet:?xt=urn:btih:0577E3A8CD391D8C3A273AC418C804E690D8035A'}
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20> (referer: None)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20> (referer: None)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5484184C0C9BD8B2A6A7C7DCB22D222381D30C2C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20>
{'baidu': 'lawrence of arabia ',
 'click': '84',
 'ctime': '2017-06-12',
 'fanyi': '',
 'filename': 'Lawrence.of.Arabia.1962.2160p.WEB-ULTRAHDCLUB.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:7B6525F8E9BD05A95C5D5D96294EB83E15A930C3'}
2018-11-27 10:35:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20>
{'baidu': 'lawrence of arabia [ ] web-dl ',
 'click': '679',
 'ctime': '2018-06-25',
 'fanyi': '[la',
 'filename': 'Lawrence of Arabia [ ] WEB-DL 2160p.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:2A1F18A9201B070CBD50BA321C1BF461A4F5A91F'}
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20> (referer: None)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F0CB71BAC2BD8470A16576F08AE8EF88DF3F2C40.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20>
{'baidu': 'ghostbusters ',
 'click': '81',
 'ctime': '2018-08-10',
 'fanyi': '',
 'filename': 'Ghostbusters.1984.2160p.WEB-DL.10xRus.3xUkr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '136.4 GB',
 'link': 'magnet:?xt=urn:btih:6363D3550D86E1F94CF7BCE716F2A278F79E73FE'}
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6FA9CE5B9A08CAB64DC268B0512F950AC896569D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/959A6A8EA8730CE8736EB839587C1CAA8FECC77F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5C0372A9D620AD2B87312408A8A32183F85E0F3B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/71B18BEF36AEA4319D804083C31CB98873C59BF4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/52CE23F4D532B12B80EC30A9D30D8A5370ACF00C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4FC481642590C70E6DDDE18C1727457ECB02F902.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20>
{'baidu': 'the bridge on the river kwai ',
 'click': '495',
 'ctime': '2017-04-03',
 'fanyi': 'The bridge on the ri',
 'filename': 'The.Bridge.on.the.River.Kwai.1957.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '107.2 GB',
 'link': 'magnet:?xt=urn:btih:B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A57AE65752452CE57723908B7B7AE1E49BE33185.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/ED9D08819BF8A91BA6D0234ACB5A6D2032E62A8B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20>
{'baidu': 'fight club ',
 'click': '169',
 'ctime': '2018-09-26',
 'fanyi': '',
 'filename': 'Fight.Club.1999.UHD.Re-Grade.6000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '104.9 GB',
 'link': 'magnet:?xt=urn:btih:6FA9CE5B9A08CAB64DC268B0512F950AC896569D'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6DFA4CED20D48D0E581E318B9EDC8B35D63FF8BD.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7413161D93646A9D4826F0E7B4B6D20190CC11D7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/69B886B35068D58A057B4462CF1BBBB36324B257.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20>
{'baidu': 'men in black ',
 'click': '873',
 'ctime': '2015-11-12',
 'fanyi': '',
 'filename': 'Men.in.Black.1997.2160p.WEB-DL.3xRus.Eng.mkv',
 'length': '109.3 GB',
 'link': 'magnet:?xt=urn:btih:959A6A8EA8730CE8736EB839587C1CAA8FECC77F'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5FD6172D4BBDF64BCE29D28BFD68D2DD9F49B704.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/32BC10297FB6165DC02DACF565CDD4A33E5A12F0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20>
{'baidu': 'saving private ryan ',
 'click': '1202',
 'ctime': '2018-05-11',
 'fanyi': '',
 'filename': 'Saving.Private.Ryan.1998.2160p.BDREMUX.HEVC.HDR.IVA(11xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '104.2 GB',
 'link': 'magnet:?xt=urn:btih:5C0372A9D620AD2B87312408A8A32183F85E0F3B'}
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20>
{'baidu': 'the fifth element ',
 'click': '3536',
 'ctime': '2015-12-01',
 'fanyi': '',
 'filename': 'The.Fifth.Element.1997.2160p.WEB-DL.2xRus.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '90.8 GB',
 'link': 'magnet:?xt=urn:btih:0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2845E8EABB19306AA52C7363EF4FB53B0792217E.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3B68E98EC4522D7A2C3DAE1614BB32D3E8A41155.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10093BA1F1E86658D0EC39708CF1E097AA83DB02.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/769B333547BF5B4C137D11FC3121CE1B23B604C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_>
{'baidu': 'aliens_',
 'click': '165',
 'ctime': '2018-05-28',
 'fanyi': 'aliens_',
 'filename': 'Aliens_1986_Directors_Cut_2160p_4K_SDR_WEB-DL_AMZ_HHD.mkv',
 'length': '94.4 GB',
 'link': 'magnet:?xt=urn:btih:69B886B35068D58A057B4462CF1BBBB36324B257'}
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20>
{'baidu': 'forrest gump ',
 'click': '1878',
 'ctime': '2018-06-13',
 'fanyi': '',
 'filename': 'Forrest.Gump.1994.UHD.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '91.9 GB',
 'link': 'magnet:?xt=urn:btih:7413161D93646A9D4826F0E7B4B6D20190CC11D7'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20> (referer: None)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20>
{'baidu': 'avatar ',
 'click': '3',
 'ctime': '2018-11-26',
 'fanyi': '',
 'filename': 'Avatar.2009.Extended.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.mkv',
 'length': '101.9 GB',
 'link': 'magnet:?xt=urn:btih:A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14DA430E8D7F940A8E7781E476EE40BCDE92E721.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20>
{'baidu': 'watchmen ',
 'click': '1951',
 'ctime': '2018-04-24',
 'fanyi': '',
 'filename': 'Watchmen.2009.The.Ultimate.Cut.UHD.BDRemux.2160p.HEVC.HDR.IVA(4xRUS.ENG).ExKinoRay.mkv',
 'length': '95.7 GB',
 'link': 'magnet:?xt=urn:btih:2845E8EABB19306AA52C7363EF4FB53B0792217E'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E95E20C81EC198FD2E1E4A8C1E532E439CB642C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20>
{'baidu': "my best friend's wedding ",
 'click': '356',
 'ctime': '2015-10-30',
 'fanyi': '',
 'filename': "My.Best.Friend's.Wedding.1997.2160p.WEB-DL.2xRus.2xUkr.Eng-TrollUHD-ULTRAHDCLUB.mkv",
 'length': '100.5 GB',
 'link': 'magnet:?xt=urn:btih:32BC10297FB6165DC02DACF565CDD4A33E5A12F0'}
2018-11-27 10:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F140154E9E81D99DF4ECFB7C676578426040D01F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F661BD9AC3C06D4DA5E285A1172AE5890DF00A72.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6EEE5ED342EC9E10293C4EEDEBCCF311BF9E4CB3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20> (referer: None)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9BFF492E9E81B0DFF2FBAC8D66E258F5C62A7A7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DEFC01CE8510988F00615C02E41F175F1DEB3C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEA8AF04251AB2DE967407801EF8D19822FFC3C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20> (referer: None)
2018-11-27 10:35:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20>
{'baidu': 'ghostbusters ii ',
 'click': '720',
 'ctime': '2017-04-17',
 'fanyi': '2',
 'filename': 'Ghostbusters.II.1989.2160p.WEB-DL.8xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '103.9 GB',
 'link': 'magnet:?xt=urn:btih:E95E20C81EC198FD2E1E4A8C1E532E439CB642C0'}
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7F20772B573F2FB7C82C11F9D357911E4F5B9427.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9AC91CD6C3521E591D85D25E3EC11C8A9925A47C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20> (referer: None)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5F7C8C25DD17B77A650D3DC2B002639A1B89C707.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 10:35:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20>
{'baidu': 'titanic ',
 'click': '736',
 'ctime': '2018-09-05',
 'fanyi': '',
 'filename': 'Titanic.1997.UHD.Remux.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '112.8 GB',
 'link': 'magnet:?xt=urn:btih:A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1'}
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20> (referer: None)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0D1F01478B2FBD42447E12DBD8512380D4EDC04F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20>
{'baidu': 'the lord of the rings ',
 'click': '771',
 'ctime': '2018-09-17',
 'fanyi': '',
 'filename': 'The.Lord.of.the.Rings.2001.The.Fellowship.of.the.Ring.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '113.3 GB',
 'link': 'magnet:?xt=urn:btih:F661BD9AC3C06D4DA5E285A1172AE5890DF00A72'}
2018-11-27 10:35:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20>
{'baidu': 'jurassic park ',
 'click': '1272',
 'ctime': '2018-05-26',
 'fanyi': '',
 'filename': 'Jurassic.Park.1993.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '115.1 GB',
 'link': 'magnet:?xt=urn:btih:FEA8AF04251AB2DE967407801EF8D19822FFC3C0'}
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4A5C7ACA043648109EA55D452D5E779B53196757.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20> (referer: None)
2018-11-27 10:35:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20>
{'baidu': 'corazones de acero ',
 'click': '80',
 'ctime': '2015-12-26',
 'fanyi': '',
 'filename': 'Corazones de Acero 2014 2160p 4K x265 HEVC WEB-DL DTSHD MA '
             'HDTeam.mkv',
 'length': '114.3 GB',
 'link': 'magnet:?xt=urn:btih:7F20772B573F2FB7C82C11F9D357911E4F5B9427'}
2018-11-27 10:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20> (referer: None)
2018-11-27 10:35:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20>
{'baidu': 'the lost world jurassic park ',
 'click': '1224',
 'ctime': '2018-05-25',
 'fanyi': '',
 'filename': 'The.Lost.World.Jurassic.Park.1997.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.3xUKR.ENG).ExKinoRay.mkv',
 'length': '99.7 GB',
 'link': 'magnet:?xt=urn:btih:0D1F01478B2FBD42447E12DBD8512380D4EDC04F'}
2018-11-27 10:35:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 10:35:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 25663,
 'downloader/request_count': 69,
 'downloader/request_method_count/GET': 69,
 'downloader/response_bytes': 125979,
 'downloader/response_count': 69,
 'downloader/response_status_count/200': 69,
 'dupefilter/filtered': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 2, 35, 50, 541445),
 'item_scraped_count': 21,
 'log_count/DEBUG': 92,
 'log_count/INFO': 7,
 'memusage/max': 785805312,
 'memusage/startup': 785805312,
 'request_depth_max': 2,
 'response_received_count': 69,
 'scheduler/dequeued': 69,
 'scheduler/dequeued/memory': 69,
 'scheduler/enqueued': 69,
 'scheduler/enqueued/memory': 69,
 'start_time': datetime.datetime(2018, 11, 27, 2, 35, 46, 315009)}
2018-11-27 10:35:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 15:55:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 15:55:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-27 15:55:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 15:55:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 15:55:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 15:55:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 15:55:03 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 15:55:03 [scrapy.core.engine] INFO: Spider opened
2018-11-27 15:55:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 15:55:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 15:55:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.so/search/2160p%20mkv_length_2.html> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl23_read', 'ssl handshake failure')]>]
2018-11-27 15:55:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_1.html> (referer: None)
2018-11-27 15:55:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9FE34633C5C5B9CC103B605513BA139808A3834A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EFF751D5A529715E3B9F2A9F98B02266D263E40B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_2.html> (referer: None)
2018-11-27 15:55:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20> (referer: None)
2018-11-27 15:55:15 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-27 15:55:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.so/search/2160p%20mkv_length_3.html> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl23_read', 'ssl handshake failure')]>]
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6363D3550D86E1F94CF7BCE716F2A278F79E73FE.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20>
{'baidu': 'lawrence of arabia ',
 'click': '638',
 'ctime': '2016-09-23',
 'fanyi': '',
 'filename': 'Lawrence.of.Arabia.1962.2160p.WEB-DL.5xRus.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:9FE34633C5C5B9CC103B605513BA139808A3834A'}
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14DA430E8D7F940A8E7781E476EE40BCDE92E721.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20> (referer: None)
2018-11-27 15:55:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20>
{'baidu': 'ghostbusters ',
 'click': '81',
 'ctime': '2018-08-10',
 'fanyi': '',
 'filename': 'Ghostbusters.1984.2160p.WEB-DL.10xRus.3xUkr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '136.4 GB',
 'link': 'magnet:?xt=urn:btih:6363D3550D86E1F94CF7BCE716F2A278F79E73FE'}
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/500F668900B36CD297D753729D5AD8073320777D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B6525F8E9BD05A95C5D5D96294EB83E15A930C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20> (referer: None)
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0577E3A8CD391D8C3A273AC418C804E690D8035A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14BD82A8A83A48F394177E36C2817F207DF15C52.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20>
{'baidu': 'fury ',
 'click': '4978',
 'ctime': '2015-10-17',
 'fanyi': '',
 'filename': 'Fury.2014.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '116.4 GB',
 'link': 'magnet:?xt=urn:btih:14DA430E8D7F940A8E7781E476EE40BCDE92E721'}
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5484184C0C9BD8B2A6A7C7DCB22D222381D30C2C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6DFA4CED20D48D0E581E318B9EDC8B35D63FF8BD.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20> (referer: None)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F140154E9E81D99DF4ECFB7C676578426040D01F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20>
{'baidu': '       ',
 'click': '1063',
 'ctime': '2018-07-16',
 'fanyi': '',
 'filename': '  .   '
             '.2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '119.5 GB',
 'link': 'magnet:?xt=urn:btih:0577E3A8CD391D8C3A273AC418C804E690D8035A'}
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/71B18BEF36AEA4319D804083C31CB98873C59BF4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20> (referer: None)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/959A6A8EA8730CE8736EB839587C1CAA8FECC77F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/ED9D08819BF8A91BA6D0234ACB5A6D2032E62A8B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20>
{'baidu': 'the bridge on the river kwai ',
 'click': '495',
 'ctime': '2017-04-03',
 'fanyi': '',
 'filename': 'The.Bridge.on.the.River.Kwai.1957.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '107.2 GB',
 'link': 'magnet:?xt=urn:btih:B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2'}
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6FA9CE5B9A08CAB64DC268B0512F950AC896569D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4FC481642590C70E6DDDE18C1727457ECB02F902.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> (referer: None)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5C0372A9D620AD2B87312408A8A32183F85E0F3B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_3.html> (referer: None)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F0CB71BAC2BD8470A16576F08AE8EF88DF3F2C40.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20>
{'baidu': 'men in black ',
 'click': '873',
 'ctime': '2015-11-12',
 'fanyi': '',
 'filename': 'Men.in.Black.1997.2160p.WEB-DL.3xRus.Eng.mkv',
 'length': '109.3 GB',
 'link': 'magnet:?xt=urn:btih:959A6A8EA8730CE8736EB839587C1CAA8FECC77F'}
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20> (referer: None)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/769B333547BF5B4C137D11FC3121CE1B23B604C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20> (referer: None)
2018-11-27 15:55:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20>
{'baidu': 'fight club ',
 'click': '169',
 'ctime': '2018-09-26',
 'fanyi': '',
 'filename': 'Fight.Club.1999.UHD.Re-Grade.6000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '104.9 GB',
 'link': 'magnet:?xt=urn:btih:6FA9CE5B9A08CAB64DC268B0512F950AC896569D'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7F20772B573F2FB7C82C11F9D357911E4F5B9427.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20>
{'baidu': 'saving private ryan ',
 'click': '1202',
 'ctime': '2018-05-11',
 'fanyi': '',
 'filename': 'Saving.Private.Ryan.1998.2160p.BDREMUX.HEVC.HDR.IVA(11xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '104.2 GB',
 'link': 'magnet:?xt=urn:btih:5C0372A9D620AD2B87312408A8A32183F85E0F3B'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEA8AF04251AB2DE967407801EF8D19822FFC3C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F661BD9AC3C06D4DA5E285A1172AE5890DF00A72.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20> (referer: None)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20> (referer: None)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20>
{'baidu': 'corazones de acero ',
 'click': '80',
 'ctime': '2015-12-26',
 'fanyi': '',
 'filename': 'Corazones de Acero 2014 2160p 4K x265 HEVC WEB-DL DTSHD MA '
             'HDTeam.mkv',
 'length': '114.3 GB',
 'link': 'magnet:?xt=urn:btih:7F20772B573F2FB7C82C11F9D357911E4F5B9427'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20>
{'baidu': 'jurassic park ',
 'click': '1272',
 'ctime': '2018-05-26',
 'fanyi': '',
 'filename': 'Jurassic.Park.1993.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '115.1 GB',
 'link': 'magnet:?xt=urn:btih:FEA8AF04251AB2DE967407801EF8D19822FFC3C0'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7413161D93646A9D4826F0E7B4B6D20190CC11D7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20> (referer: None)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5F7C8C25DD17B77A650D3DC2B002639A1B89C707.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A57AE65752452CE57723908B7B7AE1E49BE33185.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20> (referer: None)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/52CE23F4D532B12B80EC30A9D30D8A5370ACF00C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20>
{'baidu': 'titanic ',
 'click': '736',
 'ctime': '2018-09-05',
 'fanyi': '',
 'filename': 'Titanic.1997.UHD.Remux.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '112.8 GB',
 'link': 'magnet:?xt=urn:btih:A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/69B886B35068D58A057B4462CF1BBBB36324B257.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20>
{'baidu': 'the lord of the rings ',
 'click': '771',
 'ctime': '2018-09-17',
 'fanyi': '',
 'filename': 'The.Lord.of.the.Rings.2001.The.Fellowship.of.the.Ring.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '113.3 GB',
 'link': 'magnet:?xt=urn:btih:F661BD9AC3C06D4DA5E285A1172AE5890DF00A72'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20> (referer: None)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20> (referer: None)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2845E8EABB19306AA52C7363EF4FB53B0792217E.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20>
{'baidu': 'forrest gump ',
 'click': '1878',
 'ctime': '2018-06-13',
 'fanyi': '',
 'filename': 'Forrest.Gump.1994.UHD.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '91.9 GB',
 'link': 'magnet:?xt=urn:btih:7413161D93646A9D4826F0E7B4B6D20190CC11D7'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_> (referer: None)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20>
{'baidu': 'the fifth element ',
 'click': '3536',
 'ctime': '2015-12-01',
 'fanyi': '',
 'filename': 'The.Fifth.Element.1997.2160p.WEB-DL.2xRus.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '90.8 GB',
 'link': 'magnet:?xt=urn:btih:0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5FD6172D4BBDF64BCE29D28BFD68D2DD9F49B704.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20> (referer: None)
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_>
{'baidu': 'aliens_',
 'click': '165',
 'ctime': '2018-05-28',
 'fanyi': 'aliens_',
 'filename': 'Aliens_1986_Directors_Cut_2160p_4K_SDR_WEB-DL_AMZ_HHD.mkv',
 'length': '94.4 GB',
 'link': 'magnet:?xt=urn:btih:69B886B35068D58A057B4462CF1BBBB36324B257'}
2018-11-27 15:55:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20>
{'baidu': 'watchmen ',
 'click': '1951',
 'ctime': '2018-04-24',
 'fanyi': '',
 'filename': 'Watchmen.2009.The.Ultimate.Cut.UHD.BDRemux.2160p.HEVC.HDR.IVA(4xRUS.ENG).ExKinoRay.mkv',
 'length': '95.7 GB',
 'link': 'magnet:?xt=urn:btih:2845E8EABB19306AA52C7363EF4FB53B0792217E'}
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9AC91CD6C3521E591D85D25E3EC11C8A9925A47C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3B68E98EC4522D7A2C3DAE1614BB32D3E8A41155.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/32BC10297FB6165DC02DACF565CDD4A33E5A12F0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10093BA1F1E86658D0EC39708CF1E097AA83DB02.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20> (referer: None)
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E95E20C81EC198FD2E1E4A8C1E532E439CB642C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DEFC01CE8510988F00615C02E41F175F1DEB3C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9BFF492E9E81B0DFF2FBAC8D66E258F5C62A7A7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20>
{'baidu': 'avatar ',
 'click': '1905',
 'ctime': '2018-09-12',
 'fanyi': '',
 'filename': 'Avatar.2009.Extended.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '101.9 GB',
 'link': 'magnet:?xt=urn:btih:3B68E98EC4522D7A2C3DAE1614BB32D3E8A41155'}
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20> (referer: None)
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4A5C7ACA043648109EA55D452D5E779B53196757.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20> (referer: None)
2018-11-27 15:55:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20>
{'baidu': "my best friend's wedding ",
 'click': '356',
 'ctime': '2015-10-30',
 'fanyi': '',
 'filename': "My.Best.Friend's.Wedding.1997.2160p.WEB-DL.2xRus.2xUkr.Eng-TrollUHD-ULTRAHDCLUB.mkv",
 'length': '100.5 GB',
 'link': 'magnet:?xt=urn:btih:32BC10297FB6165DC02DACF565CDD4A33E5A12F0'}
2018-11-27 15:55:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20>
{'baidu': 'ghostbusters ii ',
 'click': '720',
 'ctime': '2017-04-17',
 'fanyi': '2',
 'filename': 'Ghostbusters.II.1989.2160p.WEB-DL.8xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '103.9 GB',
 'link': 'magnet:?xt=urn:btih:E95E20C81EC198FD2E1E4A8C1E532E439CB642C0'}
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0D1F01478B2FBD42447E12DBD8512380D4EDC04F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20> (referer: None)
2018-11-27 15:55:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20>
{'baidu': 'the lost world jurassic park ',
 'click': '1224',
 'ctime': '2018-05-25',
 'fanyi': '',
 'filename': 'The.Lost.World.Jurassic.Park.1997.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.3xUKR.ENG).ExKinoRay.mkv',
 'length': '99.7 GB',
 'link': 'magnet:?xt=urn:btih:0D1F01478B2FBD42447E12DBD8512380D4EDC04F'}
2018-11-27 15:55:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6EEE5ED342EC9E10293C4EEDEBCCF311BF9E4CB3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 15:55:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D595F46390E2C51123CA8DD56891BE1EE2AE3226.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.bturl.so/2A1F18A9201B070CBD50BA321C1BF461A4F5A91F.html> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl23_read', 'ssl handshake failure')]>]
2018-11-27 15:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A1F18A9201B070CBD50BA321C1BF461A4F5A91F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 15:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20> (referer: None)
2018-11-27 15:55:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20>
{'baidu': 'lawrence of arabia [ ] web-dl ',
 'click': '679',
 'ctime': '2018-06-25',
 'fanyi': '[la',
 'filename': 'Lawrence of Arabia [ ] WEB-DL 2160p.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:2A1F18A9201B070CBD50BA321C1BF461A4F5A91F'}
2018-11-27 15:55:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 15:55:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 26593,
 'downloader/request_count': 72,
 'downloader/request_method_count/GET': 72,
 'downloader/response_bytes': 125822,
 'downloader/response_count': 69,
 'downloader/response_status_count/200': 69,
 'dupefilter/filtered': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 7, 55, 31, 681603),
 'item_scraped_count': 21,
 'log_count/DEBUG': 95,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 69,
 'retry/count': 3,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'scheduler/dequeued': 72,
 'scheduler/dequeued/memory': 72,
 'scheduler/enqueued': 72,
 'scheduler/enqueued/memory': 72,
 'start_time': datetime.datetime(2018, 11, 27, 7, 55, 4, 2916)}
2018-11-27 15:55:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 16:04:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 16:04:06 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-27 16:04:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 16:04:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 16:04:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 16:04:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 16:04:06 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 16:04:06 [scrapy.core.engine] INFO: Spider opened
2018-11-27 16:04:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 16:04:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 16:04:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_2.html> (referer: None)
2018-11-27 16:04:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5C0372A9D620AD2B87312408A8A32183F85E0F3B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4FC481642590C70E6DDDE18C1727457ECB02F902.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/959A6A8EA8730CE8736EB839587C1CAA8FECC77F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/71B18BEF36AEA4319D804083C31CB98873C59BF4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> (referer: None)
2018-11-27 16:04:09 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/769B333547BF5B4C137D11FC3121CE1B23B604C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20>
{'baidu': 'saving private ryan ',
 'click': '1202',
 'ctime': '2018-05-11',
 'fanyi': '',
 'filename': 'Saving.Private.Ryan.1998.2160p.BDREMUX.HEVC.HDR.IVA(11xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '104.2 GB',
 'link': 'magnet:?xt=urn:btih:5C0372A9D620AD2B87312408A8A32183F85E0F3B'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F661BD9AC3C06D4DA5E285A1172AE5890DF00A72.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20>
{'baidu': 'men in black ',
 'click': '711',
 'ctime': '2016-09-17',
 'fanyi': '',
 'filename': 'Men.in.Black.1997.2160p.WEB-DL.6xRus.3xEng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '111.6 GB',
 'link': 'magnet:?xt=urn:btih:4FC481642590C70E6DDDE18C1727457ECB02F902'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_3.html> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7F20772B573F2FB7C82C11F9D357911E4F5B9427.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20>
{'baidu': 'the bridge on the river kwai ',
 'click': '495',
 'ctime': '2017-04-03',
 'fanyi': '',
 'filename': 'The.Bridge.on.the.River.Kwai.1957.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '107.2 GB',
 'link': 'magnet:?xt=urn:btih:B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEA8AF04251AB2DE967407801EF8D19822FFC3C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/52CE23F4D532B12B80EC30A9D30D8A5370ACF00C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5F7C8C25DD17B77A650D3DC2B002639A1B89C707.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20>
{'baidu': 'titanic ',
 'click': '736',
 'ctime': '2018-09-05',
 'fanyi': '',
 'filename': 'Titanic.1997.UHD.Remux.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '112.8 GB',
 'link': 'magnet:?xt=urn:btih:A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20>
{'baidu': 'the lord of the rings ',
 'click': '771',
 'ctime': '2018-09-17',
 'fanyi': '',
 'filename': 'The.Lord.of.the.Rings.2001.The.Fellowship.of.the.Ring.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '113.3 GB',
 'link': 'magnet:?xt=urn:btih:F661BD9AC3C06D4DA5E285A1172AE5890DF00A72'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9AC91CD6C3521E591D85D25E3EC11C8A9925A47C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20>
{'baidu': 'jurassic park ',
 'click': '1272',
 'ctime': '2018-05-26',
 'fanyi': '',
 'filename': 'Jurassic.Park.1993.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '115.1 GB',
 'link': 'magnet:?xt=urn:btih:FEA8AF04251AB2DE967407801EF8D19822FFC3C0'}
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20>
{'baidu': 'corazones de acero ',
 'click': '80',
 'ctime': '2015-12-26',
 'fanyi': '',
 'filename': 'Corazones de Acero 2014 2160p 4K x265 HEVC WEB-DL DTSHD MA '
             'HDTeam.mkv',
 'length': '114.3 GB',
 'link': 'magnet:?xt=urn:btih:7F20772B573F2FB7C82C11F9D357911E4F5B9427'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6FA9CE5B9A08CAB64DC268B0512F950AC896569D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7413161D93646A9D4826F0E7B4B6D20190CC11D7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A57AE65752452CE57723908B7B7AE1E49BE33185.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20>
{'baidu': 'fury ',
 'click': '2993',
 'ctime': '2016-08-05',
 'fanyi': '',
 'filename': 'Fury 2014 VFF 2160p UHD 4K DTS-HD MA HEVC-HDHEVC.mkv',
 'length': '111.0 GB',
 'link': 'magnet:?xt=urn:btih:52CE23F4D532B12B80EC30A9D30D8A5370ACF00C'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/69B886B35068D58A057B4462CF1BBBB36324B257.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0D1F01478B2FBD42447E12DBD8512380D4EDC04F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/32BC10297FB6165DC02DACF565CDD4A33E5A12F0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20>
{'baidu': 'the fifth element ',
 'click': '3536',
 'ctime': '2015-12-01',
 'fanyi': '',
 'filename': 'The.Fifth.Element.1997.2160p.WEB-DL.2xRus.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '90.8 GB',
 'link': 'magnet:?xt=urn:btih:0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC'}
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20>
{'baidu': 'fight club ',
 'click': '169',
 'ctime': '2018-09-26',
 'fanyi': '',
 'filename': 'Fight.Club.1999.UHD.Re-Grade.6000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '104.9 GB',
 'link': 'magnet:?xt=urn:btih:6FA9CE5B9A08CAB64DC268B0512F950AC896569D'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_>
{'baidu': 'aliens_',
 'click': '165',
 'ctime': '2018-05-28',
 'fanyi': 'aliens_',
 'filename': 'Aliens_1986_Directors_Cut_2160p_4K_SDR_WEB-DL_AMZ_HHD.mkv',
 'length': '94.4 GB',
 'link': 'magnet:?xt=urn:btih:69B886B35068D58A057B4462CF1BBBB36324B257'}
2018-11-27 16:04:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20>
{'baidu': 'forrest gump ',
 'click': '1878',
 'ctime': '2018-06-13',
 'fanyi': '',
 'filename': 'Forrest.Gump.1994.UHD.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '91.9 GB',
 'link': 'magnet:?xt=urn:btih:7413161D93646A9D4826F0E7B4B6D20190CC11D7'}
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3B68E98EC4522D7A2C3DAE1614BB32D3E8A41155.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DEFC01CE8510988F00615C02E41F175F1DEB3C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9BFF492E9E81B0DFF2FBAC8D66E258F5C62A7A7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20> (referer: None)
2018-11-27 16:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5FD6172D4BBDF64BCE29D28BFD68D2DD9F49B704.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20>
{'baidu': 'the lost world jurassic park ',
 'click': '1224',
 'ctime': '2018-05-25',
 'fanyi': '',
 'filename': 'The.Lost.World.Jurassic.Park.1997.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.3xUKR.ENG).ExKinoRay.mkv',
 'length': '99.7 GB',
 'link': 'magnet:?xt=urn:btih:0D1F01478B2FBD42447E12DBD8512380D4EDC04F'}
2018-11-27 16:04:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20>
{'baidu': "my best friend's wedding ",
 'click': '356',
 'ctime': '2015-10-30',
 'fanyi': '',
 'filename': "My.Best.Friend's.Wedding.1997.2160p.WEB-DL.2xRus.2xUkr.Eng-TrollUHD-ULTRAHDCLUB.mkv",
 'length': '100.5 GB',
 'link': 'magnet:?xt=urn:btih:32BC10297FB6165DC02DACF565CDD4A33E5A12F0'}
2018-11-27 16:04:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20>
{'baidu': 'avatar ',
 'click': '3',
 'ctime': '2018-11-26',
 'fanyi': '',
 'filename': 'Avatar.2009.Extended.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.mkv',
 'length': '101.9 GB',
 'link': 'magnet:?xt=urn:btih:A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4'}
2018-11-27 16:04:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6EEE5ED342EC9E10293C4EEDEBCCF311BF9E4CB3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20> (referer: None)
2018-11-27 16:04:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20>
{'baidu': 'ghostbusters ii ',
 'click': '1551',
 'ctime': '2015-11-27',
 'fanyi': '2',
 'filename': 'Ghostbusters.II.1989.2160p.WEB-DL.8xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '103.9 GB',
 'link': 'magnet:?xt=urn:btih:5DEFC01CE8510988F00615C02E41F175F1DEB3C3'}
2018-11-27 16:04:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4A5C7ACA043648109EA55D452D5E779B53196757.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10093BA1F1E86658D0EC39708CF1E097AA83DB02.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E95E20C81EC198FD2E1E4A8C1E532E439CB642C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2845E8EABB19306AA52C7363EF4FB53B0792217E.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 16:04:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20> (referer: None)
2018-11-27 16:04:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20>
{'baidu': 'watchmen ',
 'click': '1951',
 'ctime': '2018-04-24',
 'fanyi': '',
 'filename': 'Watchmen.2009.The.Ultimate.Cut.UHD.BDRemux.2160p.HEVC.HDR.IVA(4xRUS.ENG).ExKinoRay.mkv',
 'length': '95.7 GB',
 'link': 'magnet:?xt=urn:btih:2845E8EABB19306AA52C7363EF4FB53B0792217E'}
2018-11-27 16:04:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_1.html> (referer: None)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14DA430E8D7F940A8E7781E476EE40BCDE92E721.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6DFA4CED20D48D0E581E318B9EDC8B35D63FF8BD.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0577E3A8CD391D8C3A273AC418C804E690D8035A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14BD82A8A83A48F394177E36C2817F207DF15C52.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B6525F8E9BD05A95C5D5D96294EB83E15A930C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/500F668900B36CD297D753729D5AD8073320777D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A1F18A9201B070CBD50BA321C1BF461A4F5A91F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9FE34633C5C5B9CC103B605513BA139808A3834A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EFF751D5A529715E3B9F2A9F98B02266D263E40B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6363D3550D86E1F94CF7BCE716F2A278F79E73FE.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20> (referer: None)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F0CB71BAC2BD8470A16576F08AE8EF88DF3F2C40.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5484184C0C9BD8B2A6A7C7DCB22D222381D30C2C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20>
{'baidu': 'lawrence of arabia ',
 'click': '84',
 'ctime': '2017-06-12',
 'fanyi': '',
 'filename': 'Lawrence.of.Arabia.1962.2160p.WEB-ULTRAHDCLUB.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:7B6525F8E9BD05A95C5D5D96294EB83E15A930C3'}
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20> (referer: None)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D595F46390E2C51123CA8DD56891BE1EE2AE3226.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20> (referer: None)
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/ED9D08819BF8A91BA6D0234ACB5A6D2032E62A8B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20>
{'baidu': 'lawrence of arabia [ ] web-dl ',
 'click': '679',
 'ctime': '2018-06-25',
 'fanyi': '[la',
 'filename': 'Lawrence of Arabia [ ] WEB-DL 2160p.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:2A1F18A9201B070CBD50BA321C1BF461A4F5A91F'}
2018-11-27 16:04:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20>
{'baidu': 'ghostbusters ',
 'click': '81',
 'ctime': '2018-08-10',
 'fanyi': '',
 'filename': 'Ghostbusters.1984.2160p.WEB-DL.10xRus.3xUkr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '136.4 GB',
 'link': 'magnet:?xt=urn:btih:6363D3550D86E1F94CF7BCE716F2A278F79E73FE'}
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20> (referer: None)
2018-11-27 16:04:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20>
{'baidu': '       ',
 'click': '1063',
 'ctime': '2018-07-16',
 'fanyi': '',
 'filename': '  .   '
             '.2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '119.5 GB',
 'link': 'magnet:?xt=urn:btih:0577E3A8CD391D8C3A273AC418C804E690D8035A'}
2018-11-27 16:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F140154E9E81D99DF4ECFB7C676578426040D01F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 16:04:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 16:04:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 25663,
 'downloader/request_count': 69,
 'downloader/request_method_count/GET': 69,
 'downloader/response_bytes': 125971,
 'downloader/response_count': 69,
 'downloader/response_status_count/200': 69,
 'dupefilter/filtered': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 8, 4, 14, 938570),
 'item_scraped_count': 21,
 'log_count/DEBUG': 92,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 69,
 'scheduler/dequeued': 69,
 'scheduler/dequeued/memory': 69,
 'scheduler/enqueued': 69,
 'scheduler/enqueued/memory': 69,
 'start_time': datetime.datetime(2018, 11, 27, 8, 4, 6, 496758)}
2018-11-27 16:04:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 17:08:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 17:08:47 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-27 17:08:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 17:08:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 17:08:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 17:08:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 17:08:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 17:08:48 [scrapy.core.engine] INFO: Spider opened
2018-11-27 17:08:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 17:08:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 17:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_3.html> (referer: None)
2018-11-27 17:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_1.html> (referer: None)
2018-11-27 17:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7413161D93646A9D4826F0E7B4B6D20190CC11D7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/69B886B35068D58A057B4462CF1BBBB36324B257.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20> (referer: None)
2018-11-27 17:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p%20mkv_length_2.html> (referer: None)
2018-11-27 17:08:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=forrest%20gump%20>
{'baidu': 'forrest gump ',
 'click': '1878',
 'ctime': '2018-06-13',
 'fanyi': '',
 'filename': 'Forrest.Gump.1994.UHD.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '91.9 GB',
 'link': 'magnet:?xt=urn:btih:7413161D93646A9D4826F0E7B4B6D20190CC11D7'}
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E95E20C81EC198FD2E1E4A8C1E532E439CB642C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_> (referer: None)
2018-11-27 17:08:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=aliens_>
{'baidu': 'aliens_',
 'click': '165',
 'ctime': '2018-05-28',
 'fanyi': 'aliens_',
 'filename': 'Aliens_1986_Directors_Cut_2160p_4K_SDR_WEB-DL_AMZ_HHD.mkv',
 'length': '94.4 GB',
 'link': 'magnet:?xt=urn:btih:69B886B35068D58A057B4462CF1BBBB36324B257'}
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C9BFF492E9E81B0DFF2FBAC8D66E258F5C62A7A7.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20> (referer: None)
2018-11-27 17:08:50 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20> (referer: None)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6EEE5ED342EC9E10293C4EEDEBCCF311BF9E4CB3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20ii%20>
{'baidu': 'ghostbusters ii ',
 'click': '720',
 'ctime': '2017-04-17',
 'fanyi': '2',
 'filename': 'Ghostbusters.II.1989.2160p.WEB-DL.8xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '103.9 GB',
 'link': 'magnet:?xt=urn:btih:E95E20C81EC198FD2E1E4A8C1E532E439CB642C0'}
2018-11-27 17:08:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=avatar%20>
{'baidu': 'avatar ',
 'click': '3',
 'ctime': '2018-11-26',
 'fanyi': '',
 'filename': 'Avatar.2009.Extended.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.mkv',
 'length': '101.9 GB',
 'link': 'magnet:?xt=urn:btih:A3D5E913796B2D44ED5BA5B68F6FDDB3CA0545D4'}
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2845E8EABB19306AA52C7363EF4FB53B0792217E.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4A5C7ACA043648109EA55D452D5E779B53196757.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5FD6172D4BBDF64BCE29D28BFD68D2DD9F49B704.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3B68E98EC4522D7A2C3DAE1614BB32D3E8A41155.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20> (referer: None)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5DEFC01CE8510988F00615C02E41F175F1DEB3C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/10093BA1F1E86658D0EC39708CF1E097AA83DB02.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/500F668900B36CD297D753729D5AD8073320777D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20> (referer: None)
2018-11-27 17:08:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=saving%20private%20ryan%20>
{'baidu': 'saving private ryan ',
 'click': '5',
 'ctime': '2018-10-05',
 'fanyi': '',
 'filename': 'Saving.Private.Ryan.1998.2160p.BDREMUX.HEVC.HDR.IVA(11xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '104.2 GB',
 'link': 'magnet:?xt=urn:btih:6EEE5ED342EC9E10293C4EEDEBCCF311BF9E4CB3'}
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14BD82A8A83A48F394177E36C2817F207DF15C52.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5C0372A9D620AD2B87312408A8A32183F85E0F3B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6FA9CE5B9A08CAB64DC268B0512F950AC896569D.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=watchmen%20>
{'baidu': 'watchmen ',
 'click': '1951',
 'ctime': '2018-04-24',
 'fanyi': '',
 'filename': 'Watchmen.2009.The.Ultimate.Cut.UHD.BDRemux.2160p.HEVC.HDR.IVA(4xRUS.ENG).ExKinoRay.mkv',
 'length': '95.7 GB',
 'link': 'magnet:?xt=urn:btih:2845E8EABB19306AA52C7363EF4FB53B0792217E'}
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20> (referer: None)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20> (referer: None)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/32BC10297FB6165DC02DACF565CDD4A33E5A12F0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=my%20best%20friend%27s%20wedding%20>
{'baidu': "my best friend's wedding ",
 'click': '985',
 'ctime': '2017-03-30',
 'fanyi': '',
 'filename': "My.Best.Friend's.Wedding.1997.2160p.WEB-DL.2xRus.2xUkr.Eng.mkv",
 'length': '100.5 GB',
 'link': 'magnet:?xt=urn:btih:10093BA1F1E86658D0EC39708CF1E097AA83DB02'}
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/959A6A8EA8730CE8736EB839587C1CAA8FECC77F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/52CE23F4D532B12B80EC30A9D30D8A5370ACF00C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fury%20>
{'baidu': 'fury ',
 'click': '245',
 'ctime': '2016-05-15',
 'fanyi': '',
 'filename': 'Fury.2014.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '116.4 GB',
 'link': 'magnet:?xt=urn:btih:500F668900B36CD297D753729D5AD8073320777D'}
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20> (referer: None)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20> (referer: None)
2018-11-27 17:08:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4FC481642590C70E6DDDE18C1727457ECB02F902.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A57AE65752452CE57723908B7B7AE1E49BE33185.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20>
{'baidu': 'the bridge on the river kwai ',
 'click': '495',
 'ctime': '2017-04-03',
 'fanyi': '',
 'filename': 'The.Bridge.on.the.River.Kwai.1957.2160p.WEB-DL.3xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '107.2 GB',
 'link': 'magnet:?xt=urn:btih:B5EF5E0B49FD9370D6E39B86EA1B9693E469F2E2'}
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/769B333547BF5B4C137D11FC3121CE1B23B604C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6DFA4CED20D48D0E581E318B9EDC8B35D63FF8BD.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fight%20club%20>
{'baidu': 'fight club ',
 'click': '169',
 'ctime': '2018-09-26',
 'fanyi': '',
 'filename': 'Fight.Club.1999.UHD.Re-Grade.6000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '104.9 GB',
 'link': 'magnet:?xt=urn:btih:6FA9CE5B9A08CAB64DC268B0512F950AC896569D'}
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/ED9D08819BF8A91BA6D0234ACB5A6D2032E62A8B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20>
{'baidu': 'men in black ',
 'click': '873',
 'ctime': '2015-11-12',
 'fanyi': '',
 'filename': 'Men.in.Black.1997.2160p.WEB-DL.3xRus.Eng.mkv',
 'length': '109.3 GB',
 'link': 'magnet:?xt=urn:btih:959A6A8EA8730CE8736EB839587C1CAA8FECC77F'}
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FEA8AF04251AB2DE967407801EF8D19822FFC3C0.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F661BD9AC3C06D4DA5E285A1172AE5890DF00A72.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9AC91CD6C3521E591D85D25E3EC11C8A9925A47C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5F7C8C25DD17B77A650D3DC2B002639A1B89C707.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/14DA430E8D7F940A8E7781E476EE40BCDE92E721.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D595F46390E2C51123CA8DD56891BE1EE2AE3226.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=titanic%20>
{'baidu': 'titanic ',
 'click': '736',
 'ctime': '2018-09-05',
 'fanyi': '',
 'filename': 'Titanic.1997.UHD.Remux.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '112.8 GB',
 'link': 'magnet:?xt=urn:btih:A390FF5E19A80FD589F4B2A8F6456DD2E7F47FE1'}
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jurassic%20park%20>
{'baidu': 'jurassic park ',
 'click': '1272',
 'ctime': '2018-05-26',
 'fanyi': '',
 'filename': 'Jurassic.Park.1993.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.2xUKR.ENG).ExKinoRay.mkv',
 'length': '115.1 GB',
 'link': 'magnet:?xt=urn:btih:FEA8AF04251AB2DE967407801EF8D19822FFC3C0'}
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F140154E9E81D99DF4ECFB7C676578426040D01F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2A1F18A9201B070CBD50BA321C1BF461A4F5A91F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lord%20of%20the%20rings%20>
{'baidu': 'the lord of the rings ',
 'click': '771',
 'ctime': '2018-09-17',
 'fanyi': '',
 'filename': 'The.Lord.of.the.Rings.2001.The.Fellowship.of.the.Ring.UHD.Re-Grade.4000nit.2160p.HEVC.HDR.IVA(RUS.UKR.ENG).ExKinoRay.mkv',
 'length': '113.3 GB',
 'link': 'magnet:?xt=urn:btih:F661BD9AC3C06D4DA5E285A1172AE5890DF00A72'}
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7B6525F8E9BD05A95C5D5D96294EB83E15A930C3.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0D1F01478B2FBD42447E12DBD8512380D4EDC04F.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EFF751D5A529715E3B9F2A9F98B02266D263E40B.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F0CB71BAC2BD8470A16576F08AE8EF88DF3F2C40.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20%5B%D0%BB%D0%BE%D1%83%D1%80%D0%B5%D0%BD%D1%81%20%D0%B0%D1%80%D0%B0%D0%B2%D0%B8%D0%B9%D1%81%D0%BA%D0%B8%D0%B9%5D%20web-dl%20>
{'baidu': 'lawrence of arabia [ ] web-dl ',
 'click': '679',
 'ctime': '2018-06-25',
 'fanyi': '[la',
 'filename': 'Lawrence of Arabia [ ] WEB-DL 2160p.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:2A1F18A9201B070CBD50BA321C1BF461A4F5A91F'}
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5484184C0C9BD8B2A6A7C7DCB22D222381D30C2C.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9FE34633C5C5B9CC103B605513BA139808A3834A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_3.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=lawrence%20of%20arabia%20>
{'baidu': 'lawrence of arabia ',
 'click': '84',
 'ctime': '2017-06-12',
 'fanyi': '',
 'filename': 'Lawrence.of.Arabia.1962.2160p.WEB-ULTRAHDCLUB.mkv',
 'length': '120.7 GB',
 'link': 'magnet:?xt=urn:btih:7B6525F8E9BD05A95C5D5D96294EB83E15A930C3'}
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20lost%20world%20jurassic%20park%20>
{'baidu': 'the lost world jurassic park ',
 'click': '1224',
 'ctime': '2018-05-25',
 'fanyi': '',
 'filename': 'The.Lost.World.Jurassic.Park.1997.Lic.BDRemux.2160p.4K.UltraHD.HEVC.HDR.IVA(14xRUS.3xUKR.ENG).ExKinoRay.mkv',
 'length': '99.7 GB',
 'link': 'magnet:?xt=urn:btih:0D1F01478B2FBD42447E12DBD8512380D4EDC04F'}
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6363D3550D86E1F94CF7BCE716F2A278F79E73FE.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20> (referer: None)
2018-11-27 17:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7F20772B573F2FB7C82C11F9D357911E4F5B9427.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghostbusters%20>
{'baidu': 'ghostbusters ',
 'click': '3458',
 'ctime': '2015-11-10',
 'fanyi': '',
 'filename': 'Ghostbusters.1984.2160p.WEB-DL.10xRus.3xUkr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '136.4 GB',
 'link': 'magnet:?xt=urn:btih:F0CB71BAC2BD8470A16576F08AE8EF88DF3F2C40'}
2018-11-27 17:08:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20>
{'baidu': 'the fifth element ',
 'click': '3536',
 'ctime': '2015-12-01',
 'fanyi': '',
 'filename': 'The.Fifth.Element.1997.2160p.WEB-DL.2xRus.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '90.8 GB',
 'link': 'magnet:?xt=urn:btih:0E9A3272715E2ED62B3C1EE9332EA8FE680E48EC'}
2018-11-27 17:08:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0577E3A8CD391D8C3A273AC418C804E690D8035A.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_1.html)
2018-11-27 17:08:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20> (referer: None)
2018-11-27 17:08:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=corazones%20de%20acero%20>
{'baidu': 'corazones de acero ',
 'click': '80',
 'ctime': '2015-12-26',
 'fanyi': '',
 'filename': 'Corazones de Acero 2014 2160p 4K x265 HEVC WEB-DL DTSHD MA '
             'HDTeam.mkv',
 'length': '114.3 GB',
 'link': 'magnet:?xt=urn:btih:7F20772B573F2FB7C82C11F9D357911E4F5B9427'}
2018-11-27 17:08:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20> (referer: None)
2018-11-27 17:08:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B1%D1%8D%D1%82%D0%BC%D0%B5%D0%BD%20%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2%20%D1%81%D1%83%D0%BF%D0%B5%D1%80%D0%BC%D0%B5%D0%BD%D0%B0%20%20%D0%BD%D0%B0%20%D0%B7%D0%B0%D1%80%D0%B5%20%D1%81%D0%BF%D1%80%D0%B0%D0%B2%D0%B5%D0%B4%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8%20>
{'baidu': '       ',
 'click': '1063',
 'ctime': '2018-07-16',
 'fanyi': '',
 'filename': '  .   '
             '.2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '119.5 GB',
 'link': 'magnet:?xt=urn:btih:0577E3A8CD391D8C3A273AC418C804E690D8035A'}
2018-11-27 17:08:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/71B18BEF36AEA4319D804083C31CB98873C59BF4.html> (referer: https://www.bturl.so/search/2160p%20mkv_length_2.html)
2018-11-27 17:08:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 17:08:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 25663,
 'downloader/request_count': 69,
 'downloader/request_method_count/GET': 69,
 'downloader/response_bytes': 125970,
 'downloader/response_count': 69,
 'downloader/response_status_count/200': 69,
 'dupefilter/filtered': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 9, 8, 52, 421052),
 'item_scraped_count': 21,
 'log_count/DEBUG': 92,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 69,
 'scheduler/dequeued': 69,
 'scheduler/dequeued/memory': 69,
 'scheduler/enqueued': 69,
 'scheduler/enqueued/memory': 69,
 'start_time': datetime.datetime(2018, 11, 27, 9, 8, 48, 173395)}
2018-11-27 17:08:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-27 17:27:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-27 17:27:29 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-27 17:27:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-27 17:27:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-27 17:27:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-27 17:27:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-27 17:27:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-27 17:27:30 [scrapy.core.engine] INFO: Spider opened
2018-11-27 17:27:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-27 17:27:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-27 17:27:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_63.html> (referer: None)
2018-11-27 17:27:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_62.html> (referer: None)
2018-11-27 17:27:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_61.html> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_64.html> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/150D6CAEE98CEE1B1C5E3BC2F0A76C38F09D9B3F.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/240E82497CDDC2D4A2C05C15562D31A25D173647.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/22C60D92199E0ED14CB8549A6086D5F901C6B542.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_60.html> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_65.html> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bill%20nye%20saves%20the%20world> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/01AAD37B9E5214DDB5B73990D2752684D04935AC.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E78261E17E600C31C35F91698CD9E0B25C708A33.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/081CAAA32361FFC416503B03245FAC3080422441.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bill%20nye%20saves%20the%20world>
{'baidu': 'bill nye saves the world',
 'click': '604',
 'ctime': '2018-07-18',
 'fanyi': '',
 'filename': 'Bill.Nye.Saves.the.World.S03.2160p.NF.WEBRip.DD5.1.x264-TrollUHD[rartv]',
 'length': '74.3 GB',
 'link': 'magnet:?xt=urn:btih:150D6CAEE98CEE1B1C5E3BC2F0A76C38F09D9B3F'}
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA60F8A22B6A56803FFEEC71B7752CD8376EF97F.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/84375B9B6446AFAD09EBEEF3DF4982D0ABD1BF95.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=red%20> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B%D0%B3%D0%BE%D0%B4%D0%B7%D0%B8%D0%BB%D0%BB%D0%B0%5D%20web-dl%20> (referer: None)
2018-11-27 17:27:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=red%20>
{'baidu': 'red ',
 'click': '953',
 'ctime': '2018-02-27',
 'fanyi': '',
 'filename': 'RED.2.2013.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.4 GB',
 'link': 'magnet:?xt=urn:btih:081CAAA32361FFC416503B03245FAC3080422441'}
2018-11-27 17:27:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B%D0%B3%D0%BE%D0%B4%D0%B7%D0%B8%D0%BB%D0%BB%D0%B0%5D%20web-dl%20>
{'baidu': 'godzilla [] web-dl ',
 'click': '400',
 'ctime': '2018-07-13',
 'fanyi': '[godzilla we',
 'filename': 'Godzilla [] WEB-DL 2160p.mkv',
 'length': '74.2 GB',
 'link': 'magnet:?xt=urn:btih:01AAD37B9E5214DDB5B73990D2752684D04935AC'}
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CF70079D4240C44D0E451EFC5B354CD8C1700ED.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F3F7F9E7A0DE8C203D9576DBEA3F4AA2FEDA7854.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=reboot%20the%20guardian%20code> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hacksaw%20ridge%20> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D8FD0C1C1152A92887981A10402FE9DB95EA05BD.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=warrior%20> (referer: None)
2018-11-27 17:27:32 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=red%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E883830F15A5264A66ABFB9C7D4CE73317625412.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=escape%20plan%20> (referer: None)
2018-11-27 17:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95C6B7F877B9940F0F1E77BFFEA161B65E13B9C1.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=reboot%20the%20guardian%20code>
{'baidu': 'reboot the guardian code',
 'click': '552',
 'ctime': '2018-10-06',
 'fanyi': '',
 'filename': 'Reboot.The.Guardian.Code.S01.2160p.NF.WEBRip.x264.DD5.1-TrollUHD[rartv]',
 'length': '74.5 GB',
 'link': 'magnet:?xt=urn:btih:84375B9B6446AFAD09EBEEF3DF4982D0ABD1BF95'}
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/CF651AFF043A146C5A2C72C6AC35B793283AA6F3.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1BE3BED5B5FC237C5C5C9755B017C800C76C1152.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hacksaw%20ridge%20>
{'baidu': 'hacksaw ridge ',
 'click': '2859',
 'ctime': '2017-10-24',
 'fanyi': '',
 'filename': 'Hacksaw.Ridge.2016.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.5 GB',
 'link': 'magnet:?xt=urn:btih:E78261E17E600C31C35F91698CD9E0B25C708A33'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=warrior%20>
{'baidu': 'warrior ',
 'click': '221',
 'ctime': '2017-12-30',
 'fanyi': '',
 'filename': 'Warrior.2011.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.2 GB',
 'link': 'magnet:?xt=urn:btih:240E82497CDDC2D4A2C05C15562D31A25D173647'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=escape%20plan%20>
{'baidu': 'escape plan ',
 'click': '672',
 'ctime': '2018-07-18',
 'fanyi': '',
 'filename': 'Escape.Plan.2013.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-WhiteRhino',
 'length': '74.4 GB',
 'link': 'magnet:?xt=urn:btih:DA60F8A22B6A56803FFEEC71B7752CD8376EF97F'}
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/70158558F203FCD09BA104B6ABF19E661B6FA807.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jupiter%20ascending%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%9C%98%E8%9B%9B%E4%BE%A0> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ozark> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/63EB2A97FCE54F36D7EEE27A4C431FC00FE86B6B.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/431E1FE7FC64B53E114051C6F7774B1E57BE5344.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hell%20or%20high%20water%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jupiter%20ascending%20>
{'baidu': 'jupiter ascending ',
 'click': '820',
 'ctime': '2018-03-14',
 'fanyi': '',
 'filename': 'Jupiter.Ascending.2015.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '75.0 GB',
 'link': 'magnet:?xt=urn:btih:1BE3BED5B5FC237C5C5C9755B017C800C76C1152'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%9C%98%E8%9B%9B%E4%BE%A0>
{'baidu': '',
 'click': '4',
 'ctime': '2018-10-28',
 'fanyi': 'spider-man',
 'filename': '3.Spider-Man.3.2007.2160p.UHD.Blu-ray.HEVC.TrueHD.7.1-SUPERSIZE',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:CF651AFF043A146C5A2C72C6AC35B793283AA6F3'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ozark>
{'baidu': 'ozark',
 'click': '33',
 'ctime': '2018-10-21',
 'fanyi': '',
 'filename': 'Ozark.S02.2160p.WEBRip.HEVC.HDR.KvK.CasStudio.TV',
 'length': '74.3 GB',
 'link': 'magnet:?xt=urn:btih:95C6B7F877B9940F0F1E77BFFEA161B65E13B9C1'}
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=law%20abiding%20citizen%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=valerian%20and%20the%20city%20of%20a%20thousand%20planets%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FF8BB3B36247834D25F193DC8CD8D7623D72DEEA.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9CA52C4FDF63C55C97A34D32FA2EE034954EDCD3.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/423331CDD2D92A60D2C8687B7F2A8A3225D100ED.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hell%20or%20high%20water%20>
{'baidu': 'hell or high water ',
 'click': '714',
 'ctime': '2018-03-11',
 'fanyi': '',
 'filename': 'Hell.or.High.Water.2016.2160p.BluRay.HEVC.DTS-HD.MA.5.1-WhiteRhino',
 'length': '74.6 GB',
 'link': 'magnet:?xt=urn:btih:E883830F15A5264A66ABFB9C7D4CE73317625412'}
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6FF0A4E508C4C5FDE1252A837214975F89AC8996.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7792BE3AD0E455D97F38552FF3836C07DD4F6993.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=law%20abiding%20citizen%20>
{'baidu': 'law abiding citizen ',
 'click': '105',
 'ctime': '2018-11-23',
 'fanyi': '',
 'filename': 'Law.Abiding.Citizen.2009.UHD.BLURAY.2160p.DV.IVA(RUS.UKR.ENG).ExKinoRay',
 'length': '74.5 GB',
 'link': 'magnet:?xt=urn:btih:D8FD0C1C1152A92887981A10402FE9DB95EA05BD'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=valerian%20and%20the%20city%20of%20a%20thousand%20planets%20>
{'baidu': 'valerian and the city of a thousand planets ',
 'click': '1720',
 'ctime': '2018-02-01',
 'fanyi': '',
 'filename': 'Valerian.and.the.City.of.a.Thousand.Planets.2017.US.2160p.BluRay.REMUX.HEVC.HDR.D.V.TrueHD.7.1.Atmos.IVA(6xRUS.UKR.ENG).mkv',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:70158558F203FCD09BA104B6ABF19E661B6FA807'}
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=iron%20fist> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=spider-man%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=iron%20fist>
{'baidu': 'iron fist',
 'click': '291',
 'ctime': '2018-09-29',
 'fanyi': '',
 'filename': 'Iron.Fist.S02.2018.WEBRip.2160p.HDR.MediaClub',
 'length': '73.7 GB',
 'link': 'magnet:?xt=urn:btih:431E1FE7FC64B53E114051C6F7774B1E57BE5344'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=spider-man%20>
{'baidu': 'spider-man ',
 'click': '820',
 'ctime': '2017-12-29',
 'fanyi': '',
 'filename': 'Spider-Man.3.2007.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-SUPERSIZE',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:63EB2A97FCE54F36D7EEE27A4C431FC00FE86B6B'}
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B72831887FE79A9C7C9D093665B3DF086B04DE78.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/ECA849716728C1C0DDDB47009846162E11B6EB26.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%85%D0%B8%D0%B6%D0%B8%D0%BD%D0%B0%20%D0%B2%20%D0%BB%D0%B5%D1%81%D1%83%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/18F35A938FF9711F9B5B3C65854FD9B48C045219.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D8E6CC1214815945926FF35DBF60F1748B9D81B0.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5706F199FE88F6958C67E40AC46CA129ABE1951D.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20>
{'baidu': 'men in black ',
 'click': '435',
 'ctime': '2018-07-20',
 'fanyi': '',
 'filename': 'Men in Black 3 [   3] WEB-DL 2160p.mkv',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:423331CDD2D92A60D2C8687B7F2A8A3225D100ED'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20>
{'baidu': 'the fifth element ',
 'click': '1027',
 'ctime': '2017-11-02',
 'fanyi': '',
 'filename': 'The.Fifth.Element.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:9CA52C4FDF63C55C97A34D32FA2EE034954EDCD3'}
2018-11-27 17:27:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%85%D0%B8%D0%B6%D0%B8%D0%BD%D0%B0%20%D0%B2%20%D0%BB%D0%B5%D1%81%D1%83%20>
{'baidu': '   ',
 'click': '747',
 'ctime': '2018-07-01',
 'fanyi': '',
 'filename': '  .2012.UHD.Blu-Ray.Remux.2160p.mkv',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:FF8BB3B36247834D25F193DC8CD8D7623D72DEEA'}
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/537012E5CE1D5B0135361E43F3B0CC82A6C83C1C.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0C9AD30F9825691C8AB62169B2AE67FE48E1A47A.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=most%20cherez%20reku%20kvay%20> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tom%20clancys%20jack%20ryan> (referer: None)
2018-11-27 17:27:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%BF%D0%BE%20%D1%81%D0%BE%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%D0%BC%20%D1%81%D0%BE%D0%B2%D0%B5%D1%81%D1%82%D0%B8%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=master%20of%20none> (referer: None)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=most%20cherez%20reku%20kvay%20>
{'baidu': 'most cherez reku kvay ',
 'click': '258',
 'ctime': '2018-02-24',
 'fanyi': 'cherez reku kvay',
 'filename': 'Most.cherez.reku.Kvay.1957.2160p.HEVC.UHD.HDR.MediaClub.mkv',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:ECA849716728C1C0DDDB47009846162E11B6EB26'}
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tom%20clancys%20jack%20ryan>
{'baidu': 'tom clancys jack ryan',
 'click': '103',
 'ctime': '2018-09-29',
 'fanyi': '',
 'filename': 'Tom.Clancys.Jack.Ryan.S01.2160p.HDR.WEBRip.2xRus.Eng.EniaHD',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:5706F199FE88F6958C67E40AC46CA129ABE1951D'}
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%BF%D0%BE%20%D1%81%D0%BE%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%D0%BC%20%D1%81%D0%BE%D0%B2%D0%B5%D1%81%D1%82%D0%B8%20>
{'baidu': '   ',
 'click': '435',
 'ctime': '2018-08-02',
 'fanyi': '',
 'filename': '  .2016.UHD.Blu-Ray.Remux.2160p.mkv',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:D8E6CC1214815945926FF35DBF60F1748B9D81B0'}
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E98B7791BA63070B58EFB26640E00E1BDD6F449D.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=master%20of%20none>
{'baidu': 'master of none',
 'click': '53',
 'ctime': '2016-02-05',
 'fanyi': '',
 'filename': 'Master.of.None.S01.2160p.Netflix.WEBRip.Rus.Eng.TrollUHD-ULTRAHDCLUB',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:18F35A938FF9711F9B5B3C65854FD9B48C045219'}
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F4F1DE76BBC1DE3A3AA602FEC3607BF80F223977.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D59845753F882F5BD8C97B62C9C0D7384855AE8A.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D8560CD0E16C38C551571710E488E90E4E3B0C39.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/CABD8E652446CDE1EF942490E46A28EDE86CA3E5.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E5F3BCB5405582153DB4F79E6E6FB0A24FCD2C03.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20>
{'baidu': 'godzilla ',
 'click': '1185',
 'ctime': '2015-12-13',
 'fanyi': '',
 'filename': 'Godzilla.1998.2160p.WEB-DL.5xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '74.2 GB',
 'link': 'magnet:?xt=urn:btih:22C60D92199E0ED14CB8549A6086D5F901C6B542'}
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1EC9659D268A58E14DAFB36665123A78935CB89B.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hook%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fi%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hook%20>
{'baidu': 'hook ',
 'click': '276',
 'ctime': '2018-10-07',
 'fanyi': '',
 'filename': 'Hook.1991.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:CABD8E652446CDE1EF942490E46A28EDE86CA3E5'}
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fi%20>
{'baidu': 'fi ',
 'click': '34',
 'ctime': '2017-06-23',
 'fanyi': 'fi',
 'filename': 'Fi 01.Sezon (01-12) Boxset 4K UltraHD 2160p WebDL TDRG',
 'length': '75.6 GB',
 'link': 'magnet:?xt=urn:btih:D8560CD0E16C38C551571710E488E90E4E3B0C39'}
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9697D424D17BD65BF2395C2C0373BC65C3EDC41E.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%E4%B8%8E%E9%AD%94%E6%B3%95%E7%9F%B3%20harry%20potter%20and%20the%20sorcerer%27s%20stone%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C3EEE205C4CB2A8FFA40A6D8E5E939FF2FEDD8FF.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=john%20wick%20chapter%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7EFCE3D74C31C22851504A8319D205C128F71BC0.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF2B67332083B507B3C62351CA7C42476BBD4CC4.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%E4%B8%8E%E9%AD%94%E6%B3%95%E7%9F%B3%20harry%20potter%20and%20the%20sorcerer%27s%20stone%20>
{'baidu': " harry potter and the sorcerer's stone ",
 'click': '461',
 'ctime': '2018-04-29',
 'fanyi': 'Harry potter and the',
 'filename': ".Harry.Potter.and.the.Sorcerer's.Stone.2001.2160p.UHD.Blu-ray.HEVC.DTS-HD.MA.7.1-TERMiNAL",
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:1EC9659D268A58E14DAFB36665123A78935CB89B'}
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=life_of_pi_> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DAE449147BB9B13B01834F927FFD911D4697DA58.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=john%20wick%20chapter%20>
{'baidu': 'john wick chapter ',
 'click': '2',
 'ctime': '2017-11-05',
 'fanyi': '',
 'filename': 'John.Wick.Chapter.2.2017.2160p.UltraHD.Bluray.HDR.Atmos.7.1.x265.mkv',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:E5F3BCB5405582153DB4F79E6E6FB0A24FCD2C03'}
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D57A5BA950C63EB50A9FC4272892E533C4D0DB1C.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=life_of_pi_>
{'baidu': 'life_of_pi_',
 'click': '21',
 'ctime': '2016-07-03',
 'fanyi': 'life_of_pi_',
 'filename': 'LIFE_OF_PI_2160p.mkv',
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:9697D424D17BD65BF2395C2C0373BC65C3EDC41E'}
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=blade%20runner%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=independence%20day%20> (referer: None)
2018-11-27 17:27:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mindhunter> (referer: None)
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=blade%20runner%20>
{'baidu': 'blade runner ',
 'click': '1614',
 'ctime': '2018-02-14',
 'fanyi': '',
 'filename': 'Blade.Runner.2049.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-TERMiNAL',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:BF2B67332083B507B3C62351CA7C42476BBD4CC4'}
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=independence%20day%20>
{'baidu': 'independence day ',
 'click': '1193',
 'ctime': '2017-10-31',
 'fanyi': '',
 'filename': 'Independence.Day.1996.EXTENDED.2160p.BluRay.x264.8bit.SDR.DTS-X.7.1-SWTYBLZ',
 'length': '76.0 GB',
 'link': 'magnet:?xt=urn:btih:7EFCE3D74C31C22851504A8319D205C128F71BC0'}
2018-11-27 17:27:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mindhunter>
{'baidu': 'mindhunter',
 'click': '1',
 'ctime': '2018-11-24',
 'fanyi': 'mindhunter',
 'filename': 'Mindhunter.S01.2160p.TVShows',
 'length': '76.0 GB',
 'link': 'magnet:?xt=urn:btih:DAE449147BB9B13B01834F927FFD911D4697DA58'}
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7D092F30224DC28ABB382FA2FAF39BFC06E39B9D.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85E4F6923F1A66A5455030415A28E86317A04A06.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20sorcerers%20stone%20> (referer: None)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D43CE29D2621D84365868E4067E9BAD54605C4CD.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9E079E11CB434A8CAF2BED0E30DD0193946CEE1A.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C8409B1FFF8F61063E0D24D30698D9AF22750BFA.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B4%D0%B6%D0%B5%D0%B9%D1%81%D0%BE%D0%BD%20%D0%B1%D0%BE%D1%80%D0%BD%20> (referer: None)
2018-11-27 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20sorcerers%20stone%20>
{'baidu': 'harry potter and the sorcerers stone ',
 'click': '2498',
 'ctime': '2018-01-30',
 'fanyi': '',
 'filename': 'Harry.Potter.and.the.Sorcerers.Stone.2001.2160p.BluRay.REMUX.HEVC.DTS-X.7.1.IVA(RUS.UKR.ENG).mkv',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:7D092F30224DC28ABB382FA2FAF39BFC06E39B9D'}
2018-11-27 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B4%D0%B6%D0%B5%D0%B9%D1%81%D0%BE%D0%BD%20%D0%B1%D0%BE%D1%80%D0%BD%20>
{'baidu': '  ',
 'click': '648',
 'ctime': '2018-07-09',
 'fanyi': '',
 'filename': ' .2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:85E4F6923F1A66A5455030415A28E86317A04A06'}
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7E9C0A5F78CBB580A477E834917A488FEF16D782.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF1E913EB8B658C61B783188669BE0B88B414FA5.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=el%20hombre%20de%20acero%20%5Bfull%20uhd%5D%5B> (referer: None)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=man%20of%20steel%20> (referer: None)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/359A94F925FE32632F968BD6D5E301C4F2030D2A.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20spy%20who%20dumped%20me%20> (referer: None)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B> (referer: None)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A82CF3BDF3204B92055D32B69B9CA3C11BCB228C.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=el%20hombre%20de%20acero%20%5Bfull%20uhd%5D%5B>
{'baidu': 'el hombre de acero [full uhd][',
 'click': '597',
 'ctime': '2017-11-13',
 'fanyi': 'uhd][[',
 'filename': 'El Hombre de Acero [FULL UHD][4K 2160p][HEVC][AC3 5.1 Castellano '
             'True HD 5.1-Ingles+Subs][ES-EN]',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:C8409B1FFF8F61063E0D24D30698D9AF22750BFA'}
2018-11-27 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=man%20of%20steel%20>
{'baidu': 'man of steel ',
 'click': '1701',
 'ctime': '2017-11-16',
 'fanyi': '',
 'filename': 'Man.of.Steel.2013.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-SharpHD',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:D43CE29D2621D84365868E4067E9BAD54605C4CD'}
2018-11-27 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20spy%20who%20dumped%20me%20>
{'baidu': 'the spy who dumped me ',
 'click': '434',
 'ctime': '2018-10-28',
 'fanyi': '',
 'filename': 'The.Spy.Who.Dumped.Me.2018.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-TERMiNAL',
 'length': '76.1 GB',
 'link': 'magnet:?xt=urn:btih:9E079E11CB434A8CAF2BED0E30DD0193946CEE1A'}
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A5BE842E7A89F61742BEEC163F6D41632487FF18.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B>
{'baidu': 'godzilla [',
 'click': '3377',
 'ctime': '2016-10-12',
 'fanyi': '(',
 'filename': 'Godzilla [4K UHD 2160p HEVC X264][DTS MA 5.1 Castellano DTS MA '
             '5.1-Ingles+Subs][ES-EN]',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:7E9C0A5F78CBB580A477E834917A488FEF16D782'}
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38549CFA338CFA017D56456097F90450C07E80E7.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%B6%85%E4%BA%BA%EF%BC%9A%E9%92%A2%E9%93%81%E4%B9%8B%E8%BA%AF%20man%20of%20steel%20> (referer: None)
2018-11-27 17:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=transformers%20-%20the%20last%20knight%20%28> (referer: None)
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%B6%85%E4%BA%BA%EF%BC%9A%E9%92%A2%E9%93%81%E4%B9%8B%E8%BA%AF%20man%20of%20steel%20>
{'baidu': ' man of steel ',
 'click': '123',
 'ctime': '2018-05-02',
 'fanyi': 'Superman: steel man ',
 'filename': '.Man.of.Steel.2013.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-SharpHD',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:359A94F925FE32632F968BD6D5E301C4F2030D2A'}
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=transformers%20-%20the%20last%20knight%20%28>
{'baidu': 'transformers - the last knight (',
 'click': '907',
 'ctime': '2018-06-25',
 'fanyi': '-(',
 'filename': 'Transformers - The Last Knight (2017) [2160p].mkv',
 'length': '73.9 GB',
 'link': 'magnet:?xt=urn:btih:A82CF3BDF3204B92055D32B69B9CA3C11BCB228C'}
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BE97BF7F671B36105ED4E39A9A3034B8066E5D3A.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/220F28CD2E1582EFECBC6894F8FFAC46BAB68E50.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20hunger%20games%20catching%20fire%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=batman%20begins%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/780984C5002E07C95B54FE97E481126EAEA7CFA7.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20hunger%20games%20catching%20fire%20>
{'baidu': 'the hunger games catching fire ',
 'click': '1243',
 'ctime': '2018-02-27',
 'fanyi': '',
 'filename': 'The.Hunger.Games.Catching.Fire.2013.PROPER.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.0 GB',
 'link': 'magnet:?xt=urn:btih:38549CFA338CFA017D56456097F90450C07E80E7'}
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/634B87A96B2D933C5AFD18785FFB5F6BF8E8B00B.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/65B04DB450ECE5270FCFCDDD2883A24E2EEF888C.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=batman%20begins%20>
{'baidu': 'batman begins ',
 'click': '158',
 'ctime': '2018-07-28',
 'fanyi': '',
 'filename': 'Batman Begins 2005 2160p EUR UHD Blu-ray HEVC DTS-HD MA '
             '5.1-OLDHAM',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:A5BE842E7A89F61742BEEC163F6D41632487FF18'}
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bad%20boys%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20>
{'baidu': 'the bridge on the river kwai ',
 'click': '469',
 'ctime': '2017-12-08',
 'fanyi': '',
 'filename': 'The.Bridge.on.the.River.Kwai.1957.2160p.BluRay.REMUX.HEVC.TrueHD.7.1.Atmos.mkv',
 'length': '74.0 GB',
 'link': 'magnet:?xt=urn:btih:BE97BF7F671B36105ED4E39A9A3034B8066E5D3A'}
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bad%20boys%20>
{'baidu': 'bad boys ',
 'click': '1116',
 'ctime': '2018-09-04',
 'fanyi': '',
 'filename': 'Bad.Boys.1995.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-TERMiNAL',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:220F28CD2E1582EFECBC6894F8FFAC46BAB68E50'}
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/39ACE0AFC0E6736E563BD276D5C12A8222F838C7.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=cyw%20%E8%89%B3%E9%AA%A8%20colourful%20bone%20ep> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E63B21F095F49CD392E50390A566A4D732034EFF.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=la%20la%20land%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bu> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/41BD680277923840DC58924231F85EB9798B5390.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=cyw%20%E8%89%B3%E9%AA%A8%20colourful%20bone%20ep>
{'baidu': 'cyw  colourful bone ep',
 'click': '8',
 'ctime': '2018-07-25',
 'fanyi': 'Cyw colourful colour',
 'filename': 'CYW..Colourful '
             'Bone.EP01-54.2017.3840x2160p.WEB-DL.x265.Audio.AAC-.@',
 'length': '74.1 GB',
 'link': 'magnet:?xt=urn:btih:65B04DB450ECE5270FCFCDDD2883A24E2EEF888C'}
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=la%20la%20land%20>
{'baidu': 'la la land ',
 'click': '2041',
 'ctime': '2017-06-22',
 'fanyi': '',
 'filename': 'La.La.Land.2016.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.1 GB',
 'link': 'magnet:?xt=urn:btih:634B87A96B2D933C5AFD18785FFB5F6BF8E8B00B'}
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bu>
{'baidu': '[u',
 'click': '427',
 'ctime': '2018-09-15',
 'fanyi': '[',
 'filename': '[U3-Project] Mary to Majo no Hana [UHD-BD 4K 2160p '
             'HEVC-yuv420p10 DTS-X DTS-HDMA PGS(jpn,eng)].mkv',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:780984C5002E07C95B54FE97E481126EAEA7CFA7'}
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/032CD4B93F836EC2FB060FFC404264152F689995.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4E1E7C845C7F8C1B814876084ADC6BFC6CF089EE.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BD6B8739E72B1ACC2480A88A0C512D3CB7C7559D.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=step%20brothers%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mary%20and%20the%20witchs%20flower%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/15D3F26334BC424414B85CAABCC1823496579B14.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/12FEB10DD16A11117EB9C5EA9996CE1C6710EBB1.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4F74E61E48EABBA417C28F30297CA096096E46F8.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=step%20brothers%20>
{'baidu': 'step brothers ',
 'click': '4',
 'ctime': '2018-10-17',
 'fanyi': '',
 'filename': 'Step.Brothers.2008.UHD.BluRay.2160p.HEVC.TrueHD.7.1-COASTER',
 'length': '76.1 GB',
 'link': 'magnet:?xt=urn:btih:E63B21F095F49CD392E50390A566A4D732034EFF'}
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mary%20and%20the%20witchs%20flower%20>
{'baidu': 'mary and the witchs flower ',
 'click': '1427',
 'ctime': '2018-05-24',
 'fanyi': '',
 'filename': 'Mary.and.the.Witchs.Flower.2017.JAPANESE.2160p.BluRay.REMUX.HEVC.DTS-X.7.1-FGT',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:41BD680277923840DC58924231F85EB9798B5390'}
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20great%20gatsby%20> (referer: None)
2018-11-27 17:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/757989BF560EAB8913D7A738DAD5B6A1697A3D7D.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20great%20gatsby%20>
{'baidu': 'the great gatsby ',
 'click': '979',
 'ctime': '2018-04-14',
 'fanyi': '',
 'filename': 'The.Great.Gatsby.2013.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.5.1-FGT',
 'length': '75.3 GB',
 'link': 'magnet:?xt=urn:btih:4E1E7C845C7F8C1B814876084ADC6BFC6CF089EE'}
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/18A6D848C6786382C07E10A5B0EE80235E9A93AB.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=detroit%20> (referer: None)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/93889160517389E976FAF04CD4F9FE47E4E09728.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BEF5E5A4CFC1E6BF1A429EBD890F95E2F3B51CAD.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=detroit%20>
{'baidu': 'detroit ',
 'click': '1035',
 'ctime': '2018-05-26',
 'fanyi': '',
 'filename': 'Detroit.2017.UHD.BluRay.2160p.DTS-HD.MA.5.1.HEVC.HYBRID.REMUX-FraMeSToR',
 'length': '74.1 GB',
 'link': 'magnet:?xt=urn:btih:15D3F26334BC424414B85CAABCC1823496579B14'}
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/045502C02734467F1D039923BDD7F1183CD1B894.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/AD9314C77073041C927A89D7619CE973A94378B4.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/69CF1F618693FC1278084783009130978F77D867.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20patriot%20> (referer: None)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=better%20call%20saul> (referer: None)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/88DB1F0B4DE9D1B6FDA904F6ACCB661DD7427AB8.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=american%20psycho%20> (referer: None)
2018-11-27 17:27:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20patriot%20>
{'baidu': 'the patriot ',
 'click': '1381',
 'ctime': '2018-06-26',
 'fanyi': '',
 'filename': 'The.Patriot.2000.THEATRICAL.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '75.6 GB',
 'link': 'magnet:?xt=urn:btih:18A6D848C6786382C07E10A5B0EE80235E9A93AB'}
2018-11-27 17:27:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=better%20call%20saul>
{'baidu': 'better call saul',
 'click': '2273',
 'ctime': '2016-05-06',
 'fanyi': '',
 'filename': 'Better.Call.Saul.S02.2160p.WEBRip.KvK.CasStudio.TV',
 'length': '75.6 GB',
 'link': 'magnet:?xt=urn:btih:BEF5E5A4CFC1E6BF1A429EBD890F95E2F3B51CAD'}
2018-11-27 17:27:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=american%20psycho%20>
{'baidu': 'american psycho ',
 'click': '381',
 'ctime': '2018-09-27',
 'fanyi': '',
 'filename': 'American.Psycho.2000.UNCUT.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-WhiteRhino',
 'length': '75.5 GB',
 'link': 'magnet:?xt=urn:btih:045502C02734467F1D039923BDD7F1183CD1B894'}
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EB43622830BBFDE81D3DED7EDCB665C0035DC715.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B736082C14171D14B339115494B79E31661DDF1F.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BC316FAE6F711F059E37B6D1B50E81D19F4BF844.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zero%20dark%20thirty%20> (referer: None)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BEAC334C1E036D499A3D5447D04AF7D8FCB3D29C.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20> (referer: None)
2018-11-27 17:27:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zero%20dark%20thirty%20>
{'baidu': 'zero dark thirty ',
 'click': '6',
 'ctime': '2018-03-02',
 'fanyi': '',
 'filename': 'Zero.Dark.Thirty.2012.UHD.BluRay.2160p.REMUX.TrueHD.7.1.ATMOS.HEVC.HuN-TRiNiTY',
 'length': '74.7 GB',
 'link': 'magnet:?xt=urn:btih:EB43622830BBFDE81D3DED7EDCB665C0035DC715'}
2018-11-27 17:27:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20>
{'baidu': 'the equalizer ',
 'click': '631',
 'ctime': '2018-08-05',
 'fanyi': '',
 'filename': 'The.Equalizer.2014.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1',
 'length': '74.8 GB',
 'link': 'magnet:?xt=urn:btih:B736082C14171D14B339115494B79E31661DDF1F'}
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7D718BBB75F9D2368658878882411E520D42E485.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A1A4848CF46322043DF4E54FE4757A927512C9A3.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/31FC1274C3E507C7FEA7BCA09724ED30649A338D.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/CF3F34B9D903CF3F3AB64CDB72E5B6175520F139.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CF93A665486E2BB8EF0CE6DB8EAF670354F3BEC.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EDDBEB611048EBCC4836A56220328E741E18CCC1.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=goodfellas%20> (referer: None)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghost%20in%20the%20shell%20> (referer: None)
2018-11-27 17:27:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=goodfellas%20>
{'baidu': 'goodfellas ',
 'click': '1076',
 'ctime': '2017-11-24',
 'fanyi': '',
 'filename': 'Goodfellas.1990.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.5.1-SWTYBLZ',
 'length': '74.8 GB',
 'link': 'magnet:?xt=urn:btih:A1A4848CF46322043DF4E54FE4757A927512C9A3'}
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=t> (referer: None)
2018-11-27 17:27:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghost%20in%20the%20shell%20>
{'baidu': 'ghost in the shell ',
 'click': '1282',
 'ctime': '2018-07-06',
 'fanyi': '',
 'filename': 'Ghost.in.the.Shell.2.Innocence.2004.2160p.BluRay.HEVC.DTS-X.7.1-TASTED',
 'length': '74.7 GB',
 'link': 'magnet:?xt=urn:btih:CF3F34B9D903CF3F3AB64CDB72E5B6175520F139'}
2018-11-27 17:27:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=t>
{'baidu': 't',
 'click': '767',
 'ctime': '2017-10-31',
 'fanyi': 't',
 'filename': 'T2.Trainspotting.2017.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '74.2 GB',
 'link': 'magnet:?xt=urn:btih:EDDBEB611048EBCC4836A56220328E741E18CCC1'}
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/AF3F99A8CCF1247F02D6DE9340B6C8B7686DA4E0.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EFE68D783891AD8BAEEC7826458BB7B25541CA02.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/66ABBF3A72BFF073F58008F1CFBC78EEDF6ECA7A.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/566B913944FA1D702AC6A990185D3C57CF23E6BF.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20half-blood%20prince%20> (referer: None)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ready_player_one_bdremux%20> (referer: None)
2018-11-27 17:27:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20prestige%20> (referer: None)
2018-11-27 17:27:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20half-blood%20prince%20>
{'baidu': 'harry potter and the half-blood prince ',
 'click': '1336',
 'ctime': '2018-04-07',
 'fanyi': '',
 'filename': 'Harry.Potter.and.the.Half-Blood.Prince.2009.2160p.BluRay.HEVC.DTS-X.7.1-SUPERSIZE',
 'length': '74.6 GB',
 'link': 'magnet:?xt=urn:btih:AF3F99A8CCF1247F02D6DE9340B6C8B7686DA4E0'}
2018-11-27 17:27:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ready_player_one_bdremux%20>
{'baidu': 'ready_player_one_bdremux ',
 'click': '576',
 'ctime': '2018-08-11',
 'fanyi': 'ready_player_one_bdr',
 'filename': 'Ready_Player_One_BDREMUX.2160p.4K.UltraHD.HEVC.HDR.mkv',
 'length': '74.6 GB',
 'link': 'magnet:?xt=urn:btih:EFE68D783891AD8BAEEC7826458BB7B25541CA02'}
2018-11-27 17:27:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20prestige%20>
{'baidu': 'the prestige ',
 'click': '1348',
 'ctime': '2018-01-29',
 'fanyi': '',
 'filename': 'The.Prestige.2006.2160p.BluRay.HEVC.HDR.DTS-HD.MA.5.1.IVA(8xRUS.2xUKR.2xENG).mkv',
 'length': '74.8 GB',
 'link': 'magnet:?xt=urn:btih:66ABBF3A72BFF073F58008F1CFBC78EEDF6ECA7A'}
2018-11-27 17:27:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-27 17:27:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 58109,
 'downloader/request_count': 158,
 'downloader/request_method_count/GET': 158,
 'downloader/response_bytes': 283528,
 'downloader/response_count': 158,
 'downloader/response_status_count/200': 158,
 'dupefilter/filtered': 28,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 27, 9, 27, 38, 605667),
 'item_scraped_count': 61,
 'log_count/DEBUG': 221,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 158,
 'scheduler/dequeued': 158,
 'scheduler/dequeued/memory': 158,
 'scheduler/enqueued': 158,
 'scheduler/enqueued/memory': 158,
 'start_time': datetime.datetime(2018, 11, 27, 9, 27, 30, 156192)}
2018-11-27 17:27:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 08:27:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 08:27:41 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 08:28:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 08:28:24 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 08:28:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 08:28:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 08:28:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 08:28:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 08:28:24 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 08:28:24 [scrapy.core.engine] INFO: Spider opened
2018-11-28 08:28:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 08:28:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 08:28:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_64.html> (referer: None)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_62.html> (referer: None)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_61.html> (referer: None)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/65B04DB450ECE5270FCFCDDD2883A24E2EEF888C.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/634B87A96B2D933C5AFD18785FFB5F6BF8E8B00B.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/15D3F26334BC424414B85CAABCC1823496579B14.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/70158558F203FCD09BA104B6ABF19E661B6FA807.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_65.html> (referer: None)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=la%20la%20land%20> (referer: None)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=cyw%20%E8%89%B3%E9%AA%A8%20colourful%20bone%20ep> (referer: None)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/431E1FE7FC64B53E114051C6F7774B1E57BE5344.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D43CE29D2621D84365868E4067E9BAD54605C4CD.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=valerian%20and%20the%20city%20of%20a%20thousand%20planets%20> (referer: None)
2018-11-28 08:28:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=la%20la%20land%20>
{'baidu': 'la la land ',
 'click': '2041',
 'ctime': '2017-06-22',
 'fanyi': '',
 'filename': 'La.La.Land.2016.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.1 GB',
 'link': 'magnet:?xt=urn:btih:634B87A96B2D933C5AFD18785FFB5F6BF8E8B00B'}
2018-11-28 08:28:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=cyw%20%E8%89%B3%E9%AA%A8%20colourful%20bone%20ep>
{'baidu': 'cyw  colourful bone ep',
 'click': '8',
 'ctime': '2018-07-25',
 'fanyi': 'Cyw colourful colour',
 'filename': 'CYW..Colourful '
             'Bone.EP01-54.2017.3840x2160p.WEB-DL.x265.Audio.AAC-.@',
 'length': '74.1 GB',
 'link': 'magnet:?xt=urn:btih:65B04DB450ECE5270FCFCDDD2883A24E2EEF888C'}
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/359A94F925FE32632F968BD6D5E301C4F2030D2A.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=valerian%20and%20the%20city%20of%20a%20thousand%20planets%20>
{'baidu': 'valerian and the city of a thousand planets ',
 'click': '1720',
 'ctime': '2018-02-01',
 'fanyi': '',
 'filename': 'Valerian.and.the.City.of.a.Thousand.Planets.2017.US.2160p.BluRay.REMUX.HEVC.HDR.D.V.TrueHD.7.1.Atmos.IVA(6xRUS.UKR.ENG).mkv',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:70158558F203FCD09BA104B6ABF19E661B6FA807'}
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF1E913EB8B658C61B783188669BE0B88B414FA5.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_63.html> (referer: None)
2018-11-28 08:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=man%20of%20steel%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C8409B1FFF8F61063E0D24D30698D9AF22750BFA.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=man%20of%20steel%20>
{'baidu': 'man of steel ',
 'click': '1701',
 'ctime': '2017-11-16',
 'fanyi': '',
 'filename': 'Man.of.Steel.2013.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-SharpHD',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:D43CE29D2621D84365868E4067E9BAD54605C4CD'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A5BE842E7A89F61742BEEC163F6D41632487FF18.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%B6%85%E4%BA%BA%EF%BC%9A%E9%92%A2%E9%93%81%E4%B9%8B%E8%BA%AF%20man%20of%20steel%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1BE3BED5B5FC237C5C5C9755B017C800C76C1152.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=el%20hombre%20de%20acero%20%5Bfull%20uhd%5D%5B> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=iron%20fist> (referer: None)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%B6%85%E4%BA%BA%EF%BC%9A%E9%92%A2%E9%93%81%E4%B9%8B%E8%BA%AF%20man%20of%20steel%20>
{'baidu': ' man of steel ',
 'click': '123',
 'ctime': '2018-05-02',
 'fanyi': 'Superman: steel man ',
 'filename': '.Man.of.Steel.2013.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-SharpHD',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:359A94F925FE32632F968BD6D5E301C4F2030D2A'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=batman%20begins%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=el%20hombre%20de%20acero%20%5Bfull%20uhd%5D%5B>
{'baidu': 'el hombre de acero [full uhd][',
 'click': '597',
 'ctime': '2017-11-13',
 'fanyi': 'uhd][[',
 'filename': 'El Hombre de Acero [FULL UHD][4K 2160p][HEVC][AC3 5.1 Castellano '
             'True HD 5.1-Ingles+Subs][ES-EN]',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:C8409B1FFF8F61063E0D24D30698D9AF22750BFA'}
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=iron%20fist>
{'baidu': 'iron fist',
 'click': '291',
 'ctime': '2018-09-29',
 'fanyi': '',
 'filename': 'Iron.Fist.S02.2018.WEBRip.2160p.HDR.MediaClub',
 'length': '73.7 GB',
 'link': 'magnet:?xt=urn:btih:431E1FE7FC64B53E114051C6F7774B1E57BE5344'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E883830F15A5264A66ABFB9C7D4CE73317625412.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/63EB2A97FCE54F36D7EEE27A4C431FC00FE86B6B.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=batman%20begins%20>
{'baidu': 'batman begins ',
 'click': '158',
 'ctime': '2018-07-28',
 'fanyi': '',
 'filename': 'Batman Begins 2005 2160p EUR UHD Blu-ray HEVC DTS-HD MA '
             '5.1-OLDHAM',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:A5BE842E7A89F61742BEEC163F6D41632487FF18'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jupiter%20ascending%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/780984C5002E07C95B54FE97E481126EAEA7CFA7.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/CF651AFF043A146C5A2C72C6AC35B793283AA6F3.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9CA52C4FDF63C55C97A34D32FA2EE034954EDCD3.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=jupiter%20ascending%20>
{'baidu': 'jupiter ascending ',
 'click': '820',
 'ctime': '2018-03-14',
 'fanyi': '',
 'filename': 'Jupiter.Ascending.2015.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '75.0 GB',
 'link': 'magnet:?xt=urn:btih:1BE3BED5B5FC237C5C5C9755B017C800C76C1152'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hell%20or%20high%20water%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/38549CFA338CFA017D56456097F90450C07E80E7.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=spider-man%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BE97BF7F671B36105ED4E39A9A3034B8066E5D3A.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7792BE3AD0E455D97F38552FF3836C07DD4F6993.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hell%20or%20high%20water%20>
{'baidu': 'hell or high water ',
 'click': '714',
 'ctime': '2018-03-11',
 'fanyi': '',
 'filename': 'Hell.or.High.Water.2016.2160p.BluRay.HEVC.DTS-HD.MA.5.1-WhiteRhino',
 'length': '74.6 GB',
 'link': 'magnet:?xt=urn:btih:E883830F15A5264A66ABFB9C7D4CE73317625412'}
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=spider-man%20>
{'baidu': 'spider-man ',
 'click': '820',
 'ctime': '2017-12-29',
 'fanyi': '',
 'filename': 'Spider-Man.3.2007.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-SUPERSIZE',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:63EB2A97FCE54F36D7EEE27A4C431FC00FE86B6B'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/2CF70079D4240C44D0E451EFC5B354CD8C1700ED.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%9C%98%E8%9B%9B%E4%BE%A0> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bu> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/AD9314C77073041C927A89D7619CE973A94378B4.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20hunger%20games%20catching%20fire%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/240E82497CDDC2D4A2C05C15562D31A25D173647.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/01AAD37B9E5214DDB5B73990D2752684D04935AC.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E8%9C%98%E8%9B%9B%E4%BE%A0>
{'baidu': '',
 'click': '4',
 'ctime': '2018-10-28',
 'fanyi': 'spider-man',
 'filename': '3.Spider-Man.3.2007.2160p.UHD.Blu-ray.HEVC.TrueHD.7.1-SUPERSIZE',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:CF651AFF043A146C5A2C72C6AC35B793283AA6F3'}
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bu>
{'baidu': '[u',
 'click': '427',
 'ctime': '2018-09-15',
 'fanyi': '[',
 'filename': '[U3-Project] Mary to Majo no Hana [UHD-BD 4K 2160p '
             'HEVC-yuv420p10 DTS-X DTS-HDMA PGS(jpn,eng)].mkv',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:780984C5002E07C95B54FE97E481126EAEA7CFA7'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/FF8BB3B36247834D25F193DC8CD8D7623D72DEEA.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F3F7F9E7A0DE8C203D9576DBEA3F4AA2FEDA7854.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20fifth%20element%20>
{'baidu': 'the fifth element ',
 'click': '1027',
 'ctime': '2017-11-02',
 'fanyi': '',
 'filename': 'The.Fifth.Element.1997.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:9CA52C4FDF63C55C97A34D32FA2EE034954EDCD3'}
2018-11-28 08:28:27 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=detroit%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EDDBEB611048EBCC4836A56220328E741E18CCC1.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=red%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20hunger%20games%20catching%20fire%20>
{'baidu': 'the hunger games catching fire ',
 'click': '1243',
 'ctime': '2018-02-27',
 'fanyi': '',
 'filename': 'The.Hunger.Games.Catching.Fire.2013.PROPER.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.0 GB',
 'link': 'magnet:?xt=urn:btih:38549CFA338CFA017D56456097F90450C07E80E7'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/22C60D92199E0ED14CB8549A6086D5F901C6B542.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=warrior%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/423331CDD2D92A60D2C8687B7F2A8A3225D100ED.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/150D6CAEE98CEE1B1C5E3BC2F0A76C38F09D9B3F.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=men%20in%20black%20>
{'baidu': 'men in black ',
 'click': '365',
 'ctime': '2016-05-26',
 'fanyi': '',
 'filename': 'Men.in.Black.3.2012.2160p.WEB-DL.2xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:7792BE3AD0E455D97F38552FF3836C07DD4F6993'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/95C6B7F877B9940F0F1E77BFFEA161B65E13B9C1.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=red%20>
{'baidu': 'red ',
 'click': '132',
 'ctime': '2018-02-14',
 'fanyi': '',
 'filename': 'RED.2.2013.UHD.BluRay.2160p.REMUX.TrueHD.7.1.ATMOS.HEVC.HuN-TRiNiTY',
 'length': '74.1 GB',
 'link': 'magnet:?xt=urn:btih:2CF70079D4240C44D0E451EFC5B354CD8C1700ED'}
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=warrior%20>
{'baidu': 'warrior ',
 'click': '1129',
 'ctime': '2018-02-15',
 'fanyi': '',
 'filename': 'Warrior.2011.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '73.9 GB',
 'link': 'magnet:?xt=urn:btih:BF1E913EB8B658C61B783188669BE0B88B414FA5'}
2018-11-28 08:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20bridge%20on%20the%20river%20kwai%20>
{'baidu': 'the bridge on the river kwai ',
 'click': '469',
 'ctime': '2017-12-08',
 'fanyi': '',
 'filename': 'The.Bridge.on.the.River.Kwai.1957.2160p.BluRay.REMUX.HEVC.TrueHD.7.1.Atmos.mkv',
 'length': '74.0 GB',
 'link': 'magnet:?xt=urn:btih:BE97BF7F671B36105ED4E39A9A3034B8066E5D3A'}
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20> (referer: None)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/84375B9B6446AFAD09EBEEF3DF4982D0ABD1BF95.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=t> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%85%D0%B8%D0%B6%D0%B8%D0%BD%D0%B0%20%D0%B2%20%D0%BB%D0%B5%D1%81%D1%83%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EFE68D783891AD8BAEEC7826458BB7B25541CA02.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ozark> (referer: None)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20>
{'baidu': 'godzilla ',
 'click': '504',
 'ctime': '2016-06-05',
 'fanyi': '',
 'filename': 'Godzilla.1998.2160p.WEB-DL.5xRus.Ukr.Eng.TrollUHD-ULTRAHDCLUB.mkv',
 'length': '74.2 GB',
 'link': 'magnet:?xt=urn:btih:F3F7F9E7A0DE8C203D9576DBEA3F4AA2FEDA7854'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bill%20nye%20saves%20the%20world> (referer: None)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=t>
{'baidu': 't',
 'click': '767',
 'ctime': '2017-10-31',
 'fanyi': 't',
 'filename': 'T2.Trainspotting.2017.2160p.BluRay.x264.8bit.SDR.DTS-HD.MA.TrueHD.7.1.Atmos-SWTYBLZ',
 'length': '74.2 GB',
 'link': 'magnet:?xt=urn:btih:EDDBEB611048EBCC4836A56220328E741E18CCC1'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/6FF0A4E508C4C5FDE1252A837214975F89AC8996.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D1%85%D0%B8%D0%B6%D0%B8%D0%BD%D0%B0%20%D0%B2%20%D0%BB%D0%B5%D1%81%D1%83%20>
{'baidu': '   ',
 'click': '747',
 'ctime': '2018-07-01',
 'fanyi': '',
 'filename': '  .2012.UHD.Blu-Ray.Remux.2160p.mkv',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:FF8BB3B36247834D25F193DC8CD8D7623D72DEEA'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=reboot%20the%20guardian%20code> (referer: None)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ozark>
{'baidu': 'ozark',
 'click': '33',
 'ctime': '2018-10-21',
 'fanyi': '',
 'filename': 'Ozark.S02.2160p.WEBRip.HEVC.HDR.KvK.CasStudio.TV',
 'length': '74.3 GB',
 'link': 'magnet:?xt=urn:btih:95C6B7F877B9940F0F1E77BFFEA161B65E13B9C1'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/537012E5CE1D5B0135361E43F3B0CC82A6C83C1C.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B%D0%B3%D0%BE%D0%B4%D0%B7%D0%B8%D0%BB%D0%BB%D0%B0%5D%20web-dl%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bill%20nye%20saves%20the%20world>
{'baidu': 'bill nye saves the world',
 'click': '604',
 'ctime': '2018-07-18',
 'fanyi': '',
 'filename': 'Bill.Nye.Saves.the.World.S03.2160p.NF.WEBRip.DD5.1.x264-TrollUHD[rartv]',
 'length': '74.3 GB',
 'link': 'magnet:?xt=urn:btih:150D6CAEE98CEE1B1C5E3BC2F0A76C38F09D9B3F'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ready_player_one_bdremux%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=detroit%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E78261E17E600C31C35F91698CD9E0B25C708A33.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=reboot%20the%20guardian%20code>
{'baidu': 'reboot the guardian code',
 'click': '552',
 'ctime': '2018-10-06',
 'fanyi': '',
 'filename': 'Reboot.The.Guardian.Code.S01.2160p.NF.WEBRip.x264.DD5.1-TrollUHD[rartv]',
 'length': '74.5 GB',
 'link': 'magnet:?xt=urn:btih:84375B9B6446AFAD09EBEEF3DF4982D0ABD1BF95'}
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B%D0%B3%D0%BE%D0%B4%D0%B7%D0%B8%D0%BB%D0%BB%D0%B0%5D%20web-dl%20>
{'baidu': 'godzilla [] web-dl ',
 'click': '400',
 'ctime': '2018-07-13',
 'fanyi': '[godzilla we',
 'filename': 'Godzilla [] WEB-DL 2160p.mkv',
 'length': '74.2 GB',
 'link': 'magnet:?xt=urn:btih:01AAD37B9E5214DDB5B73990D2752684D04935AC'}
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ready_player_one_bdremux%20>
{'baidu': 'ready_player_one_bdremux ',
 'click': '576',
 'ctime': '2018-08-11',
 'fanyi': 'ready_player_one_bdr',
 'filename': 'Ready_Player_One_BDREMUX.2160p.4K.UltraHD.HEVC.HDR.mkv',
 'length': '74.6 GB',
 'link': 'magnet:?xt=urn:btih:EFE68D783891AD8BAEEC7826458BB7B25541CA02'}
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=detroit%20>
{'baidu': 'detroit ',
 'click': '1035',
 'ctime': '2018-05-26',
 'fanyi': '',
 'filename': 'Detroit.2017.UHD.BluRay.2160p.DTS-HD.MA.5.1.HEVC.HYBRID.REMUX-FraMeSToR',
 'length': '74.1 GB',
 'link': 'magnet:?xt=urn:btih:15D3F26334BC424414B85CAABCC1823496579B14'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0C9AD30F9825691C8AB62169B2AE67FE48E1A47A.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DA60F8A22B6A56803FFEEC71B7752CD8376EF97F.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B72831887FE79A9C7C9D093665B3DF086B04DE78.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_60.html> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F4F1DE76BBC1DE3A3AA602FEC3607BF80F223977.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/081CAAA32361FFC416503B03245FAC3080422441.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hacksaw%20ridge%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D8FD0C1C1152A92887981A10402FE9DB95EA05BD.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/18F35A938FF9711F9B5B3C65854FD9B48C045219.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D8E6CC1214815945926FF35DBF60F1748B9D81B0.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hacksaw%20ridge%20>
{'baidu': 'hacksaw ridge ',
 'click': '2859',
 'ctime': '2017-10-24',
 'fanyi': '',
 'filename': 'Hacksaw.Ridge.2016.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.5 GB',
 'link': 'magnet:?xt=urn:btih:E78261E17E600C31C35F91698CD9E0B25C708A33'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/AF3F99A8CCF1247F02D6DE9340B6C8B7686DA4E0.html> (referer: https://www.bturl.so/search/2160p_length_63.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/5706F199FE88F6958C67E40AC46CA129ABE1951D.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=master%20of%20none> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D59845753F882F5BD8C97B62C9C0D7384855AE8A.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BD6B8739E72B1ACC2480A88A0C512D3CB7C7559D.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=master%20of%20none>
{'baidu': 'master of none',
 'click': '17',
 'ctime': '2016-03-08',
 'fanyi': '',
 'filename': 'Master.of.None.S01.2160p.Netflix.WEBRip.Rus.Eng.TrollUHD-ULTRAHDCLUB',
 'length': '73.5 GB',
 'link': 'magnet:?xt=urn:btih:0C9AD30F9825691C8AB62169B2AE67FE48E1A47A'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/032CD4B93F836EC2FB060FFC404264152F689995.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/757989BF560EAB8913D7A738DAD5B6A1697A3D7D.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%BF%D0%BE%20%D1%81%D0%BE%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%D0%BC%20%D1%81%D0%BE%D0%B2%D0%B5%D1%81%D1%82%D0%B8%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=law%20abiding%20citizen%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tom%20clancys%20jack%20ryan> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20half-blood%20prince%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/045502C02734467F1D039923BDD7F1183CD1B894.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/41BD680277923840DC58924231F85EB9798B5390.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%BF%D0%BE%20%D1%81%D0%BE%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%D0%BC%20%D1%81%D0%BE%D0%B2%D0%B5%D1%81%D1%82%D0%B8%20>
{'baidu': '   ',
 'click': '435',
 'ctime': '2018-08-02',
 'fanyi': '',
 'filename': '  .2016.UHD.Blu-Ray.Remux.2160p.mkv',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:D8E6CC1214815945926FF35DBF60F1748B9D81B0'}
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=law%20abiding%20citizen%20>
{'baidu': 'law abiding citizen ',
 'click': '105',
 'ctime': '2018-11-23',
 'fanyi': '',
 'filename': 'Law.Abiding.Citizen.2009.UHD.BLURAY.2160p.DV.IVA(RUS.UKR.ENG).ExKinoRay',
 'length': '74.5 GB',
 'link': 'magnet:?xt=urn:btih:D8FD0C1C1152A92887981A10402FE9DB95EA05BD'}
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tom%20clancys%20jack%20ryan>
{'baidu': 'tom clancys jack ryan',
 'click': '103',
 'ctime': '2018-09-29',
 'fanyi': '',
 'filename': 'Tom.Clancys.Jack.Ryan.S01.2160p.HDR.WEBRip.2xRus.Eng.EniaHD',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:5706F199FE88F6958C67E40AC46CA129ABE1951D'}
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/12FEB10DD16A11117EB9C5EA9996CE1C6710EBB1.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=blade%20runner%20> (referer: None)
2018-11-28 08:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E98B7791BA63070B58EFB26640E00E1BDD6F449D.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20half-blood%20prince%20>
{'baidu': 'harry potter and the half-blood prince ',
 'click': '1336',
 'ctime': '2018-04-07',
 'fanyi': '',
 'filename': 'Harry.Potter.and.the.Half-Blood.Prince.2009.2160p.BluRay.HEVC.DTS-X.7.1-SUPERSIZE',
 'length': '74.6 GB',
 'link': 'magnet:?xt=urn:btih:AF3F99A8CCF1247F02D6DE9340B6C8B7686DA4E0'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7D092F30224DC28ABB382FA2FAF39BFC06E39B9D.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=blade%20runner%20>
{'baidu': 'blade runner ',
 'click': '75',
 'ctime': '2018-02-02',
 'fanyi': '',
 'filename': 'Blade Runner 2049 [4K Remux][2160p][HDR][AC3 5.1-DTS-MA '
             '5.1Castellano True HD 7.1-Ingles+Subs][ES-EN]',
 'length': '75.3 GB',
 'link': 'magnet:?xt=urn:btih:BD6B8739E72B1ACC2480A88A0C512D3CB7C7559D'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4F74E61E48EABBA417C28F30297CA096096E46F8.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E5F3BCB5405582153DB4F79E6E6FB0A24FCD2C03.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/CABD8E652446CDE1EF942490E46A28EDE86CA3E5.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=american%20psycho%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mary%20and%20the%20witchs%20flower%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/ECA849716728C1C0DDDB47009846162E11B6EB26.html> (referer: https://www.bturl.so/search/2160p_length_65.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=escape%20plan%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D8560CD0E16C38C551571710E488E90E4E3B0C39.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF2B67332083B507B3C62351CA7C42476BBD4CC4.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85E4F6923F1A66A5455030415A28E86317A04A06.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1EC9659D268A58E14DAFB36665123A78935CB89B.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=american%20psycho%20>
{'baidu': 'american psycho ',
 'click': '381',
 'ctime': '2018-09-27',
 'fanyi': '',
 'filename': 'American.Psycho.2000.UNCUT.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-WhiteRhino',
 'length': '75.5 GB',
 'link': 'magnet:?xt=urn:btih:045502C02734467F1D039923BDD7F1183CD1B894'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mary%20and%20the%20witchs%20flower%20>
{'baidu': 'mary and the witchs flower ',
 'click': '1427',
 'ctime': '2018-05-24',
 'fanyi': '',
 'filename': 'Mary.and.the.Witchs.Flower.2017.JAPANESE.2160p.BluRay.REMUX.HEVC.DTS-X.7.1-FGT',
 'length': '75.2 GB',
 'link': 'magnet:?xt=urn:btih:41BD680277923840DC58924231F85EB9798B5390'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9697D424D17BD65BF2395C2C0373BC65C3EDC41E.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=john%20wick%20chapter%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=escape%20plan%20>
{'baidu': 'escape plan ',
 'click': '672',
 'ctime': '2018-07-18',
 'fanyi': '',
 'filename': 'Escape.Plan.2013.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-WhiteRhino',
 'length': '74.4 GB',
 'link': 'magnet:?xt=urn:btih:DA60F8A22B6A56803FFEEC71B7752CD8376EF97F'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hook%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=most%20cherez%20reku%20kvay%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DAE449147BB9B13B01834F927FFD911D4697DA58.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D57A5BA950C63EB50A9FC4272892E533C4D0DB1C.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fi%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=john%20wick%20chapter%20>
{'baidu': 'john wick chapter ',
 'click': '2',
 'ctime': '2017-11-05',
 'fanyi': '',
 'filename': 'John.Wick.Chapter.2.2017.2160p.UltraHD.Bluray.HDR.Atmos.7.1.x265.mkv',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:E5F3BCB5405582153DB4F79E6E6FB0A24FCD2C03'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hook%20>
{'baidu': 'hook ',
 'click': '276',
 'ctime': '2018-10-07',
 'fanyi': '',
 'filename': 'Hook.1991.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:CABD8E652446CDE1EF942490E46A28EDE86CA3E5'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E63B21F095F49CD392E50390A566A4D732034EFF.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9E079E11CB434A8CAF2BED0E30DD0193946CEE1A.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=most%20cherez%20reku%20kvay%20>
{'baidu': 'most cherez reku kvay ',
 'click': '258',
 'ctime': '2018-02-24',
 'fanyi': 'cherez reku kvay',
 'filename': 'Most.cherez.reku.Kvay.1957.2160p.HEVC.UHD.HDR.MediaClub.mkv',
 'length': '73.6 GB',
 'link': 'magnet:?xt=urn:btih:ECA849716728C1C0DDDB47009846162E11B6EB26'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=life_of_pi_> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7EFCE3D74C31C22851504A8319D205C128F71BC0.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B4%D0%B6%D0%B5%D0%B9%D1%81%D0%BE%D0%BD%20%D0%B1%D0%BE%D1%80%D0%BD%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%E4%B8%8E%E9%AD%94%E6%B3%95%E7%9F%B3%20harry%20potter%20and%20the%20sorcerer%27s%20stone%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/18A6D848C6786382C07E10A5B0EE80235E9A93AB.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mindhunter> (referer: None)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fi%20>
{'baidu': 'fi ',
 'click': '34',
 'ctime': '2017-06-23',
 'fanyi': 'fi',
 'filename': 'Fi 01.Sezon (01-12) Boxset 4K UltraHD 2160p WebDL TDRG',
 'length': '75.6 GB',
 'link': 'magnet:?xt=urn:btih:D8560CD0E16C38C551571710E488E90E4E3B0C39'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BC316FAE6F711F059E37B6D1B50E81D19F4BF844.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20sorcerers%20stone%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4E1E7C845C7F8C1B814876084ADC6BFC6CF089EE.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=life_of_pi_>
{'baidu': 'life_of_pi_',
 'click': '21',
 'ctime': '2016-07-03',
 'fanyi': 'life_of_pi_',
 'filename': 'LIFE_OF_PI_2160p.mkv',
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:9697D424D17BD65BF2395C2C0373BC65C3EDC41E'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/93889160517389E976FAF04CD4F9FE47E4E09728.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=step%20brothers%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%E4%B8%8E%E9%AD%94%E6%B3%95%E7%9F%B3%20harry%20potter%20and%20the%20sorcerer%27s%20stone%20>
{'baidu': " harry potter and the sorcerer's stone ",
 'click': '461',
 'ctime': '2018-04-29',
 'fanyi': 'Harry potter and the',
 'filename': ".Harry.Potter.and.the.Sorcerer's.Stone.2001.2160p.UHD.Blu-ray.HEVC.DTS-HD.MA.7.1-TERMiNAL",
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:1EC9659D268A58E14DAFB36665123A78935CB89B'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B4%D0%B6%D0%B5%D0%B9%D1%81%D0%BE%D0%BD%20%D0%B1%D0%BE%D1%80%D0%BD%20>
{'baidu': '  ',
 'click': '648',
 'ctime': '2018-07-09',
 'fanyi': '',
 'filename': ' .2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:85E4F6923F1A66A5455030415A28E86317A04A06'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20spy%20who%20dumped%20me%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=independence%20day%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mindhunter>
{'baidu': 'mindhunter',
 'click': '1',
 'ctime': '2018-11-24',
 'fanyi': 'mindhunter',
 'filename': 'Mindhunter.S01.2160p.TVShows',
 'length': '76.0 GB',
 'link': 'magnet:?xt=urn:btih:DAE449147BB9B13B01834F927FFD911D4697DA58'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20sorcerers%20stone%20>
{'baidu': 'harry potter and the sorcerers stone ',
 'click': '2498',
 'ctime': '2018-01-30',
 'fanyi': '',
 'filename': 'Harry.Potter.and.the.Sorcerers.Stone.2001.2160p.BluRay.REMUX.HEVC.DTS-X.7.1.IVA(RUS.UKR.ENG).mkv',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:7D092F30224DC28ABB382FA2FAF39BFC06E39B9D'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/CF3F34B9D903CF3F3AB64CDB72E5B6175520F139.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=step%20brothers%20>
{'baidu': 'step brothers ',
 'click': '4',
 'ctime': '2018-10-17',
 'fanyi': '',
 'filename': 'Step.Brothers.2008.UHD.BluRay.2160p.HEVC.TrueHD.7.1-COASTER',
 'length': '76.1 GB',
 'link': 'magnet:?xt=urn:btih:E63B21F095F49CD392E50390A566A4D732034EFF'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/EB43622830BBFDE81D3DED7EDCB665C0035DC715.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/566B913944FA1D702AC6A990185D3C57CF23E6BF.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20great%20gatsby%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20spy%20who%20dumped%20me%20>
{'baidu': 'the spy who dumped me ',
 'click': '434',
 'ctime': '2018-10-28',
 'fanyi': '',
 'filename': 'The.Spy.Who.Dumped.Me.2018.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-TERMiNAL',
 'length': '76.1 GB',
 'link': 'magnet:?xt=urn:btih:9E079E11CB434A8CAF2BED0E30DD0193946CEE1A'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=independence%20day%20>
{'baidu': 'independence day ',
 'click': '1193',
 'ctime': '2017-10-31',
 'fanyi': '',
 'filename': 'Independence.Day.1996.EXTENDED.2160p.BluRay.x264.8bit.SDR.DTS-X.7.1-SWTYBLZ',
 'length': '76.0 GB',
 'link': 'magnet:?xt=urn:btih:7EFCE3D74C31C22851504A8319D205C128F71BC0'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=better%20call%20saul> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20patriot%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/69CF1F618693FC1278084783009130978F77D867.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghost%20in%20the%20shell%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20great%20gatsby%20>
{'baidu': 'the great gatsby ',
 'click': '979',
 'ctime': '2018-04-14',
 'fanyi': '',
 'filename': 'The.Great.Gatsby.2013.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.5.1-FGT',
 'length': '75.3 GB',
 'link': 'magnet:?xt=urn:btih:4E1E7C845C7F8C1B814876084ADC6BFC6CF089EE'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zero%20dark%20thirty%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/66ABBF3A72BFF073F58008F1CFBC78EEDF6ECA7A.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/39ACE0AFC0E6736E563BD276D5C12A8222F838C7.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=better%20call%20saul>
{'baidu': 'better call saul',
 'click': '105',
 'ctime': '2016-05-10',
 'fanyi': '',
 'filename': 'Better.Call.Saul.S02.2160p.WEBRip.KvK.CasStudio.TV',
 'length': '75.6 GB',
 'link': 'magnet:?xt=urn:btih:BC316FAE6F711F059E37B6D1B50E81D19F4BF844'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20patriot%20>
{'baidu': 'the patriot ',
 'click': '1381',
 'ctime': '2018-06-26',
 'fanyi': '',
 'filename': 'The.Patriot.2000.THEATRICAL.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '75.6 GB',
 'link': 'magnet:?xt=urn:btih:18A6D848C6786382C07E10A5B0EE80235E9A93AB'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BEAC334C1E036D499A3D5447D04AF7D8FCB3D29C.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ghost%20in%20the%20shell%20>
{'baidu': 'ghost in the shell ',
 'click': '1282',
 'ctime': '2018-07-06',
 'fanyi': '',
 'filename': 'Ghost.in.the.Shell.2.Innocence.2004.2160p.BluRay.HEVC.DTS-X.7.1-TASTED',
 'length': '74.7 GB',
 'link': 'magnet:?xt=urn:btih:CF3F34B9D903CF3F3AB64CDB72E5B6175520F139'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=zero%20dark%20thirty%20>
{'baidu': 'zero dark thirty ',
 'click': '6',
 'ctime': '2018-03-02',
 'fanyi': '',
 'filename': 'Zero.Dark.Thirty.2012.UHD.BluRay.2160p.REMUX.TrueHD.7.1.ATMOS.HEVC.HuN-TRiNiTY',
 'length': '74.7 GB',
 'link': 'magnet:?xt=urn:btih:EB43622830BBFDE81D3DED7EDCB665C0035DC715'}
2018-11-28 08:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20equalizer%20>
{'baidu': 'the equalizer ',
 'click': '1306',
 'ctime': '2018-07-13',
 'fanyi': '',
 'filename': 'The.Equalizer.2014.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '74.8 GB',
 'link': 'magnet:?xt=urn:btih:566B913944FA1D702AC6A990185D3C57CF23E6BF'}
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7D718BBB75F9D2368658878882411E520D42E485.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/31FC1274C3E507C7FEA7BCA09724ED30649A338D.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20prestige%20> (referer: None)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A1A4848CF46322043DF4E54FE4757A927512C9A3.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BEF5E5A4CFC1E6BF1A429EBD890F95E2F3B51CAD.html> (referer: https://www.bturl.so/search/2160p_length_61.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C3EEE205C4CB2A8FFA40A6D8E5E939FF2FEDD8FF.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3CF93A665486E2BB8EF0CE6DB8EAF670354F3BEC.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20prestige%20>
{'baidu': 'the prestige ',
 'click': '1348',
 'ctime': '2018-01-29',
 'fanyi': '',
 'filename': 'The.Prestige.2006.2160p.BluRay.HEVC.HDR.DTS-HD.MA.5.1.IVA(8xRUS.2xUKR.2xENG).mkv',
 'length': '74.8 GB',
 'link': 'magnet:?xt=urn:btih:66ABBF3A72BFF073F58008F1CFBC78EEDF6ECA7A'}
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/88DB1F0B4DE9D1B6FDA904F6ACCB661DD7427AB8.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/220F28CD2E1582EFECBC6894F8FFAC46BAB68E50.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=goodfellas%20> (referer: None)
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A82CF3BDF3204B92055D32B69B9CA3C11BCB228C.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=goodfellas%20>
{'baidu': 'goodfellas ',
 'click': '1076',
 'ctime': '2017-11-24',
 'fanyi': '',
 'filename': 'Goodfellas.1990.2160p.BluRay.x265.10bit.SDR.DTS-HD.MA.5.1-SWTYBLZ',
 'length': '74.8 GB',
 'link': 'magnet:?xt=urn:btih:A1A4848CF46322043DF4E54FE4757A927512C9A3'}
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bad%20boys%20> (referer: None)
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B736082C14171D14B339115494B79E31661DDF1F.html> (referer: https://www.bturl.so/search/2160p_length_62.html)
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=transformers%20-%20the%20last%20knight%20%28> (referer: None)
2018-11-28 08:28:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=bad%20boys%20>
{'baidu': 'bad boys ',
 'click': '1116',
 'ctime': '2018-09-04',
 'fanyi': '',
 'filename': 'Bad.Boys.1995.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-TERMiNAL',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:220F28CD2E1582EFECBC6894F8FFAC46BAB68E50'}
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7E9C0A5F78CBB580A477E834917A488FEF16D782.html> (referer: https://www.bturl.so/search/2160p_length_64.html)
2018-11-28 08:28:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=transformers%20-%20the%20last%20knight%20%28>
{'baidu': 'transformers - the last knight (',
 'click': '907',
 'ctime': '2018-06-25',
 'fanyi': '-(',
 'filename': 'Transformers - The Last Knight (2017) [2160p].mkv',
 'length': '73.9 GB',
 'link': 'magnet:?xt=urn:btih:A82CF3BDF3204B92055D32B69B9CA3C11BCB228C'}
2018-11-28 08:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B> (referer: None)
2018-11-28 08:28:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=godzilla%20%5B>
{'baidu': 'godzilla [',
 'click': '3377',
 'ctime': '2016-10-12',
 'fanyi': '(',
 'filename': 'Godzilla [4K UHD 2160p HEVC X264][DTS MA 5.1 Castellano DTS MA '
             '5.1-Ingles+Subs][ES-EN]',
 'length': '73.8 GB',
 'link': 'magnet:?xt=urn:btih:7E9C0A5F78CBB580A477E834917A488FEF16D782'}
2018-11-28 08:28:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 08:28:30 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\PyProjects\scrapy\magnet\magnet\pipelines.py", line 63, in close_spider
    html = html_template.format(title=title, content=string_bulid)
KeyError: 'link'
2018-11-28 08:28:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 58061,
 'downloader/request_count': 158,
 'downloader/request_method_count/GET': 158,
 'downloader/response_bytes': 283428,
 'downloader/response_count': 158,
 'downloader/response_status_count/200': 158,
 'dupefilter/filtered': 28,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 0, 28, 30, 540101),
 'item_scraped_count': 61,
 'log_count/DEBUG': 221,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 158,
 'scheduler/dequeued': 158,
 'scheduler/dequeued/memory': 158,
 'scheduler/enqueued': 158,
 'scheduler/enqueued/memory': 158,
 'start_time': datetime.datetime(2018, 11, 28, 0, 28, 24, 774735)}
2018-11-28 08:28:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 08:34:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 08:34:27 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 08:34:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 08:34:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 08:34:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 08:34:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 08:34:28 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 08:34:28 [scrapy.core.engine] INFO: Spider opened
2018-11-28 08:34:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 08:34:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 08:34:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_60.html> (referer: None)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D8560CD0E16C38C551571710E488E90E4E3B0C39.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1EC9659D268A58E14DAFB36665123A78935CB89B.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/C3EEE205C4CB2A8FFA40A6D8E5E939FF2FEDD8FF.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7EFCE3D74C31C22851504A8319D205C128F71BC0.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%E4%B8%8E%E9%AD%94%E6%B3%95%E7%9F%B3%20harry%20potter%20and%20the%20sorcerer%27s%20stone%20> (referer: None)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DAE449147BB9B13B01834F927FFD911D4697DA58.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ozark> (referer: None)
2018-11-28 08:34:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%E4%B8%8E%E9%AD%94%E6%B3%95%E7%9F%B3%20harry%20potter%20and%20the%20sorcerer%27s%20stone%20>
{'baidu': " harry potter and the sorcerer's stone ",
 'click': '461',
 'ctime': '2018-04-29',
 'fanyi': 'Harry potter and the',
 'filename': ".Harry.Potter.and.the.Sorcerer's.Stone.2001.2160p.UHD.Blu-ray.HEVC.DTS-HD.MA.7.1-TERMiNAL",
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:1EC9659D268A58E14DAFB36665123A78935CB89B'}
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/D57A5BA950C63EB50A9FC4272892E533C4D0DB1C.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=independence%20day%20> (referer: None)
2018-11-28 08:34:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=ozark>
{'baidu': 'ozark',
 'click': '509',
 'ctime': '2018-09-23',
 'fanyi': '',
 'filename': 'Ozark.S02.2017.WEBRip.2160p.HDR.MediaClub',
 'length': '75.9 GB',
 'link': 'magnet:?xt=urn:btih:C3EEE205C4CB2A8FFA40A6D8E5E939FF2FEDD8FF'}
2018-11-28 08:34:30 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mindhunter> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-28 08:34:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=independence%20day%20>
{'baidu': 'independence day ',
 'click': '1193',
 'ctime': '2017-10-31',
 'fanyi': '',
 'filename': 'Independence.Day.1996.EXTENDED.2160p.BluRay.x264.8bit.SDR.DTS-X.7.1-SWTYBLZ',
 'length': '76.0 GB',
 'link': 'magnet:?xt=urn:btih:7EFCE3D74C31C22851504A8319D205C128F71BC0'}
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/39ACE0AFC0E6736E563BD276D5C12A8222F838C7.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mindhunter> (referer: None)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7D092F30224DC28ABB382FA2FAF39BFC06E39B9D.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mindhunter>
{'baidu': 'mindhunter',
 'click': '1',
 'ctime': '2018-11-24',
 'fanyi': 'mindhunter',
 'filename': 'Mindhunter.S01.2160p.TVShows',
 'length': '76.0 GB',
 'link': 'magnet:?xt=urn:btih:DAE449147BB9B13B01834F927FFD911D4697DA58'}
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20sorcerers%20stone%20> (referer: None)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E63B21F095F49CD392E50390A566A4D732034EFF.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=harry%20potter%20and%20the%20sorcerers%20stone%20>
{'baidu': 'harry potter and the sorcerers stone ',
 'click': '2498',
 'ctime': '2018-01-30',
 'fanyi': '',
 'filename': 'Harry.Potter.and.the.Sorcerers.Stone.2001.2160p.BluRay.REMUX.HEVC.DTS-X.7.1.IVA(RUS.UKR.ENG).mkv',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:7D092F30224DC28ABB382FA2FAF39BFC06E39B9D'}
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=step%20brothers%20> (referer: None)
2018-11-28 08:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E5F3BCB5405582153DB4F79E6E6FB0A24FCD2C03.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=step%20brothers%20>
{'baidu': 'step brothers ',
 'click': '4',
 'ctime': '2018-10-17',
 'fanyi': '',
 'filename': 'Step.Brothers.2008.UHD.BluRay.2160p.HEVC.TrueHD.7.1-COASTER',
 'length': '76.1 GB',
 'link': 'magnet:?xt=urn:btih:E63B21F095F49CD392E50390A566A4D732034EFF'}
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=john%20wick%20chapter%20> (referer: None)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/CABD8E652446CDE1EF942490E46A28EDE86CA3E5.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=john%20wick%20chapter%20>
{'baidu': 'john wick chapter ',
 'click': '2',
 'ctime': '2017-11-05',
 'fanyi': '',
 'filename': 'John.Wick.Chapter.2.2017.2160p.UltraHD.Bluray.HDR.Atmos.7.1.x265.mkv',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:E5F3BCB5405582153DB4F79E6E6FB0A24FCD2C03'}
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/85E4F6923F1A66A5455030415A28E86317A04A06.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9697D424D17BD65BF2395C2C0373BC65C3EDC41E.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/9E079E11CB434A8CAF2BED0E30DD0193946CEE1A.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF2B67332083B507B3C62351CA7C42476BBD4CC4.html> (referer: https://www.bturl.so/search/2160p_length_60.html)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hook%20> (referer: None)
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hook%20>
{'baidu': 'hook ',
 'click': '276',
 'ctime': '2018-10-07',
 'fanyi': '',
 'filename': 'Hook.1991.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:CABD8E652446CDE1EF942490E46A28EDE86CA3E5'}
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=life_of_pi_> (referer: None)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20spy%20who%20dumped%20me%20> (referer: None)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=blade%20runner%20> (referer: None)
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B4%D0%B6%D0%B5%D0%B9%D1%81%D0%BE%D0%BD%20%D0%B1%D0%BE%D1%80%D0%BD%20> (referer: None)
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=life_of_pi_>
{'baidu': 'life_of_pi_',
 'click': '21',
 'ctime': '2016-07-03',
 'fanyi': 'life_of_pi_',
 'filename': 'LIFE_OF_PI_2160p.mkv',
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:9697D424D17BD65BF2395C2C0373BC65C3EDC41E'}
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=blade%20runner%20>
{'baidu': 'blade runner ',
 'click': '1614',
 'ctime': '2018-02-14',
 'fanyi': '',
 'filename': 'Blade.Runner.2049.2017.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-TERMiNAL',
 'length': '75.7 GB',
 'link': 'magnet:?xt=urn:btih:BF2B67332083B507B3C62351CA7C42476BBD4CC4'}
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%D0%B4%D0%B6%D0%B5%D0%B9%D1%81%D0%BE%D0%BD%20%D0%B1%D0%BE%D1%80%D0%BD%20>
{'baidu': '  ',
 'click': '648',
 'ctime': '2018-07-09',
 'fanyi': '',
 'filename': ' .2016.UHD.BluRay.Remux.2160p.mkv',
 'length': '75.8 GB',
 'link': 'magnet:?xt=urn:btih:85E4F6923F1A66A5455030415A28E86317A04A06'}
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20spy%20who%20dumped%20me%20>
{'baidu': 'the spy who dumped me ',
 'click': '434',
 'ctime': '2018-10-28',
 'fanyi': '',
 'filename': 'The.Spy.Who.Dumped.Me.2018.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-TERMiNAL',
 'length': '76.1 GB',
 'link': 'magnet:?xt=urn:btih:9E079E11CB434A8CAF2BED0E30DD0193946CEE1A'}
2018-11-28 08:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fi%20> (referer: None)
2018-11-28 08:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=fi%20>
{'baidu': 'fi ',
 'click': '34',
 'ctime': '2017-06-23',
 'fanyi': 'fi',
 'filename': 'Fi 01.Sezon (01-12) Boxset 4K UltraHD 2160p WebDL TDRG',
 'length': '75.6 GB',
 'link': 'magnet:?xt=urn:btih:D8560CD0E16C38C551571710E488E90E4E3B0C39'}
2018-11-28 08:34:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 08:34:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10537,
 'downloader/request_count': 29,
 'downloader/request_method_count/GET': 29,
 'downloader/response_bytes': 49736,
 'downloader/response_count': 29,
 'downloader/response_status_count/200': 29,
 'dupefilter/filtered': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 0, 34, 31, 703815),
 'item_scraped_count': 13,
 'log_count/DEBUG': 44,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 29,
 'scheduler/dequeued': 29,
 'scheduler/dequeued/memory': 29,
 'scheduler/enqueued': 29,
 'scheduler/enqueued/memory': 29,
 'start_time': datetime.datetime(2018, 11, 28, 0, 34, 28, 422701)}
2018-11-28 08:34:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:44:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 10:44:36 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:44:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 10:44:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:44:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:44:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:44:36 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 10:44:36 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:44:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:44:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 10:44:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_3.html> (referer: None)
2018-11-28 10:44:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:44:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 237,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3570,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 44, 38, 576613),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 28, 2, 44, 36, 670442)}
2018-11-28 10:44:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:48:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 10:48:37 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:48:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 10:48:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:48:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:48:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:48:38 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 10:48:38 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:48:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:48:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 10:48:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_3.html> (referer: None)
2018-11-28 10:48:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/A7C58DA116C766B5984E59587EA3433D4F7DE935.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20grand%20tour> (referer: None)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/260AC3B389BE23D137BB13724DC6A5B43637FE1E.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20grand%20tour>
{'baidu': 'the grand tour',
 'click': '1306',
 'ctime': '2017-02-09',
 'fanyi': 'the',
 'filename': 'The.Grand.Tour.S01.2160p.Amazon.WEBRip.Rus.Eng.TrollUHD-ULTRAHDCLUB',
 'length': '263.9 GB',
 'link': 'magnet:?xt=urn:btih:A7C58DA116C766B5984E59587EA3433D4F7DE935'}
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=breaking%20bad> (referer: None)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/7D4DDDA453657D51711E544E9B4900550FA22021.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=breaking%20bad>
{'baidu': 'breaking bad',
 'click': '2185',
 'ctime': '2016-08-22',
 'fanyi': '',
 'filename': 'Breaking.Bad.S01.2160p.WEBRip.DTS-HD.MA5.1.x264-TrollUHD',
 'length': '266.7 GB',
 'link': 'magnet:?xt=urn:btih:260AC3B389BE23D137BB13724DC6A5B43637FE1E'}
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/04BACCC8217A62EEAD324C355934A1C3984656B1.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0E3BC1506D1C8D89E33281D1D9E61C83A880B046.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mickey%20hart%20band%20superorganism%20live%20> (referer: None)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/B1EF5F14C7A03F7744730ADEAEC6C767E41FCCCD.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=mickey%20hart%20band%20superorganism%20live%20>
{'baidu': 'mickey hart band superorganism live ',
 'click': '205',
 'ctime': '2016-11-03',
 'fanyi': '',
 'filename': 'Mickey.Hart.Band.Superorganism.Live.2013.2160p.WEB-DL.Eng.ULTRAHDCLUB.mov',
 'length': '273.7 GB',
 'link': 'magnet:?xt=urn:btih:04BACCC8217A62EEAD324C355934A1C3984656B1'}
2018-11-28 10:48:40 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=breaking%20bad> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/509A5F56B746CB6852C1648A6D4741BE694D881C.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dynasty%20> (referer: None)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/484831B06C0147491A45877E5D8694641C83E38C.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=game%20of%20thrones> (referer: None)
2018-11-28 10:48:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=dynasty%20>
{'baidu': 'dynasty ',
 'click': '663',
 'ctime': '2018-05-24',
 'fanyi': '',
 'filename': 'Dynasty.2017.S01.2160p.NF.WEBRip.DD5.1.x264-NTb[rartv]',
 'length': '273.3 GB',
 'link': 'magnet:?xt=urn:btih:7D4DDDA453657D51711E544E9B4900550FA22021'}
2018-11-28 10:48:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=naughty%20america%20siterip%20pack%20> (referer: None)
2018-11-28 10:48:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=game%20of%20thrones>
{'baidu': 'game of thrones',
 'click': '1289',
 'ctime': '2018-07-05',
 'fanyi': '',
 'filename': 'Game.of.Thrones.S01.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos.SpaceHD13',
 'length': '271.8 GB',
 'link': 'magnet:?xt=urn:btih:0E3BC1506D1C8D89E33281D1D9E61C83A880B046'}
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20blacklist%20%28> (referer: None)
2018-11-28 10:48:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=naughty%20america%20siterip%20pack%20>
{'baidu': 'naughty america siterip pack ',
 'click': '114',
 'ctime': '2016-11-16',
 'fanyi': 'siterip',
 'filename': 'Naughty America SiteRip Pack 32 4k 2160p-sweety',
 'length': '277.6 GB',
 'link': 'magnet:?xt=urn:btih:509A5F56B746CB6852C1648A6D4741BE694D881C'}
2018-11-28 10:48:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20blacklist%20%28>
{'baidu': 'the blacklist (',
 'click': '2169',
 'ctime': '2016-10-06',
 'fanyi': '(',
 'filename': 'The.Blacklist.(2013).S01.2160p.WEB-DL.DTS-HD.MA.5.1.x264.TrollUHD',
 'length': '288.7 GB',
 'link': 'magnet:?xt=urn:btih:484831B06C0147491A45877E5D8694641C83E38C'}
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0104C6AF9EC7841739638079776F11898A4E612C.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/26ABD2A2BDCD36B3E6173BFC963189E7017AF599.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/356076C27685215C21DC99341BEC35573399A4B9.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0BE0975E0495DFE53D698B633D19A331AE7FA5B3.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vixen%20siterip%20> (referer: None)
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vixen%20complete%20siterip%20> (referer: None)
2018-11-28 10:48:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vixen%20siterip%20>
{'baidu': 'vixen siterip ',
 'click': '189',
 'ctime': '2017-08-05',
 'fanyi': 'siterip',
 'filename': 'Vixen SiteRip 2016 2160p WEB-DL AAC AVC',
 'length': '284.0 GB',
 'link': 'magnet:?xt=urn:btih:26ABD2A2BDCD36B3E6173BFC963189E7017AF599'}
2018-11-28 10:48:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=vixen%20complete%20siterip%20>
{'baidu': 'vixen complete siterip ',
 'click': '149',
 'ctime': '2017-03-18',
 'fanyi': 'siterip',
 'filename': 'VIXEN.Complete.SiteRip.2016.XXX.2160p.MP4-KTR',
 'length': '268.0 GB',
 'link': 'magnet:?xt=urn:btih:0104C6AF9EC7841739638079776F11898A4E612C'}
2018-11-28 10:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=orange%20is%20the%20new%20black> (referer: None)
2018-11-28 10:48:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=orange%20is%20the%20new%20black>
{'baidu': 'orange is the new black',
 'click': '955',
 'ctime': '2018-08-06',
 'fanyi': '',
 'filename': 'Orange.Is.the.New.Black.S06.2160p.NF.WEBRip.DDP5.1.x264-NTb[rartv]',
 'length': '281.6 GB',
 'link': 'magnet:?xt=urn:btih:0BE0975E0495DFE53D698B633D19A331AE7FA5B3'}
2018-11-28 10:48:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/4E69EA1766FD20A24397F51AF425886383735964.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BF613ED2880E26DCB04A64FC7C6983E620285A4E.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20blacklist> (referer: None)
2018-11-28 10:48:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20blacklist>
{'baidu': 'the blacklist',
 'click': '96',
 'ctime': '2016-04-29',
 'fanyi': '',
 'filename': 'The.Blacklist.S01.2160p.WEB-DL.2xRus.Eng.TrollUHD-ULTRAHDCLUB',
 'length': '288.7 GB',
 'link': 'magnet:?xt=urn:btih:356076C27685215C21DC99341BEC35573399A4B9'}
2018-11-28 10:48:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/0C6C9B9DFD67387F21F97164D5A9CB5A7F37A7EF.html> (referer: https://www.bturl.so/search/2160p_length_3.html)
2018-11-28 10:48:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:48:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 9749,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 47685,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'dupefilter/filtered': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 48, 56, 12254),
 'item_scraped_count': 11,
 'log_count/DEBUG': 40,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2018, 11, 28, 2, 48, 38, 294256)}
2018-11-28 10:48:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:00:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:00:44 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:07:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:07:46 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:07:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 11:07:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:07:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:07:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:07:47 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 11:07:47 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:07:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:07:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 11:07:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 11:07:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 3, 7, 47, 396163),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 28, 3, 7, 47, 380542)}
2018-11-28 11:07:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:09:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:09:42 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:09:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 11:09:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:09:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:09:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:09:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 11:09:43 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:09:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:09:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 11:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/2160p_length_4.html> (referer: None)
2018-11-28 11:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E9B0AAB4EBE52967B6AB8863492E7B450DA1CBED.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20grand%20tour> (referer: None)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/690579B21436C1BAE5B10B85DD72A970AC906EAB.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/AEA630348E63C89712733B2DFE1F52D9D931259E.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20grand%20tour>
{'baidu': 'the grand tour',
 'click': '48',
 'ctime': '2017-02-16',
 'fanyi': 'the',
 'filename': 'The.Grand.Tour.S01.2160p.Amazon.WEBRip.Rus.Eng.TrollUHD-ULTRAHDCLUB',
 'length': '226.8 GB',
 'link': 'magnet:?xt=urn:btih:E9B0AAB4EBE52967B6AB8863492E7B450DA1CBED'}
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=marvels%20luke%20cage> (referer: None)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=breaking%20bad> (referer: None)
2018-11-28 11:09:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=marvels%20luke%20cage>
{'baidu': 'marvels luke cage',
 'click': '25',
 'ctime': '2018-07-17',
 'fanyi': '',
 'filename': 'Marvels.Luke.Cage.S02.2160p.NF.WEBRip.DDP5.1.x264-NTb',
 'length': '245.4 GB',
 'link': 'magnet:?xt=urn:btih:690579B21436C1BAE5B10B85DD72A970AC906EAB'}
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3D0CAB1615BE958478E06DDDC5389C0BA604F41B.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=breaking%20bad>
{'baidu': 'breaking bad',
 'click': '16',
 'ctime': '2017-06-27',
 'fanyi': '',
 'filename': 'Breaking.Bad.S01.2160p.WEB-DL.5xUkr.Eng[Hurtom]',
 'length': '232.5 GB',
 'link': 'magnet:?xt=urn:btih:AEA630348E63C89712733B2DFE1F52D9D931259E'}
2018-11-28 11:09:45 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=the%20grand%20tour> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/3073BDF38B5C2342F9E414676037F2E20D5803B3.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/DCAE08EB04ADBD166C634B7869C67CC779498EB0.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=westworld> (referer: None)
2018-11-28 11:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=orange%20is%20the%20new%20black> (referer: None)
2018-11-28 11:09:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=westworld>
{'baidu': 'westworld',
 'click': '2327',
 'ctime': '2017-12-30',
 'fanyi': '',
 'filename': 'Westworld.S01.2160p.BluRay.HEVC.TrueHD.7.1.Atmos-SUPERSIZE',
 'length': '257.3 GB',
 'link': 'magnet:?xt=urn:btih:3073BDF38B5C2342F9E414676037F2E20D5803B3'}
2018-11-28 11:09:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=orange%20is%20the%20new%20black>
{'baidu': 'orange is the new black',
 'click': '261',
 'ctime': '2016-08-09',
 'fanyi': '',
 'filename': 'Orange.Is.the.New.Black.S04.2160p.NF.WEBRip.Rus.Eng.NTb-ULTRAHDCLUB',
 'length': '240.0 GB',
 'link': 'magnet:?xt=urn:btih:DCAE08EB04ADBD166C634B7869C67CC779498EB0'}
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/849F50BA7C3E78B5CC1126A74D7F6B7A3163AC5F.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/1084AD2D0A93CAF683299015D029F18B53FDD745.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/BB04B94C80AE3865DC49843D321A52D46A0993BD.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=game%20of%20thrones> (referer: None)
2018-11-28 11:09:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=game%20of%20thrones>
{'baidu': 'game of thrones',
 'click': '104',
 'ctime': '2018-07-16',
 'fanyi': '',
 'filename': 'Game.of.Thrones.S01.2160p.PROPER.UHD.BluRay.REMUX.HDR.HEVC.TrueHD.Atmos.7.\u200b1.HUN-GS88',
 'length': '259.9 GB',
 'link': 'magnet:?xt=urn:btih:849F50BA7C3E78B5CC1126A74D7F6B7A3163AC5F'}
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/30CCE31D7E02BFC4353FD77FC7D3CC963CC36AE3.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/089C6EBC7C6DF5F93357AD378933B7ED7990DF53.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E331EF61A12FEA297609B6C5F37F87769EC98378.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/E7CD0F3FA6899BB26B4B445099121232D5E05C8E.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=longmire> (referer: None)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/F8C10E22DF56DFBE44FAB992ABE1977526663971.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=longmire>
{'baidu': 'longmire',
 'click': '347',
 'ctime': '2017-09-13',
 'fanyi': 'longmire',
 'filename': 'Longmire.S05.2160p.NF.WEBRip.Rus.Eng.DEFLATE-ULTRAHDCLUB',
 'length': '230.2 GB',
 'link': 'magnet:?xt=urn:btih:30CCE31D7E02BFC4353FD77FC7D3CC963CC36AE3'}
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%E3%80%90> (referer: None)
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=atkgirlfriends%20siterip%20> (referer: None)
2018-11-28 11:09:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=atkgirlfriends%20siterip%20>
{'baidu': 'atkgirlfriends siterip ',
 'click': '5990',
 'ctime': '2015-12-05',
 'fanyi': 'atkgirlfriends siter',
 'filename': 'atkgirlfriends SITERip 4K 2160p WEB-DL MP4',
 'length': '244.5 GB',
 'link': 'magnet:?xt=urn:btih:F8C10E22DF56DFBE44FAB992ABE1977526663971'}
2018-11-28 11:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/86D6A78A5D12CB74BEEB8017A7E14146DD7880E2.html> (referer: https://www.bturl.so/search/2160p_length_4.html)
2018-11-28 11:09:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 11:09:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8983,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 51509,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'dupefilter/filtered': 6,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 3, 9, 47, 47277),
 'item_scraped_count': 8,
 'log_count/DEBUG': 35,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2018, 11, 28, 3, 9, 43, 31819)}
2018-11-28 11:09:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:15:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:15:05 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:15:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 11:15:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:15:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:15:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:15:06 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 11:15:06 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:15:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:15:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 11:15:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 11:15:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 3, 15, 6, 399045),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 28, 3, 15, 6, 399045)}
2018-11-28 11:15:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:16:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:16:37 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:16:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 11:16:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:16:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:16:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:16:38 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 11:16:38 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:16:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:16:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 11:16:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/2160p_size_2.html> (referer: None)
2018-11-28 11:16:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 11:16:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3559,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 3, 16, 40, 20028),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 28, 3, 16, 38, 551337)}
2018-11-28 11:16:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:24:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:24:37 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:24:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 11:24:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:24:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:24:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:24:38 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 11:24:38 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:24:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:24:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 11:24:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/2160p_size_2.html> (referer: None)
2018-11-28 11:24:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/215810bf6bbf1aefe54fafb6c3b453a58efffa4d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/fdf7513966441cdb96f201111a8d2bd58f47a27c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/baaea868434d1bf2ed3443e9aa44bd7f22ab7320.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2d0915d3ea0a99a0fa03e4aaf07c991c7a02345d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e91b21eeed900aff1fc0fc06a64b5cf07937ccb.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/659f14c8c5f0d95508b15010ef455b462c8cf554.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/8cb37926b8b7fa846929b20fca6b9b705291c35c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f854df06018c2a5fe3dbaa3027ea0e54712fd7a8.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/142a6464b6cee0cd4c91baae790f00788c3ee541.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/738473f180a20b69497b79ff6118daa0cc08e754.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:24:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 11:24:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4412,
 'downloader/request_count': 11,
 'downloader/request_method_count/GET': 11,
 'downloader/response_bytes': 25984,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 11,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 3, 24, 41, 453623),
 'log_count/DEBUG': 12,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2018, 11, 28, 3, 24, 38, 397668)}
2018-11-28 11:24:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:41:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:41:41 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:41:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 11:41:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:41:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:41:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:41:42 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 11:41:42 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:41:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:41:42 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 11:41:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/2160p_size_2.html> (referer: None)
2018-11-28 11:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/215810bf6bbf1aefe54fafb6c3b453a58efffa4d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/fdf7513966441cdb96f201111a8d2bd58f47a27c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/738473f180a20b69497b79ff6118daa0cc08e754.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/8cb37926b8b7fa846929b20fca6b9b705291c35c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e91b21eeed900aff1fc0fc06a64b5cf07937ccb.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/baaea868434d1bf2ed3443e9aa44bd7f22ab7320.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2d0915d3ea0a99a0fa03e4aaf07c991c7a02345d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/659f14c8c5f0d95508b15010ef455b462c8cf554.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/142a6464b6cee0cd4c91baae790f00788c3ee541.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f854df06018c2a5fe3dbaa3027ea0e54712fd7a8.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:41:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 11:41:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4412,
 'downloader/request_count': 11,
 'downloader/request_method_count/GET': 11,
 'downloader/response_bytes': 25966,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 11,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 3, 41, 44, 838996),
 'log_count/DEBUG': 12,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2018, 11, 28, 3, 41, 42, 58679)}
2018-11-28 11:41:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:44:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 11:44:39 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:44:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 11:44:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:44:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:44:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:44:40 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 11:44:40 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:44:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 11:44:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/2160p_size_2.html> (referer: None)
2018-11-28 11:44:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f854df06018c2a5fe3dbaa3027ea0e54712fd7a8.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/8cb37926b8b7fa846929b20fca6b9b705291c35c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/baaea868434d1bf2ed3443e9aa44bd7f22ab7320.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tears%20of%20steel%20> (referer: None)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/fdf7513966441cdb96f201111a8d2bd58f47a27c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e91b21eeed900aff1fc0fc06a64b5cf07937ccb.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tears%20of%20steel%20>
{'baidu': 'tears of steel ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Tears of Steel 2012 2160p DM DD5.1 x264-DON',
 'length': '2013-12-03',
 'link': 'magnet:?xt=urn:btih:8CB37926B8B7FA846929B20FCA6B9B705291C35C'}
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hercules%20> (referer: None)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/215810bf6bbf1aefe54fafb6c3b453a58efffa4d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sicario%20%28> (referer: None)
2018-11-28 11:44:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hercules%20>
{'baidu': 'hercules ',
 'click': '',
 'ctime': ' ',
 'fanyi': '',
 'filename': 'Hercules 3D 4K 2014 BDRip 2160p halfSbS (IgorekSh) '
             '[fan-HD.ru].mkv',
 'length': '2016-01-10',
 'link': 'magnet:?xt=urn:btih:FDF7513966441CDB96F201111A8D2BD58F47A27C'}
2018-11-28 11:44:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sicario%20%28>
{'baidu': 'sicario (',
 'click': '',
 'ctime': ' ',
 'fanyi': 'sicario(',
 'filename': 'Sicario (2015) 2160p 4K UltraHD BluRay HEVC x265 Dolby Atmos.mkv',
 'length': '2017-02-12',
 'link': 'magnet:?xt=urn:btih:3E91B21EEED900AFF1FC0FC06A64B5CF07937CCB'}
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2d0915d3ea0a99a0fa03e4aaf07c991c7a02345d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/738473f180a20b69497b79ff6118daa0cc08e754.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwakeupnfuck%5D%20kassandra%20layn%20aka%20mira%20sol%20%28wunf%20> (referer: None)
2018-11-28 11:44:42 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hercules%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/142a6464b6cee0cd4c91baae790f00788c3ee541.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwakeupnfuck%5D%20kassandra%20layn%20aka%20mira%20sol%20%28wunf%20>
{'baidu': '[wakeupnfuck] kassandra layn aka mira sol (wunf ',
 'click': '',
 'ctime': ' ',
 'fanyi': '[wakeupnfuck]kassandra(',
 'filename': '[WakeUpNFuck] Kassandra Layn aka Mira Sol (WUNF 168 - 08.10.15) '
             'rq (2160p).mp4',
 'length': '2015-10-12',
 'link': 'magnet:?xt=urn:btih:215810BF6BBF1AEFE54FAFB6C3B453A58EFFFA4D'}
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=samsung%20uhd%20demo%20germany%20> (referer: None)
2018-11-28 11:44:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=samsung%20uhd%20demo%20germany%20>
{'baidu': 'samsung uhd demo germany ',
 'click': '',
 'ctime': ' ',
 'fanyi': 'uhd',
 'filename': 'Samsung UHD Demo Germany 2160p 4K',
 'length': '2013-12-06',
 'link': 'magnet:?xt=urn:btih:2D0915D3EA0A99A0FA03E4AAF07C991C7A02345D'}
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20rachel%20james%20%28updated%20-%20casting%20x%20> (referer: None)
2018-11-28 11:44:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20rachel%20james%20%28updated%20-%20casting%20x%20>
{'baidu': '[woodmancastingx] rachel james (updated - casting x ',
 'click': '',
 'ctime': ' ',
 'fanyi': '[woodmancastingx](- x',
 'filename': '[WoodmanCastingX] Rachel James (Updated - Casting X 151 - '
             '13.01.16) rq (2160p) Full Version.mp4',
 'length': '2016-02-05',
 'link': 'magnet:?xt=urn:btih:142A6464B6CEE0CD4C91BAAE790F00788C3EE541'}
2018-11-28 11:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/659f14c8c5f0d95508b15010ef455b462c8cf554.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 11:44:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpornfidelity%5D%20goldie%20%28bubble%20butt%20carwash%20-%20> (referer: None)
2018-11-28 11:44:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpornfidelity%5D%20goldie%20%28bubble%20butt%20carwash%20-%20>
{'baidu': '[pornfidelity] goldie (bubble butt carwash - ',
 'click': '',
 'ctime': ' ',
 'fanyi': '[pornfidelity](-',
 'filename': '[PornFidelity] Goldie (Bubble Butt Carwash - 25.09.15) rq '
             '(2160p).mp4',
 'length': '2015-09-26',
 'link': 'magnet:?xt=urn:btih:659F14C8C5F0D95508B15010EF455B462C8CF554'}
2018-11-28 11:44:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20carla%20crouz%20%28updated%20-%20casting%20x%20> (referer: None)
2018-11-28 11:44:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20carla%20crouz%20%28updated%20-%20casting%20x%20>
{'baidu': '[woodmancastingx] carla crouz (updated - casting x ',
 'click': '',
 'ctime': ' ',
 'fanyi': '[woodmancastingx]crouz(- x',
 'filename': '[WoodmanCastingX] Carla Crouz (Updated - Casting X 152 - '
             '12.12.15) rq (2160p).mp4',
 'length': '2016-02-08',
 'link': 'magnet:?xt=urn:btih:BAAEA868434D1BF2ED3443E9AA44BD7F22AB7320'}
2018-11-28 11:44:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 11:44:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7926,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 29300,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 3, 44, 43, 358872),
 'item_scraped_count': 8,
 'log_count/DEBUG': 30,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 20,
 'scheduler/dequeued': 20,
 'scheduler/dequeued/memory': 20,
 'scheduler/enqueued': 20,
 'scheduler/enqueued/memory': 20,
 'start_time': datetime.datetime(2018, 11, 28, 3, 44, 40, 374622)}
2018-11-28 11:44:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 15:46:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-28 15:46:28 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-28 15:46:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-28 15:46:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 15:46:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 15:46:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 15:46:28 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-28 15:46:28 [scrapy.core.engine] INFO: Spider opened
2018-11-28 15:46:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:46:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-28 15:46:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/s/2160p_size_2.html> (referer: None)
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/215810bf6bbf1aefe54fafb6c3b453a58efffa4d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwakeupnfuck%5D%20kassandra%20layn%20aka%20mira%20sol%20%28wunf%20> (referer: None)
2018-11-28 15:46:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwakeupnfuck%5D%20kassandra%20layn%20aka%20mira%20sol%20%28wunf%20>
{'baidu': '[wakeupnfuck] kassandra layn aka mira sol (wunf ',
 'click': 'loading...',
 'ctime': '2015-10-12',
 'fanyi': '[wakeupnfuck]kassandra(',
 'filename': '[WakeUpNFuck] Kassandra Layn aka Mira Sol (WUNF 168 - 08.10.15) '
             'rq (2160p).mp4',
 'length': '11.08 Gb',
 'link': 'magnet:?xt=urn:btih:215810BF6BBF1AEFE54FAFB6C3B453A58EFFFA4D'}
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/fdf7513966441cdb96f201111a8d2bd58f47a27c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/baaea868434d1bf2ed3443e9aa44bd7f22ab7320.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/659f14c8c5f0d95508b15010ef455b462c8cf554.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hercules%20> (referer: None)
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20carla%20crouz%20%28updated%20-%20casting%20x%20> (referer: None)
2018-11-28 15:46:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hercules%20>
{'baidu': 'hercules ',
 'click': 'loading...',
 'ctime': '2016-01-10',
 'fanyi': '',
 'filename': 'Hercules 3D 4K 2014 BDRip 2160p halfSbS (IgorekSh) '
             '[fan-HD.ru].mkv',
 'length': '21.05 Gb',
 'link': 'magnet:?xt=urn:btih:FDF7513966441CDB96F201111A8D2BD58F47A27C'}
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpornfidelity%5D%20goldie%20%28bubble%20butt%20carwash%20-%20> (referer: None)
2018-11-28 15:46:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20carla%20crouz%20%28updated%20-%20casting%20x%20>
{'baidu': '[woodmancastingx] carla crouz (updated - casting x ',
 'click': 'loading...',
 'ctime': '2016-02-08',
 'fanyi': '[woodmancastingx]crouz(- x',
 'filename': '[WoodmanCastingX] Carla Crouz (Updated - Casting X 152 - '
             '12.12.15) rq (2160p).mp4',
 'length': '12.09 Gb',
 'link': 'magnet:?xt=urn:btih:BAAEA868434D1BF2ED3443E9AA44BD7F22AB7320'}
2018-11-28 15:46:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bpornfidelity%5D%20goldie%20%28bubble%20butt%20carwash%20-%20>
{'baidu': '[pornfidelity] goldie (bubble butt carwash - ',
 'click': 'loading...',
 'ctime': '2015-09-26',
 'fanyi': '[pornfidelity](-',
 'filename': '[PornFidelity] Goldie (Bubble Butt Carwash - 25.09.15) rq '
             '(2160p).mp4',
 'length': '11.55 Gb',
 'link': 'magnet:?xt=urn:btih:659F14C8C5F0D95508B15010EF455B462C8CF554'}
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/2d0915d3ea0a99a0fa03e4aaf07c991c7a02345d.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=samsung%20uhd%20demo%20germany%20> (referer: None)
2018-11-28 15:46:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/8cb37926b8b7fa846929b20fca6b9b705291c35c.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/3e91b21eeed900aff1fc0fc06a64b5cf07937ccb.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=samsung%20uhd%20demo%20germany%20>
{'baidu': 'samsung uhd demo germany ',
 'click': 'loading...',
 'ctime': '2013-12-06',
 'fanyi': 'uhd',
 'filename': 'Samsung UHD Demo Germany 2160p 4K',
 'length': '11.18 Gb',
 'link': 'magnet:?xt=urn:btih:2D0915D3EA0A99A0FA03E4AAF07C991C7A02345D'}
2018-11-28 15:46:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tears%20of%20steel%20> (referer: None)
2018-11-28 15:46:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sicario%20%28> (referer: None)
2018-11-28 15:46:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=tears%20of%20steel%20>
{'baidu': 'tears of steel ',
 'click': 'loading...',
 'ctime': '2013-12-03',
 'fanyi': '',
 'filename': 'Tears of Steel 2012 2160p DM DD5.1 x264-DON',
 'length': '11.97 Gb',
 'link': 'magnet:?xt=urn:btih:8CB37926B8B7FA846929B20FCA6B9B705291C35C'}
2018-11-28 15:46:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=sicario%20%28>
{'baidu': 'sicario (',
 'click': 'loading...',
 'ctime': '2017-02-12',
 'fanyi': 'sicario(',
 'filename': 'Sicario (2015) 2160p 4K UltraHD BluRay HEVC x265 Dolby Atmos.mkv',
 'length': '24.74 Gb',
 'link': 'magnet:?xt=urn:btih:3E91B21EEED900AFF1FC0FC06A64B5CF07937CCB'}
2018-11-28 15:46:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/f854df06018c2a5fe3dbaa3027ea0e54712fd7a8.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=> (referer: None)
2018-11-28 15:46:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/738473f180a20b69497b79ff6118daa0cc08e754.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:31 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=hercules%20> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-11-28 15:46:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ciliba.biz/detail/142a6464b6cee0cd4c91baae790f00788c3ee541.html> (referer: https://www.ciliba.biz/s/2160p_size_2.html)
2018-11-28 15:46:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20rachel%20james%20%28updated%20-%20casting%20x%20> (referer: None)
2018-11-28 15:46:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://fanyi.youdao.com/openapi.do?keyfrom=wufeifei&key=716426270&type=data&doctype=json&version=1.1&q=%5Bwoodmancastingx%5D%20rachel%20james%20%28updated%20-%20casting%20x%20>
{'baidu': '[woodmancastingx] rachel james (updated - casting x ',
 'click': 'loading...',
 'ctime': '2016-02-05',
 'fanyi': '[woodmancastingx](- x',
 'filename': '[WoodmanCastingX] Rachel James (Updated - Casting X 151 - '
             '13.01.16) rq (2160p) Full Version.mp4',
 'length': '17.69 Gb',
 'link': 'magnet:?xt=urn:btih:142A6464B6CEE0CD4C91BAAE790F00788C3EE541'}
2018-11-28 15:46:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 15:46:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7763,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 29106,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 7, 46, 34, 265464),
 'item_scraped_count': 8,
 'log_count/DEBUG': 30,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 20,
 'scheduler/dequeued': 20,
 'scheduler/dequeued/memory': 20,
 'scheduler/enqueued': 20,
 'scheduler/enqueued/memory': 20,
 'start_time': datetime.datetime(2018, 11, 28, 7, 46, 28, 750073)}
2018-11-28 15:46:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:38:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:38:33 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:38:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:38:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:38:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:38:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:38:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:38:34 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:38:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:38:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/other/bturl.html> (referer: None)
2018-11-29 09:38:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:38:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12162,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 38, 34, 673098),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 38, 34, 549223)}
2018-11-29 09:38:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:39:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:39:20 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:39:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:39:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:39:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:39:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:39:21 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:39:21 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:39:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:39:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:39:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/other/bturl.html> (referer: None)
2018-11-29 09:39:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:39:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12162,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 39, 21, 229355),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 39, 21, 110475)}
2018-11-29 09:39:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:40:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:40:29 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:40:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:40:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:40:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:40:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:40:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:40:30 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:40:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:40:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:40:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/other/bturl.html> (referer: None)
2018-11-29 09:40:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:40:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12162,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 40, 30, 400742),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 40, 30, 282764)}
2018-11-29 09:40:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:42:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:42:47 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:42:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:42:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:42:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:42:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:42:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:42:48 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:42:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:42:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:42:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/other/bturl.html> (referer: None)
2018-11-29 09:42:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:42:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12162,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 42, 48, 273352),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 42, 48, 157473)}
2018-11-29 09:42:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:43:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:43:47 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:43:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:43:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:43:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:43:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:43:48 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:43:48 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:43:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:43:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:43:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/other/bturl.html> (referer: None)
2018-11-29 09:43:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:43:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12162,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 43, 48, 236108),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 43, 48, 110207)}
2018-11-29 09:43:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:44:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:44:39 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:44:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:44:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:44:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:44:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:44:40 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:44:40 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:44:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:44:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E_ctime_1.html> (referer: None)
2018-11-29 09:44:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:44:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 276,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3643,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 44, 42, 86695),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 44, 40, 211771)}
2018-11-29 09:44:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:44:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:44:52 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:44:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:44:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:44:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:44:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:44:53 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:44:53 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:44:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:44:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:44:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E_ctime_1.html> (referer: None)
2018-11-29 09:44:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:44:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 276,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3643,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 44, 54, 633031),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 44, 53, 508076)}
2018-11-29 09:44:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 09:48:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 09:48:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 09:48:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 09:48:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 09:48:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 09:48:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 09:48:16 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 09:48:16 [scrapy.core.engine] INFO: Spider opened
2018-11-29 09:48:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 09:48:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E_ctime_1.html> (referer: None)
2018-11-29 09:48:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 09:48:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 276,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3643,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 1, 48, 18, 995395),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 1, 48, 16, 386118)}
2018-11-29 09:48:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:32:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:32:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:32:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:32:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:32:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:32:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:32:17 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:32:17 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:32:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:32:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:32:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:32:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 32, 17, 810536),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 32, 17, 810536)}
2018-11-29 10:32:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:34:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:34:30 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:34:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:34:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:34:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:34:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:34:31 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:34:31 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:34:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:34:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:34:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:34:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 34, 31, 131932),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 34, 31, 131932)}
2018-11-29 10:34:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:37:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:37:29 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:37:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:37:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:37:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:37:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:37:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:37:30 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-29 10:37:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2018-11-29 10:40:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:40:40 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:40:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:40:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:40:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:40:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:40:41 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:40:41 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-29 10:40:41 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2018-11-29 10:40:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:40:59 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:40:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:40:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:41:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:41:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:41:00 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:41:00 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-29 10:41:00 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2018-11-29 10:42:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:42:13 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:42:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:42:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:42:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:42:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:42:13 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:42:13 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-29 10:42:13 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2018-11-29 10:42:21 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:42:21 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:42:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:42:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:42:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:42:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:42:21 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:42:21 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-29 10:42:21 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2018-11-29 10:43:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:43:10 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:43:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:43:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:43:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:43:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:43:11 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:43:11 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-29 10:43:11 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2018-11-29 10:45:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:45:05 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:45:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:45:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:45:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:45:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:45:06 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:45:06 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:45:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:45:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:45:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:45:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 45, 6, 424210),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 45, 6, 424210)}
2018-11-29 10:45:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:45:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:45:53 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:45:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:45:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:45:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:45:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:45:53 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:45:53 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:45:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:45:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:45:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:45:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 45, 53, 749598),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 45, 53, 733973)}
2018-11-29 10:45:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:47:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:47:34 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:47:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:47:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:47:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:47:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:47:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:47:34 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:47:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:47:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:47:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:47:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 47, 34, 710409),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 47, 34, 710409)}
2018-11-29 10:47:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:47:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:47:42 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:47:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:47:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:47:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:47:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:47:43 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:47:43 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:47:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:47:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:47:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:47:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 47, 43, 538152),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 47, 43, 522527)}
2018-11-29 10:47:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:48:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:48:49 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:48:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:48:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:48:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:48:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:48:50 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:48:50 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:48:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:48:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:48:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:48:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 48, 50, 405851),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 48, 50, 405851)}
2018-11-29 10:48:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:49:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:49:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:49:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:49:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:49:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:49:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:49:16 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:49:16 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:49:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:49:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:49:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:49:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 49, 16, 207109),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 49, 16, 207109)}
2018-11-29 10:49:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:49:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:49:26 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:49:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:49:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:49:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:49:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:49:27 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:49:27 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:49:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:49:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:49:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:49:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 49, 27, 273166),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 49, 27, 257542)}
2018-11-29 10:49:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 10:49:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 10:49:33 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 10:49:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 10:49:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 10:49:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 10:49:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 10:49:34 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 10:49:34 [scrapy.core.engine] INFO: Spider opened
2018-11-29 10:49:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 10:49:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 10:49:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 10:49:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 2, 49, 34, 515479),
 'log_count/DEBUG': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2018, 11, 29, 2, 49, 34, 499854)}
2018-11-29 10:49:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:02:07 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:02:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:02:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:02:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:02:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:02:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:02:08 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:02:08 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:02:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:02:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:02:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E_ctime_1.html> (referer: None)
2018-11-29 11:02:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:02:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 276,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3643,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 2, 10, 45308),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 2, 8, 560991)}
2018-11-29 11:02:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:04:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:04:24 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:04:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:04:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:04:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:04:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:04:24 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:04:24 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:04:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:04:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:04:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E_ctime_1.html> (referer: None)
2018-11-29 11:04:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:04:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 276,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3643,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 4, 26, 594812),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 4, 24, 985503)}
2018-11-29 11:04:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:08:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:08:51 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:08:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:08:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:08:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:08:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:08:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:08:51 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:08:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:08:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:09:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E_ctime_1.html> (referer: None)
2018-11-29 11:09:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:09:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 276,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3643,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 9, 0, 547407),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 8, 51, 748023)}
2018-11-29 11:09:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:11:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:11:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:11:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:11:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:11:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:11:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:11:16 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:11:16 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:11:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:11:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:11:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 1 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:11:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 2 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:11:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 3 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:11:16 [scrapy.core.scraper] ERROR: Error downloading <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html>
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\core\downloader\handlers\file.py", line 13, in download_request
    with open(filepath, 'rb') as fo:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:11:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:11:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/builtins.FileNotFoundError': 3,
 'downloader/request_bytes': 726,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 11, 16, 681085),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/builtins.FileNotFoundError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 29, 3, 11, 16, 459210)}
2018-11-29 11:11:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:12:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:12:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:12:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:12:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:12:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:12:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:12:16 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:12:16 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:12:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:12:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:12:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 1 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:12:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 2 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:12:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 3 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:12:16 [scrapy.core.scraper] ERROR: Error downloading <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html>
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\core\downloader\handlers\file.py", line 13, in download_request
    with open(filepath, 'rb') as fo:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:12:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:12:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/builtins.FileNotFoundError': 3,
 'downloader/request_bytes': 726,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 12, 16, 594780),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/builtins.FileNotFoundError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 29, 3, 12, 16, 360412)}
2018-11-29 11:12:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:13:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:13:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:13:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:13:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:13:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:13:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:13:15 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:13:15 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:13:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:13:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:13:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 1 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:13:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 2 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:13:15 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html> (failed 3 times): [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:13:15 [scrapy.core.scraper] ERROR: Error downloading <GET file:///D:/PyProjects/scrapy/magnet/other/temp.html>
Traceback (most recent call last):
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "C:\Users\l_wuq\Anaconda3\lib\site-packages\scrapy\core\downloader\handlers\file.py", line 13, in download_request
    with open(filepath, 'rb') as fo:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\PyProjects\\scrapy\\magnet\\other\\temp.html'
2018-11-29 11:13:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:13:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/builtins.FileNotFoundError': 3,
 'downloader/request_bytes': 726,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 13, 15, 838535),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/builtins.FileNotFoundError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 11, 29, 3, 13, 15, 619791)}
2018-11-29 11:13:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:14:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:14:29 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:14:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:14:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:14:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:14:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:14:30 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:14:30 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:14:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:14:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:14:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bturl.so/search/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E_ctime_1.html> (referer: None)
2018-11-29 11:14:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:14:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 276,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3643,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 14, 31, 50232),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 14, 30, 175265)}
2018-11-29 11:14:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:17:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:17:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:17:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:17:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:17:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:17:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:17:11 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:17:11 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:17:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:17:11 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:17:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:17:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10980,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 17, 11, 997879),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 17, 11, 888504)}
2018-11-29 11:17:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:19:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:19:05 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:19:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:19:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:19:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:19:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:19:05 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:19:05 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:19:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:19:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:19:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:19:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:19:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10980,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 19, 6, 124237),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 19, 5, 999238)}
2018-11-29 11:19:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:23:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:23:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:23:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:23:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:23:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:23:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:23:04 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:23:04 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:23:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:23:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:23:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:23:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:23:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10980,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 23, 4, 717372),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 23, 4, 595495)}
2018-11-29 11:23:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:23:16 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:23:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:23:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:23:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:23:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:23:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:23:16 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:23:16 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:23:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:23:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:23:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/search?word=%E5%A6%82%E6%87%BF%E4%BC%A0&sortProperties=download_count&page=3> (referer: None)
2018-11-29 11:23:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:23:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 289,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12586,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 23, 18, 191392),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 23, 16, 736520)}
2018-11-29 11:23:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:26:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:26:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:26:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:26:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:26:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:26:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:26:17 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:26:17 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:26:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:26:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:26:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/search?word=%E5%A6%82%E6%87%BF%E4%BC%A0&sortProperties=download_count&page=3> (referer: None)
2018-11-29 11:26:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:26:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 289,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12596,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 26, 18, 419767),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 26, 17, 856365)}
2018-11-29 11:26:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:29:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:29:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:29:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:29:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:29:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:29:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:29:05 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:29:05 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:29:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:29:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:29:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:29:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:29:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 46960,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 29, 5, 492773),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 29, 5, 376710)}
2018-11-29 11:29:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:29:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:29:54 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:29:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:29:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:29:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:29:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:29:54 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:29:54 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:29:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:29:54 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:29:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:29:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:29:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 46960,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 29, 54, 959788),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 29, 54, 837656)}
2018-11-29 11:29:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:43:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:43:37 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:43:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:43:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:43:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:43:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:43:38 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:43:38 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:43:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:43:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:43:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2> (referer: None)
2018-11-29 11:43:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/114639873F5AA939DCD6C55377CDDD2DFCD5E7B0?r=645> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/522DE5A668C8C0AA9E10627BD20D8FC5200B590D?r=1427> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/8A0D1C7921C89330889EF01D634F5075D8186C10?r=2870> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/B76BFC940628319DB0F826B62A1033FA84088AD0?r=5250> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/9F6FB3367F9AB9833820C93B305DEEB4BCC7AD42?r=6219> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/DD3C24B5E504439E8882444D0C3508F2C50EF099?r=5658> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/93A9D990BFC163B04864261536B3211ED4754B38?r=969> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/90FE5BB3AE388B37B9AA185CBDA94A6CD355135B?r=1077> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/CFA8DE4346A5239172178289BE154CBBEFB62A3C?r=8118> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/C1AC2F99E2D1E71AED65C1226390966C97AA54B2?r=4579> (referer: https://www.cilimao.cc/search?word=2160p&sortProperties=content_size&page=2)
2018-11-29 11:43:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:43:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4093,
 'downloader/request_count': 11,
 'downloader/request_method_count/GET': 11,
 'downloader/response_bytes': 66573,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 11,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 43, 46, 37254),
 'log_count/DEBUG': 12,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2018, 11, 29, 3, 43, 38, 424259)}
2018-11-29 11:43:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:44:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:44:50 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:44:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:44:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:44:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:44:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:44:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:44:51 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:44:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:44:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:44:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:44:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:44:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 46960,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 44, 51, 629614),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 44, 51, 504740)}
2018-11-29 11:44:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:45:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:45:50 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:45:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:45:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:45:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:45:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:45:51 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:45:51 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:45:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:45:51 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:45:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cilimao.cc/information/2424415A59C9791C51DB996F6BAA6D24D89A001D?r=1090> (referer: None)
2018-11-29 11:45:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:45:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 272,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5469,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 45, 52, 36673),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 45, 51, 167221)}
2018-11-29 11:45:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:48:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:48:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:48:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:48:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:48:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:48:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:48:17 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:48:17 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:48:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:48:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:48:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:48:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:48:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17001,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 48, 17, 845217),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 48, 17, 726203)}
2018-11-29 11:48:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:48:57 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:48:57 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:48:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:48:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:48:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:48:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:48:57 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:48:57 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:48:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:48:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:48:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:48:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:48:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17001,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 48, 57, 763277),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 48, 57, 639404)}
2018-11-29 11:48:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:51:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:51:24 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:51:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:51:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:51:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:51:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:51:25 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:51:25 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:51:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:51:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:51:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:51:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:51:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17001,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 51, 25, 743538),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 51, 25, 619665)}
2018-11-29 11:51:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 11:59:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 11:59:06 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 11:59:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 11:59:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 11:59:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 11:59:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 11:59:06 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 11:59:06 [scrapy.core.engine] INFO: Spider opened
2018-11-29 11:59:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 11:59:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 11:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 11:59:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 11:59:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17001,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 3, 59, 6, 756267),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 3, 59, 6, 628401)}
2018-11-29 11:59:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-29 13:32:07 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: magnet)
2018-11-29 13:32:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Windows-10-10.0.17134-SP0
2018-11-29 13:32:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'magnet', 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'magnet.spiders', 'SPIDER_MODULES': ['magnet.spiders']}
2018-11-29 13:32:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-29 13:32:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-29 13:32:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-29 13:32:07 [scrapy.middleware] INFO: Enabled item pipelines:
['magnet.pipelines.MagnetPipeline']
2018-11-29 13:32:07 [scrapy.core.engine] INFO: Spider opened
2018-11-29 13:32:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-29 13:32:07 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-11-29 13:32:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET file:///D:/PyProjects/scrapy/magnet/output/temp.html> (referer: None)
2018-11-29 13:32:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-29 13:32:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 243,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17001,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 29, 5, 32, 8, 2540),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 11, 29, 5, 32, 7, 878525)}
2018-11-29 13:32:08 [scrapy.core.engine] INFO: Spider closed (finished)
